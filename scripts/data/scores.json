{
  "01-ai/Yi-34B": {
    "arc": 64.59,
    "hellaswag": 85.69,
    "truthfulqa": 56.23,
    "mmlu": 76.35,
    "gsm8k": 50.64,
    "winogrande": 83.03,
    "average": 69.42
  },
  "01-ai/Yi-34B-200K": {
    "arc": 65.36,
    "hellaswag": 85.58,
    "truthfulqa": 53.64,
    "winogrande": 82.56,
    "gsm8k": 61.64,
    "mmlu": 76.06,
    "average": 70.81
  },
  "01-ai/Yi-34B-Chat": {
    "arc": 65.44,
    "hellaswag": 84.16,
    "truthfulqa": 55.37,
    "winogrande": 80.11,
    "gsm8k": 31.92,
    "mmlu": 74.9,
    "average": 65.32
  },
  "01-ai/Yi-6B": {
    "arc": 55.55,
    "hellaswag": 76.57,
    "truthfulqa": 41.96,
    "mmlu": 64.11,
    "gsm8k": 12.13,
    "winogrande": 74.19,
    "average": 54.09
  },
  "01-ai/Yi-6B-200K": {
    "arc": 53.58,
    "hellaswag": 75.58,
    "truthfulqa": 41.74,
    "winogrande": 74.27,
    "gsm8k": 30.33,
    "mmlu": 64.65,
    "average": 56.69
  },
  "42MARU/sitebunny-13b": {
    "arc": 63.14,
    "hellaswag": 83.64,
    "truthfulqa": 56.21,
    "mmlu": 59.91,
    "gsm8k": 9.4,
    "winogrande": 76.72,
    "average": 58.17
  },
  "42dot/42dot_LLM-PLM-1.3B": {
    "arc": 32.42,
    "hellaswag": 56.39,
    "truthfulqa": 38.68,
    "winogrande": 58.88,
    "gsm8k": 0.76,
    "mmlu": 27.09,
    "average": 35.7
  },
  "42dot/42dot_LLM-SFT-1.3B": {
    "arc": 36.09,
    "hellaswag": 58.96,
    "truthfulqa": 39.98,
    "winogrande": 58.41,
    "gsm8k": 0.68,
    "mmlu": 25.51,
    "average": 36.6
  },
  "64bits/LexPodLM-13B": {
    "arc": 57.76,
    "hellaswag": 81.04,
    "truthfulqa": 43.48,
    "mmlu": 48.38,
    "gsm8k": 0,
    "winogrande": 76.16,
    "average": 51.14
  },
  "922-CA/monika-ddlc-7b-v1": {
    "arc": 54.95,
    "hellaswag": 76.78,
    "truthfulqa": 43.94,
    "winogrande": 72.85,
    "gsm8k": 8.79,
    "mmlu": 45.61,
    "average": 50.49
  },
  "AA051610/T1B": {
    "arc": 56.14,
    "hellaswag": 79.78,
    "truthfulqa": 47.02,
    "mmlu": 60.01
  },
  "AA051610/T1C": {
    "arc": 50.17,
    "hellaswag": 72.21,
    "truthfulqa": 42.52,
    "mmlu": 56.34
  },
  "AA051610/T2A": {
    "arc": 51.45,
    "hellaswag": 73.99,
    "truthfulqa": 47.01,
    "mmlu": 62.08
  },
  "AA051610/VA": {
    "arc": 41.38,
    "hellaswag": 62.52,
    "truthfulqa": 44.93,
    "mmlu": 49.96
  },
  "AGI-inc/lora_moe_7b": {
    "arc": 50.94,
    "hellaswag": 77.8,
    "truthfulqa": 34.34,
    "mmlu": 35.67
  },
  "AGI-inc/lora_moe_7b_baseline": {
    "arc": 50.94,
    "hellaswag": 77.8,
    "truthfulqa": 34.34,
    "mmlu": 35.67
  },
  "AI-Sweden-Models/gpt-sw3-1.3b": {
    "arc": 30.38,
    "hellaswag": 50.4,
    "truthfulqa": 39.97,
    "winogrande": 58.88,
    "gsm8k": 0.08,
    "mmlu": 26.14,
    "average": 34.31
  },
  "AI-Sweden-Models/gpt-sw3-1.3b-instruct": {
    "arc": 30.97,
    "hellaswag": 51.42,
    "truthfulqa": 40.31,
    "winogrande": 56.75,
    "gsm8k": 1.59,
    "mmlu": 26.17,
    "average": 34.53
  },
  "AI-Sweden-Models/gpt-sw3-20b": {
    "arc": 41.81,
    "hellaswag": 68.75,
    "truthfulqa": 37.1,
    "winogrande": 67.17,
    "gsm8k": 0.99,
    "mmlu": 28.47,
    "average": 40.71
  },
  "AI-Sweden-Models/gpt-sw3-20b-instruct": {
    "arc": 43.17,
    "hellaswag": 71.09,
    "truthfulqa": 41.02,
    "winogrande": 66.77,
    "gsm8k": 8.79,
    "mmlu": 31.32,
    "average": 43.69
  },
  "AI-Sweden-Models/gpt-sw3-40b": {
    "arc": 43,
    "hellaswag": 72.37,
    "truthfulqa": 37.52,
    "winogrande": 67.96,
    "gsm8k": 4.7,
    "mmlu": 34.97,
    "average": 43.42
  },
  "AI-Sweden-Models/gpt-sw3-6.7b": {
    "arc": 36.35,
    "hellaswag": 60.75,
    "truthfulqa": 39.04,
    "winogrande": 60.69,
    "gsm8k": 0.53,
    "mmlu": 26,
    "average": 37.23
  },
  "AI-Sweden-Models/gpt-sw3-6.7b-v2": {
    "arc": 39.42,
    "hellaswag": 66.39,
    "truthfulqa": 35.6,
    "winogrande": 64.25,
    "gsm8k": 1.21,
    "mmlu": 30.09,
    "average": 39.49
  },
  "AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct": {
    "arc": 40.78,
    "hellaswag": 67.77,
    "truthfulqa": 40.32,
    "winogrande": 63.54,
    "gsm8k": 6.37,
    "mmlu": 31.57,
    "average": 41.73
  },
  "AIDC-ai-business/Marcoroni-70B-v1": {
    "arc": 73.55,
    "hellaswag": 87.62,
    "truthfulqa": 64.41,
    "mmlu": 70.67,
    "gsm8k": 33.28,
    "winogrande": 83.43,
    "average": 68.83
  },
  "APMIC/caigun-lora-model-33B": {},
  "Abe13/juniper-certificate-Llama-2-7b-chat-hf": {
    "arc": 29.1,
    "hellaswag": 27.63,
    "truthfulqa": 48.23,
    "mmlu": 24.02,
    "gsm8k": 0,
    "winogrande": 48.3,
    "average": 29.55
  },
  "Aeala/Alpaca-elina-65b": {
    "arc": 65.27,
    "hellaswag": 85.75,
    "truthfulqa": 47.32,
    "mmlu": 63.42,
    "gsm8k": 29.04,
    "winogrande": 81.37,
    "average": 62.03
  },
  "Aeala/Enterredaas-33b": {
    "arc": 60.92,
    "hellaswag": 84.18,
    "truthfulqa": 49.02,
    "mmlu": 58.3,
    "gsm8k": 16.22,
    "winogrande": 78.77,
    "average": 57.9
  },
  "Aeala/GPT4-x-AlpacaDente-30b": {
    "arc": 62.12,
    "hellaswag": 82.78,
    "truthfulqa": 52.68,
    "mmlu": 56.19,
    "gsm8k": 30.1,
    "winogrande": 78.69,
    "average": 60.43
  },
  "Aeala/GPT4-x-AlpacaDente2-30b": {
    "arc": 60.58,
    "hellaswag": 81.81,
    "truthfulqa": 48.38,
    "mmlu": 56.63,
    "gsm8k": 26.76,
    "winogrande": 78.14,
    "average": 58.72
  },
  "Aeala/GPT4-x-Alpasta-13b": {
    "arc": 58.53,
    "hellaswag": 79.92,
    "truthfulqa": 53.06,
    "mmlu": 46.03,
    "gsm8k": 8.79,
    "winogrande": 73.95,
    "average": 53.38
  },
  "Aeala/VicUnlocked-alpaca-30b": {
    "arc": 61.86,
    "hellaswag": 83.79,
    "truthfulqa": 51.03,
    "mmlu": 57.64,
    "gsm8k": 14.63,
    "winogrande": 78.22,
    "average": 57.86
  },
  "AlekseyKorshuk/chatml-pyg-v1": {
    "arc": 37.88,
    "hellaswag": 63.29,
    "truthfulqa": 42.61,
    "mmlu": 32.77,
    "gsm8k": 5.16,
    "winogrande": 62.51,
    "average": 40.7
  },
  "AlekseyKorshuk/pygmalion-6b-vicuna-chatml": {
    "arc": 40.61,
    "hellaswag": 67.73,
    "truthfulqa": 42.76,
    "mmlu": 33.92,
    "gsm8k": 4.4,
    "winogrande": 63.06,
    "average": 42.08
  },
  "AlekseyKorshuk/vic15-exp-syn-fight-cp3838": {
    "arc": 51.79,
    "hellaswag": 75.79,
    "truthfulqa": 49.61,
    "mmlu": 50.23,
    "gsm8k": 6.6,
    "winogrande": 71.82,
    "average": 50.97
  },
  "AlpinDale/pygmalion-instruct": {
    "arc": 52.56,
    "hellaswag": 77.65,
    "truthfulqa": 42.13,
    "mmlu": 35.94,
    "gsm8k": 9.86,
    "winogrande": 72.06,
    "average": 48.37
  },
  "Andron00e/YetAnother_Open-Llama-3B-LoRA": {
    "gsm8k": 0,
    "winogrande": 51.38
  },
  "Andron00e/YetAnother_Open-Llama-3B-LoRA-OpenOrca": {
    "arc": 38.91,
    "hellaswag": 67.62,
    "truthfulqa": 35.3,
    "mmlu": 27.21,
    "gsm8k": 0,
    "winogrande": 50.83,
    "average": 36.65
  },
  "Aspik101/30B-Lazarus-instruct-PL-lora_unload": {
    "arc": 62.8,
    "hellaswag": 84.13,
    "truthfulqa": 55.49,
    "mmlu": 56.87,
    "gsm8k": 11.37,
    "winogrande": 79.08,
    "average": 58.29
  },
  "Aspik101/Llama-2-7b-hf-instruct-pl-lora_unload": {
    "arc": 53.75,
    "hellaswag": 78.34,
    "truthfulqa": 42.34,
    "mmlu": 46.8,
    "gsm8k": 6.22,
    "winogrande": 73.95,
    "average": 50.23
  },
  "Aspik101/Nous-Hermes-13b-pl-lora_unload": {
    "arc": 57.08,
    "hellaswag": 81.49,
    "truthfulqa": 48.3,
    "mmlu": 49.17,
    "gsm8k": 9.25,
    "winogrande": 76.4,
    "average": 53.62
  },
  "Aspik101/Redmond-Puffin-13B-instruct-PL-lora_unload": {
    "arc": 60.92,
    "hellaswag": 82.43,
    "truthfulqa": 44.26,
    "mmlu": 55.61,
    "gsm8k": 11.07,
    "winogrande": 75.69,
    "average": 55
  },
  "Aspik101/StableBeluga-13B-instruct-PL-lora_unload": {
    "arc": 60.92,
    "hellaswag": 82.13,
    "truthfulqa": 48.64,
    "mmlu": 56.99,
    "gsm8k": 12.21,
    "winogrande": 76.56,
    "average": 56.24
  },
  "Aspik101/Vicuzard-30B-Uncensored-instruct-PL-lora_unload": {
    "arc": 62.46,
    "hellaswag": 83.66,
    "truthfulqa": 50.94,
    "mmlu": 57.82,
    "gsm8k": 15.31,
    "winogrande": 78.37,
    "average": 58.09
  },
  "Aspik101/WizardVicuna-Uncensored-3B-instruct-PL-lora_unload": {
    "arc": 41.98,
    "hellaswag": 66.82,
    "truthfulqa": 39.67,
    "mmlu": 25.69,
    "gsm8k": 0.68,
    "winogrande": 64.88,
    "average": 39.95
  },
  "Aspik101/llama-30b-2048-instruct-PL-lora_unload": {
    "arc": 63.82,
    "hellaswag": 84.7,
    "truthfulqa": 52.49,
    "mmlu": 61.49,
    "gsm8k": 17.89,
    "winogrande": 79.79,
    "average": 60.03
  },
  "Aspik101/llama-30b-instruct-2048-PL-lora": {
    "arc": 63.65,
    "hellaswag": 84.66,
    "truthfulqa": 53.32,
    "mmlu": 61.69,
    "gsm8k": 16.83,
    "winogrande": 79.08,
    "average": 59.87
  },
  "Aspik101/trurl-2-13b-pl-instruct_unload": {
    "arc": 59.9,
    "hellaswag": 79.99,
    "truthfulqa": 45.56,
    "mmlu": 78.66,
    "gsm8k": 12.21,
    "winogrande": 74.35,
    "average": 58.44
  },
  "Aspik101/trurl-2-7b-pl-instruct_unload": {
    "arc": 53.16,
    "hellaswag": 74.64,
    "truthfulqa": 45.74,
    "mmlu": 49.89,
    "gsm8k": 7.43,
    "winogrande": 72.3,
    "average": 50.53
  },
  "Aspik101/tulu-7b-instruct-pl-lora_unload": {
    "arc": 28.67,
    "hellaswag": 26.05,
    "truthfulqa": 48.61,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 48.22,
    "average": 29.11
  },
  "Aspik101/vicuna-13b-v1.5-PL-lora_unload": {
    "arc": 56.91,
    "hellaswag": 81.22,
    "truthfulqa": 49.76,
    "mmlu": 56.06,
    "gsm8k": 12.28,
    "winogrande": 75.22,
    "average": 55.24
  },
  "Aspik101/vicuna-7b-v1.3-instruct-pl-lora_unload": {
    "arc": 48.04,
    "hellaswag": 76.28,
    "truthfulqa": 44.4,
    "mmlu": 47.42,
    "gsm8k": 6.22,
    "winogrande": 70.09,
    "average": 48.74
  },
  "AtAndDev/ShortKing-3b-v0.3": {
    "arc": 40.96,
    "hellaswag": 70.72,
    "truthfulqa": 38.78,
    "mmlu": 26.21,
    "gsm8k": 1.21,
    "winogrande": 66.93,
    "average": 40.8
  },
  "AtAndDev/ShortKingv0.1": {
    "arc": 34.22,
    "hellaswag": 54.59,
    "truthfulqa": 41.64,
    "mmlu": 25.78,
    "gsm8k": 0.45,
    "winogrande": 56.04,
    "average": 35.45
  },
  "AtomEchoAI/AtomGPT_56k": {
    "arc": 53.16,
    "hellaswag": 76.73,
    "truthfulqa": 40.27,
    "mmlu": 45.31
  },
  "Austism/chronos-hermes-13b-v2": {
    "arc": 60.32,
    "hellaswag": 83.21,
    "truthfulqa": 50.91,
    "mmlu": 55.05,
    "gsm8k": 11.75,
    "winogrande": 75.37,
    "average": 56.1
  },
  "Azure99/blossom-v1-3b": {
    "arc": 36.86,
    "hellaswag": 55.1,
    "truthfulqa": 43.45,
    "mmlu": 26.7,
    "gsm8k": 0.38,
    "winogrande": 58.88,
    "average": 36.9
  },
  "Azure99/blossom-v2-3b": {
    "arc": 35.32,
    "hellaswag": 54.1,
    "truthfulqa": 43.11,
    "mmlu": 23.99,
    "gsm8k": 0.53,
    "winogrande": 58.8,
    "average": 35.98
  },
  "Azure99/blossom-v2-llama2-7b": {
    "arc": 54.1,
    "hellaswag": 78.57,
    "truthfulqa": 46.84,
    "mmlu": 51.66,
    "gsm8k": 4.78,
    "winogrande": 74.35,
    "average": 51.72
  },
  "Azure99/blossom-v3-mistral-7b": {
    "arc": 60.49,
    "hellaswag": 81.9,
    "truthfulqa": 50.31,
    "winogrande": 76.95,
    "gsm8k": 46.7,
    "mmlu": 61.35,
    "average": 62.95
  },
  "Azure99/blossom-v3_1-mistral-7b": {
    "arc": 60.49,
    "hellaswag": 81.71,
    "truthfulqa": 49.51,
    "winogrande": 75.53,
    "gsm8k": 46.93,
    "mmlu": 61,
    "average": 62.53
  },
  "BEE-spoke-data/NanoLlama-GQA-L10-A32_KV8-v13-KI": {
    "arc": 23.81,
    "hellaswag": 29.39,
    "truthfulqa": 44.77,
    "winogrande": 51.14,
    "gsm8k": 0.91,
    "mmlu": 25.37,
    "average": 29.23
  },
  "BEE-spoke-data/TinyLlama-1.1bee": {
    "arc": 30.55,
    "hellaswag": 51.8,
    "truthfulqa": 39.01,
    "mmlu": 24.25,
    "gsm8k": 0.23,
    "winogrande": 54.46,
    "average": 33.38
  },
  "BEE-spoke-data/smol_llama-101M-GQA": {
    "arc": 23.46,
    "hellaswag": 28.73,
    "truthfulqa": 45.8,
    "winogrande": 50.67,
    "gsm8k": 0.76,
    "mmlu": 24.35,
    "average": 28.96
  },
  "BEE-spoke-data/smol_llama-81M-tied": {
    "arc": 22.18,
    "hellaswag": 29.33,
    "truthfulqa": 43.97,
    "winogrande": 49.25,
    "gsm8k": 0.23,
    "mmlu": 24.06,
    "average": 28.17
  },
  "BEE-spoke-data/verysmol_llama-v11-KIx2": {
    "arc": 22.7,
    "hellaswag": 27.6,
    "truthfulqa": 44.75,
    "winogrande": 51.54,
    "gsm8k": 0.3,
    "mmlu": 25.28,
    "average": 28.7
  },
  "BELLE-2/BELLE-Llama2-13B-chat-0.4M": {
    "arc": 60.67,
    "hellaswag": 82.31,
    "truthfulqa": 50.85,
    "mmlu": 55.94,
    "gsm8k": 14.4,
    "winogrande": 75.53,
    "average": 56.62
  },
  "Ba2han/HermesStar-OrcaWind-Synth-11B": {
    "arc": 65.27,
    "hellaswag": 83.69,
    "truthfulqa": 48.55,
    "winogrande": 80.11,
    "gsm8k": 56.63,
    "mmlu": 65.31,
    "average": 66.59
  },
  "BramVanroy/Llama-2-13b-chat-dutch": {
    "arc": 59.3,
    "hellaswag": 81.45,
    "truthfulqa": 38.23,
    "mmlu": 55.82,
    "gsm8k": 10.69,
    "winogrande": 76.64,
    "average": 53.69
  },
  "BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny": {
    "arc": 59.3,
    "hellaswag": 82.04,
    "truthfulqa": 38.03,
    "mmlu": 54.67,
    "gsm8k": 10.31,
    "winogrande": 77.27,
    "average": 53.6
  },
  "BreadAi/DiscordPy": {
    "arc": 23.29,
    "hellaswag": 26.15,
    "truthfulqa": 48.16,
    "mmlu": 25.04,
    "gsm8k": 0,
    "winogrande": 50.99,
    "average": 28.94
  },
  "BreadAi/MuseCan": {
    "gsm8k": 0,
    "winogrande": 49.09
  },
  "BreadAi/MusePy-1-2": {
    "arc": 25.77,
    "hellaswag": 25.94,
    "truthfulqa": 49.33,
    "mmlu": 25.22,
    "gsm8k": 0,
    "winogrande": 50.51,
    "average": 29.46
  },
  "BreadAi/PM_modelV2": {
    "arc": 25.09,
    "hellaswag": 26.45,
    "truthfulqa": 51.36,
    "mmlu": 26.14,
    "gsm8k": 0,
    "winogrande": 49.57,
    "average": 29.77
  },
  "BreadAi/StoryPy": {
    "arc": 22.35,
    "hellaswag": 26.19,
    "truthfulqa": 49.1,
    "mmlu": 24.37,
    "gsm8k": 0,
    "winogrande": 51.07,
    "average": 28.85
  },
  "BreadAi/gpt-YA-1-1_160M": {
    "arc": 22.95,
    "hellaswag": 27.29,
    "truthfulqa": 47.02,
    "mmlu": 26.25,
    "gsm8k": 0,
    "winogrande": 50.67,
    "average": 29.03
  },
  "BreadAi/gpt-YA-1-1_70M": {
    "arc": 22.53,
    "hellaswag": 27.37,
    "truthfulqa": 47.09,
    "mmlu": 25.38,
    "gsm8k": 0,
    "winogrande": 50.91,
    "average": 28.88
  },
  "BreadAi/gpt-Youtube": {
    "arc": 23.29,
    "hellaswag": 26.34,
    "truthfulqa": 48.63,
    "mmlu": 23.54,
    "gsm8k": 0,
    "winogrande": 48.93,
    "average": 28.46
  },
  "Brillibits/Instruct_Llama70B_Dolly15k": {
    "arc": 68.34,
    "hellaswag": 87.21,
    "truthfulqa": 46.46,
    "mmlu": 69.52,
    "gsm8k": 42.68,
    "winogrande": 84.29,
    "average": 66.42
  },
  "Brouz/Slerpeno": {
    "arc": 61.69,
    "hellaswag": 84.1,
    "truthfulqa": 48.05,
    "mmlu": 56.77,
    "gsm8k": 12.51,
    "winogrande": 76.4,
    "average": 56.59
  },
  "ByteWave/Yi-8B-Llama": {
    "arc": 25.68,
    "hellaswag": 26.79,
    "truthfulqa": 47.79,
    "winogrande": 48.3,
    "gsm8k": 0,
    "mmlu": 24.14,
    "average": 28.78
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE1_17w": {
    "arc": 59.47,
    "hellaswag": 81,
    "truthfulqa": 38.17,
    "mmlu": 54.31,
    "gsm8k": 13.27,
    "winogrande": 77.27,
    "average": 53.92
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE1_17w-gate_up_down_proj": {
    "arc": 57.17,
    "hellaswag": 82.26,
    "truthfulqa": 39.93,
    "mmlu": 55.89,
    "gsm8k": 12.89,
    "winogrande": 76.56,
    "average": 54.12
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE1_17w-q_k_v_o_proj": {
    "arc": 59.73,
    "hellaswag": 81.06,
    "truthfulqa": 38.64,
    "mmlu": 54.53,
    "gsm8k": 14.03,
    "winogrande": 78.14,
    "average": 54.36
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r16": {
    "arc": 57.25,
    "hellaswag": 82.27,
    "truthfulqa": 39.75,
    "mmlu": 56.16,
    "gsm8k": 13.34,
    "winogrande": 77.43,
    "average": 54.37
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r4": {
    "arc": 56.74,
    "hellaswag": 82.27,
    "truthfulqa": 39.65,
    "mmlu": 56.18,
    "gsm8k": 13.19,
    "winogrande": 77.03,
    "average": 54.18
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE2_3w": {
    "arc": 58.62,
    "hellaswag": 82.32,
    "truthfulqa": 38.17,
    "mmlu": 54.25,
    "gsm8k": 11.98,
    "winogrande": 76.8,
    "average": 53.69
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE2_3w-gate_up_down_proj": {
    "arc": 57.42,
    "hellaswag": 82.42,
    "truthfulqa": 39.19,
    "mmlu": 55.57,
    "gsm8k": 12.05,
    "winogrande": 77.03,
    "average": 53.95
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE2_3w-q_k_v_o_proj": {
    "arc": 58.53,
    "hellaswag": 82.47,
    "truthfulqa": 37.92,
    "mmlu": 53.9,
    "gsm8k": 12.81,
    "winogrande": 76.8,
    "average": 53.74
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE2_TEST_2.2w": {
    "arc": 56.23,
    "hellaswag": 82.7,
    "truthfulqa": 39.55,
    "mmlu": 55.35,
    "gsm8k": 8.64,
    "winogrande": 76.72,
    "average": 53.2
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down": {
    "arc": 58.7,
    "hellaswag": 81.89,
    "truthfulqa": 38.95,
    "mmlu": 56.08,
    "gsm8k": 12.96,
    "winogrande": 77.35,
    "average": 54.32
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o": {
    "arc": 59.3,
    "hellaswag": 81.2,
    "truthfulqa": 38.13,
    "mmlu": 55.58,
    "gsm8k": 13.5,
    "winogrande": 76.8,
    "average": 54.09
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down": {
    "arc": 59.22,
    "hellaswag": 81.52,
    "truthfulqa": 42.83,
    "mmlu": 54.94,
    "gsm8k": 11.6,
    "winogrande": 76.87,
    "average": 54.5
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down": {
    "arc": 56.4,
    "hellaswag": 81.93,
    "truthfulqa": 39.23,
    "mmlu": 53.63,
    "gsm8k": 11.98,
    "winogrande": 76.95,
    "average": 53.35
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o": {
    "arc": 59.04,
    "hellaswag": 81.15,
    "truthfulqa": 40.16,
    "mmlu": 53,
    "gsm8k": 11.9,
    "winogrande": 76.48,
    "average": 53.62
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down": {
    "arc": 57.76,
    "hellaswag": 80.78,
    "truthfulqa": 40.8,
    "mmlu": 54.32,
    "gsm8k": 7.96,
    "winogrande": 76.72,
    "average": 53.06
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down": {
    "arc": 57.25,
    "hellaswag": 81.79,
    "truthfulqa": 39.66,
    "mmlu": 53.96,
    "gsm8k": 11.75,
    "winogrande": 77.82,
    "average": 53.71
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o": {
    "arc": 56.06,
    "hellaswag": 81.89,
    "truthfulqa": 40.12,
    "mmlu": 55.04,
    "gsm8k": 14.25,
    "winogrande": 76.56,
    "average": 53.99
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down": {
    "arc": 57.94,
    "hellaswag": 81.19,
    "truthfulqa": 40.48,
    "mmlu": 53.43,
    "gsm8k": 10.84,
    "winogrande": 76.72,
    "average": 53.43
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down": {
    "arc": 55.03,
    "hellaswag": 81.97,
    "truthfulqa": 38.07,
    "mmlu": 56.64,
    "gsm8k": 12.21,
    "winogrande": 77.19,
    "average": 53.52
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1": {
    "arc": 55.8,
    "hellaswag": 82.27,
    "truthfulqa": 38.15,
    "mmlu": 55.63,
    "gsm8k": 12.66,
    "winogrande": 77.43,
    "average": 53.66
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o": {
    "arc": 56.23,
    "hellaswag": 81.98,
    "truthfulqa": 39.76,
    "mmlu": 55.87,
    "gsm8k": 11.52,
    "winogrande": 76.72,
    "average": 53.68
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down": {
    "arc": 57.25,
    "hellaswag": 81.49,
    "truthfulqa": 39.79,
    "mmlu": 55.9,
    "gsm8k": 12.05,
    "winogrande": 75.77,
    "average": 53.71
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down": {
    "arc": 55.8,
    "hellaswag": 81.74,
    "truthfulqa": 39.12,
    "mmlu": 55.09,
    "gsm8k": 12.81,
    "winogrande": 76.32,
    "average": 53.48
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o": {
    "arc": 54.78,
    "hellaswag": 81.4,
    "truthfulqa": 41.02,
    "mmlu": 54.73,
    "gsm8k": 10.54,
    "winogrande": 76.64,
    "average": 53.19
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down": {
    "arc": 56.31,
    "hellaswag": 81.43,
    "truthfulqa": 39.11,
    "mmlu": 55.3,
    "gsm8k": 10.46,
    "winogrande": 76.8,
    "average": 53.24
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down": {
    "arc": 54.35,
    "hellaswag": 82.13,
    "truthfulqa": 39.6,
    "mmlu": 55.33,
    "gsm8k": 12.89,
    "winogrande": 77.19,
    "average": 53.58
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o": {
    "arc": 57.68,
    "hellaswag": 81.91,
    "truthfulqa": 41.31,
    "mmlu": 54.95,
    "gsm8k": 12.05,
    "winogrande": 76.48,
    "average": 54.06
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down": {
    "arc": 55.97,
    "hellaswag": 81.53,
    "truthfulqa": 40.72,
    "mmlu": 54.42,
    "gsm8k": 9.55,
    "winogrande": 75.06,
    "average": 52.88
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down": {
    "arc": 58.53,
    "hellaswag": 82.27,
    "truthfulqa": 40.26,
    "mmlu": 55.9,
    "gsm8k": 15.39,
    "winogrande": 76.95,
    "average": 54.88
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down": {
    "arc": 58.36,
    "hellaswag": 82.33,
    "truthfulqa": 39.51,
    "mmlu": 56.14,
    "gsm8k": 10.92,
    "winogrande": 76.4,
    "average": 53.94
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-gate_up_down": {
    "arc": 55.8,
    "hellaswag": 82.1,
    "truthfulqa": 39.82,
    "mmlu": 55.33,
    "gsm8k": 11.37,
    "winogrande": 76.24,
    "average": 53.44
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-q_k_v_o": {
    "arc": 58.7,
    "hellaswag": 81.66,
    "truthfulqa": 43.02,
    "mmlu": 53.87,
    "gsm8k": 13.8,
    "winogrande": 76.72,
    "average": 54.63
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-gate_up_down": {
    "arc": 55.38,
    "hellaswag": 81.92,
    "truthfulqa": 40.76,
    "mmlu": 55.28,
    "gsm8k": 13.72,
    "winogrande": 76.09,
    "average": 53.86
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o": {
    "arc": 58.36,
    "hellaswag": 81.1,
    "truthfulqa": 37.02,
    "mmlu": 54.53,
    "gsm8k": 12.28,
    "winogrande": 76.64,
    "average": 53.32
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down": {
    "arc": 55.89,
    "hellaswag": 81.38,
    "truthfulqa": 40.25,
    "mmlu": 53.77,
    "gsm8k": 12.28,
    "winogrande": 76.72,
    "average": 53.38
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-gate_up_down": {
    "arc": 57.17,
    "hellaswag": 82.15,
    "truthfulqa": 40.23,
    "mmlu": 54.88,
    "gsm8k": 13.34,
    "winogrande": 76.32,
    "average": 54.01
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o": {
    "arc": 57.25,
    "hellaswag": 81.73,
    "truthfulqa": 41.53,
    "mmlu": 55.72,
    "gsm8k": 14.03,
    "winogrande": 77.58,
    "average": 54.64
  },
  "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down": {
    "arc": 55.72,
    "hellaswag": 81.55,
    "truthfulqa": 41.89,
    "mmlu": 53.9,
    "gsm8k": 11.9,
    "winogrande": 77.19,
    "average": 53.69
  },
  "CHIH-HUNG/llama-2-13b-Open-Platypus_2.5w": {
    "arc": 59.56,
    "hellaswag": 82.46,
    "truthfulqa": 42.45,
    "mmlu": 56.06,
    "gsm8k": 8.57,
    "winogrande": 76.8,
    "average": 54.32
  },
  "CHIH-HUNG/llama-2-13b-OpenOrca_20w": {
    "arc": 59.9,
    "hellaswag": 82.51,
    "truthfulqa": 43.14,
    "mmlu": 56.3,
    "gsm8k": 12.66,
    "winogrande": 77.19,
    "average": 55.28
  },
  "CHIH-HUNG/llama-2-13b-OpenOrca_5w": {
    "arc": 61.01,
    "hellaswag": 82.82,
    "truthfulqa": 44.87,
    "mmlu": 56.09,
    "gsm8k": 12.28,
    "winogrande": 77.74,
    "average": 55.8
  },
  "CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w": {
    "arc": 58.96,
    "hellaswag": 82.51,
    "truthfulqa": 40.07,
    "mmlu": 56.12,
    "gsm8k": 6.82,
    "winogrande": 76.64,
    "average": 53.52
  },
  "CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch": {
    "arc": 58.62,
    "hellaswag": 82.56,
    "truthfulqa": 42.09,
    "mmlu": 55.84,
    "gsm8k": 7.05,
    "winogrande": 76.64,
    "average": 53.8
  },
  "CHIH-HUNG/llama-2-13b-alpaca-test": {
    "arc": 60.07,
    "hellaswag": 81.29,
    "truthfulqa": 36.94,
    "mmlu": 55.59
  },
  "CHIH-HUNG/llama-2-13b-dolphin_20w": {
    "arc": 59.56,
    "hellaswag": 82.55,
    "truthfulqa": 42.67,
    "mmlu": 55.89,
    "gsm8k": 12.43,
    "winogrande": 77.27,
    "average": 55.06
  },
  "CHIH-HUNG/llama-2-13b-dolphin_5w": {
    "arc": 60.67,
    "hellaswag": 82.69,
    "truthfulqa": 44.41,
    "mmlu": 56.23,
    "gsm8k": 11.83,
    "winogrande": 77.35,
    "average": 55.53
  },
  "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w": {
    "gsm8k": 11.98,
    "winogrande": 76.8
  },
  "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj": {
    "gsm8k": 12.05,
    "winogrande": 77.03
  },
  "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj": {
    "gsm8k": 12.81,
    "winogrande": 76.8
  },
  "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w": {
    "gsm8k": 13.27,
    "winogrande": 77.27
  },
  "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj": {
    "gsm8k": 12.89,
    "winogrande": 76.56
  },
  "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj": {
    "gsm8k": 14.03,
    "winogrande": 78.14
  },
  "CHIH-HUNG/llama-2-7b-dolphin_10w-test": {
    "arc": 51.71,
    "hellaswag": 74.5,
    "truthfulqa": 42.08,
    "mmlu": 43.9
  },
  "CalderaAI/13B-BlueMethod": {
    "arc": 59.64,
    "hellaswag": 82.07,
    "truthfulqa": 47.74,
    "mmlu": 50.34,
    "gsm8k": 7.81,
    "winogrande": 77.11,
    "average": 54.12
  },
  "CalderaAI/13B-Legerdemain-L2": {
    "arc": 61.26,
    "hellaswag": 83.26,
    "truthfulqa": 41.99,
    "mmlu": 56,
    "gsm8k": 13.04,
    "winogrande": 75.22,
    "average": 55.13
  },
  "CalderaAI/13B-Ouroboros": {
    "arc": 57.42,
    "hellaswag": 82.11,
    "truthfulqa": 47.99,
    "mmlu": 51.43,
    "gsm8k": 0.45,
    "winogrande": 57.85,
    "average": 49.54
  },
  "CalderaAI/13B-Thorns-l2": {
    "arc": 62.88,
    "hellaswag": 83.57,
    "truthfulqa": 49.52,
    "mmlu": 56.95,
    "gsm8k": 0.91,
    "winogrande": 74.51,
    "average": 54.72
  },
  "CalderaAI/30B-Epsilon": {
    "arc": 63.05,
    "hellaswag": 83.59,
    "truthfulqa": 59.03,
    "mmlu": 56.89,
    "gsm8k": 24.56,
    "winogrande": 77.66,
    "average": 60.8
  },
  "CalderaAI/30B-Lazarus": {
    "arc": 64.93,
    "hellaswag": 84.27,
    "truthfulqa": 58.65,
    "mmlu": 56.47,
    "gsm8k": 7.73,
    "winogrande": 78.37,
    "average": 58.4
  },
  "CausalLM/14B": {
    "arc": 56.66,
    "hellaswag": 79.08,
    "truthfulqa": 47.75,
    "winogrande": 74.9,
    "gsm8k": 58.61,
    "mmlu": 65.86,
    "average": 63.81
  },
  "CausalLM/14B-DPO-alpha": {
    "arc": 58.11,
    "hellaswag": 79.38,
    "truthfulqa": 54.15,
    "winogrande": 74.51,
    "gsm8k": 62.7,
    "mmlu": 66.62,
    "average": 65.91
  },
  "CausalLM/7B": {
    "arc": 50,
    "hellaswag": 74.58,
    "truthfulqa": 50.13,
    "winogrande": 69.69,
    "gsm8k": 22.97,
    "mmlu": 61.79,
    "average": 54.86
  },
  "CausalLM/7B-DPO-alpha": {
    "arc": 50.85,
    "hellaswag": 73,
    "truthfulqa": 57.58,
    "winogrande": 67.56,
    "gsm8k": 22.67,
    "mmlu": 63.39,
    "average": 55.84
  },
  "Charlie911/vicuna-7b-v1.5-lora-mctaco": {
    "arc": 45.65,
    "hellaswag": 75.65,
    "truthfulqa": 43.12,
    "mmlu": 49.27,
    "gsm8k": 4.47,
    "winogrande": 69.93,
    "average": 48.02
  },
  "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified1": {
    "arc": 40.87,
    "hellaswag": 73.4,
    "truthfulqa": 39.87,
    "mmlu": 47.42,
    "gsm8k": 1.29,
    "winogrande": 69.46,
    "average": 45.39
  },
  "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified2": {
    "arc": 42.92,
    "hellaswag": 73.97,
    "truthfulqa": 40.43,
    "mmlu": 48.49,
    "gsm8k": 0.68,
    "winogrande": 69.69,
    "average": 46.03
  },
  "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified4": {
    "arc": 40.7,
    "hellaswag": 73.08,
    "truthfulqa": 41.59,
    "mmlu": 47.26,
    "gsm8k": 0.08,
    "winogrande": 67.88,
    "average": 45.1
  },
  "Charlie911/vicuna-7b-v1.5-lora-mixed-datasets": {
    "arc": 51.71,
    "hellaswag": 76.44,
    "truthfulqa": 39.57,
    "mmlu": 50.13,
    "gsm8k": 7.13,
    "winogrande": 73.24,
    "average": 49.7
  },
  "Charlie911/vicuna-7b-v1.5-lora-mixed-datasets-time-unit": {
    "arc": 51.79,
    "hellaswag": 76.41,
    "truthfulqa": 40.33,
    "mmlu": 49.58,
    "gsm8k": 7.13,
    "winogrande": 73.4,
    "average": 49.77
  },
  "Charlie911/vicuna-7b-v1.5-lora-timedial": {
    "arc": 52.9,
    "hellaswag": 76.29,
    "truthfulqa": 41.6,
    "mmlu": 50.47,
    "gsm8k": 7.28,
    "winogrande": 73.56,
    "average": 50.35
  },
  "Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080082": {
    "arc": 52.82,
    "hellaswag": 76.07,
    "truthfulqa": 43.54,
    "mmlu": 50.47,
    "gsm8k": 7.81,
    "winogrande": 73.72,
    "average": 50.74
  },
  "Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080091": {
    "arc": 52.82,
    "hellaswag": 76.1,
    "truthfulqa": 43.4,
    "mmlu": 50.58,
    "gsm8k": 7.66,
    "winogrande": 73.72,
    "average": 50.71
  },
  "CobraMamba/mamba-gpt-3b": {
    "arc": 40.53,
    "hellaswag": 64.94,
    "truthfulqa": 37.14,
    "mmlu": 25.35,
    "gsm8k": 0.23,
    "winogrande": 65.04,
    "average": 38.87
  },
  "CobraMamba/mamba-gpt-3b-v2": {
    "arc": 42.15,
    "hellaswag": 71.5,
    "truthfulqa": 36.74,
    "mmlu": 27.1
  },
  "CobraMamba/mamba-gpt-3b-v3": {
    "arc": 41.72,
    "hellaswag": 71.05,
    "truthfulqa": 37.86,
    "mmlu": 27.31,
    "gsm8k": 1.21,
    "winogrande": 67.48,
    "average": 41.11
  },
  "CobraMamba/mamba-gpt-3b-v4": {
    "arc": 42.58,
    "hellaswag": 71.04,
    "truthfulqa": 37.26,
    "mmlu": 30.04,
    "gsm8k": 0.68,
    "winogrande": 65.82,
    "average": 41.24
  },
  "CobraMamba/mamba-gpt-7b": {
    "arc": 51.19,
    "hellaswag": 75.4,
    "truthfulqa": 42.06,
    "mmlu": 47.47,
    "gsm8k": 11.98,
    "winogrande": 71.67,
    "average": 49.96
  },
  "CobraMamba/mamba-gpt-7b-v1": {
    "arc": 61.26,
    "hellaswag": 84.1,
    "truthfulqa": 46.34,
    "winogrande": 79.16,
    "gsm8k": 17.36,
    "mmlu": 63.46,
    "average": 58.61
  },
  "CobraMamba/mamba-gpt-7b-v2": {
    "arc": 61.95,
    "hellaswag": 83.83,
    "truthfulqa": 46.63,
    "winogrande": 78.45,
    "gsm8k": 17.29,
    "mmlu": 61.74,
    "average": 58.32
  },
  "Community-LM/llava-v1.5-13b-hf": {
    "arc": 56.14,
    "hellaswag": 80.36,
    "truthfulqa": 43.35,
    "mmlu": 56.89
  },
  "CoolWP/llama-2-13b-guanaco-fp16": {
    "arc": 59.56,
    "hellaswag": 82.39,
    "truthfulqa": 43.4,
    "mmlu": 55.47
  },
  "Corianas/1.3b": {
    "arc": 27.3,
    "hellaswag": 38.3,
    "truthfulqa": 39.02,
    "mmlu": 26.77,
    "gsm8k": 0.15,
    "winogrande": 53.04,
    "average": 30.76
  },
  "Corianas/111m": {
    "arc": 19.71,
    "hellaswag": 26.68,
    "truthfulqa": 43.72,
    "mmlu": 25.28,
    "gsm8k": 0,
    "winogrande": 50.2,
    "average": 27.6
  },
  "Corianas/256_5epoch": {
    "arc": 22.27,
    "hellaswag": 28.99,
    "truthfulqa": 41.71,
    "mmlu": 26.62,
    "gsm8k": 0.23,
    "winogrande": 52.72,
    "average": 28.76
  },
  "Corianas/590m": {
    "arc": 24.15,
    "hellaswag": 31.91,
    "truthfulqa": 42.19,
    "mmlu": 26.61,
    "gsm8k": 0.08,
    "winogrande": 48.38,
    "average": 28.89
  },
  "Corianas/Quokka_1.3b": {
    "arc": 27.73,
    "hellaswag": 37.91,
    "truthfulqa": 40.14,
    "mmlu": 26.66,
    "gsm8k": 0,
    "winogrande": 52.72,
    "average": 30.86
  },
  "Corianas/Quokka_2.7b": {
    "arc": 31.06,
    "hellaswag": 47.72,
    "truthfulqa": 40.14,
    "mmlu": 24.8,
    "gsm8k": 0.38,
    "winogrande": 55.49,
    "average": 33.27
  },
  "Corianas/Quokka_256m": {
    "arc": 22.87,
    "hellaswag": 28.84,
    "truthfulqa": 39.47,
    "mmlu": 26.48,
    "gsm8k": 0,
    "winogrande": 52.25,
    "average": 28.32
  },
  "Corianas/Quokka_590m": {
    "arc": 24.4,
    "hellaswag": 31.61,
    "truthfulqa": 39.59,
    "mmlu": 25.36,
    "gsm8k": 0,
    "winogrande": 50.2,
    "average": 28.53
  },
  "Corianas/gpt-j-6B-Dolly": {
    "arc": 41.3,
    "hellaswag": 65.97,
    "truthfulqa": 37.91,
    "mmlu": 26.78,
    "gsm8k": 0.91,
    "winogrande": 64.72,
    "average": 39.6
  },
  "CoruNethron/neu-sai-it1": {
    "arc": 61.26,
    "hellaswag": 81.39,
    "truthfulqa": 51.49,
    "winogrande": 77.51,
    "gsm8k": 2.88,
    "mmlu": 60.17,
    "average": 55.78
  },
  "Dampish/Dante-2.8B": {
    "gsm8k": 0,
    "winogrande": 51.07
  },
  "Dampish/StellarX-4B-V0": {
    "arc": 36.95,
    "hellaswag": 61.9,
    "truthfulqa": 34.3,
    "mmlu": 26.85,
    "gsm8k": 0,
    "winogrande": 63.85,
    "average": 37.31
  },
  "Dampish/StellarX-4B-V0.2": {
    "arc": 34.64,
    "hellaswag": 56.74,
    "truthfulqa": 38.55,
    "mmlu": 25.55,
    "gsm8k": 0,
    "winogrande": 61.4,
    "average": 36.15
  },
  "DanielSc4/RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1": {
    "arc": 38.65,
    "hellaswag": 63.53,
    "truthfulqa": 36.07,
    "mmlu": 25.16,
    "gsm8k": 0.08,
    "winogrande": 60.14,
    "average": 37.27
  },
  "DanielSc4/RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1": {
    "arc": 41.3,
    "hellaswag": 66.82,
    "truthfulqa": 35.04,
    "mmlu": 26.1,
    "gsm8k": 0.3,
    "winogrande": 65.43,
    "average": 39.17
  },
  "Danielbrdz/Barcenas-13b": {
    "arc": 61.26,
    "hellaswag": 82.13,
    "truthfulqa": 46.67,
    "mmlu": 56.25,
    "gsm8k": 12.36,
    "winogrande": 76.32,
    "average": 55.83
  },
  "Danielbrdz/Barcenas-3b": {
    "arc": 43.17,
    "hellaswag": 67.82,
    "truthfulqa": 41.56,
    "winogrande": 66.22,
    "gsm8k": 2.5,
    "mmlu": 29.16,
    "average": 41.74
  },
  "Danielbrdz/Barcenas-7b": {
    "arc": 55.12,
    "hellaswag": 77.4,
    "truthfulqa": 43.64,
    "mmlu": 49.27,
    "gsm8k": 6.14,
    "winogrande": 73.64,
    "average": 50.87
  },
  "Danielbrdz/CodeBarcenas-7b": {
    "arc": 42.32,
    "hellaswag": 63.43,
    "truthfulqa": 38.51,
    "mmlu": 33.39,
    "gsm8k": 2.5,
    "winogrande": 60.38,
    "average": 40.09
  },
  "DataLinguistic/DataLinguistic-34B-V1.0": {
    "arc": 27.65,
    "hellaswag": 32.96,
    "truthfulqa": 48.73,
    "mmlu": 23.12
  },
  "Deci/DeciCoder-1b": {
    "arc": 21.16,
    "hellaswag": 31.09,
    "truthfulqa": 47.05,
    "mmlu": 24.34,
    "gsm8k": 1.74,
    "winogrande": 50.83,
    "average": 29.37
  },
  "Delcos/Mistral-Pygmalion-7b": {
    "arc": 54.44,
    "hellaswag": 78.48,
    "truthfulqa": 41.82,
    "mmlu": 49.23,
    "gsm8k": 6.82,
    "winogrande": 75.3,
    "average": 51.01
  },
  "Delcos/NATE-7b": {
    "arc": 60.92,
    "hellaswag": 82.1,
    "truthfulqa": 57.18,
    "mmlu": 58.91
  },
  "DevaMalla/llama-base-7b": {
    "arc": 50.94,
    "hellaswag": 77.8,
    "truthfulqa": 34.34,
    "mmlu": 35.67,
    "gsm8k": 3.56,
    "winogrande": 71.43,
    "average": 45.62
  },
  "DevaMalla/llama7b_alpaca_1gpu_bf16": {
    "arc": 52.73,
    "hellaswag": 78.78,
    "truthfulqa": 33.71,
    "mmlu": 36.26,
    "gsm8k": 4.55,
    "winogrande": 72.93,
    "average": 46.49
  },
  "DevaMalla/llama_7b_lora": {
    "arc": 54.86,
    "hellaswag": 79.1,
    "truthfulqa": 34.74,
    "mmlu": 33.63,
    "gsm8k": 5.53,
    "winogrande": 72.77,
    "average": 46.77
  },
  "DevaMalla/llama_7b_qlora": {
    "arc": 55.12,
    "hellaswag": 78.26,
    "truthfulqa": 33.98,
    "mmlu": 35.71,
    "gsm8k": 4.55,
    "winogrande": 72.06,
    "average": 46.61
  },
  "DevaMalla/llama_7b_qlora_cds": {
    "arc": 52.47,
    "hellaswag": 77.76,
    "truthfulqa": 46.14,
    "mmlu": 32.38,
    "gsm8k": 4.09,
    "winogrande": 71.74,
    "average": 47.43
  },
  "DevaMalla/llama_7b_qlora_pds-eval": {
    "arc": 53.92,
    "hellaswag": 78.13,
    "truthfulqa": 45.6,
    "mmlu": 32.98,
    "gsm8k": 4.17,
    "winogrande": 72.61,
    "average": 47.9
  },
  "Devio/test-1400": {
    "arc": 38.14,
    "hellaswag": 66.19,
    "truthfulqa": 36.87,
    "mmlu": 28.63
  },
  "Devio/test-22B": {
    "arc": 39.42,
    "hellaswag": 64.51,
    "truthfulqa": 37.13,
    "mmlu": 27.13,
    "gsm8k": 0.38,
    "winogrande": 57.7,
    "average": 37.71
  },
  "Devio/test-3b": {
    "arc": 27.65,
    "hellaswag": 44.79,
    "truthfulqa": 41.42,
    "mmlu": 23.53,
    "gsm8k": 0.3,
    "winogrande": 55.49,
    "average": 32.2
  },
  "Devio/test-9k-fn": {
    "arc": 40.87,
    "hellaswag": 69.45,
    "truthfulqa": 39.15,
    "mmlu": 29.47
  },
  "Devio/test100": {
    "arc": 37.37,
    "hellaswag": 58.54,
    "truthfulqa": 34.01,
    "mmlu": 27.29
  },
  "Devio/testC": {
    "arc": 39.59,
    "hellaswag": 62.88,
    "truthfulqa": 35.67,
    "mmlu": 27.76
  },
  "DiscoResearch/DiscoLM-70b": {
    "arc": 68.77,
    "hellaswag": 86.1,
    "truthfulqa": 57.64,
    "winogrande": 83.58,
    "gsm8k": 63.53,
    "mmlu": 68.58,
    "average": 71.37
  },
  "Doctor-Shotgun/CalliopeDS-L2-13B": {
    "arc": 60.49,
    "hellaswag": 83.38,
    "truthfulqa": 51.32,
    "mmlu": 55.8,
    "gsm8k": 10.01,
    "winogrande": 77.03,
    "average": 56.34
  },
  "Doctor-Shotgun/CalliopeDS-v2-L2-13B": {
    "arc": 62.8,
    "hellaswag": 84.14,
    "truthfulqa": 51.06,
    "mmlu": 56.14,
    "gsm8k": 12.59,
    "winogrande": 76.01,
    "average": 57.12
  },
  "Doctor-Shotgun/mythospice-70b": {
    "arc": 69.28,
    "hellaswag": 87.53,
    "truthfulqa": 56.76,
    "mmlu": 70.1,
    "gsm8k": 30.1,
    "winogrande": 83.27,
    "average": 66.17
  },
  "Doctor-Shotgun/mythospice-limarp-70b": {
    "arc": 69.2,
    "hellaswag": 87.46,
    "truthfulqa": 55.86,
    "mmlu": 70.14,
    "gsm8k": 32.22,
    "winogrande": 82.72,
    "average": 66.27
  },
  "DopeorNope/LaOT": {
    "arc": 55.63,
    "hellaswag": 78.96,
    "truthfulqa": 44.72,
    "mmlu": 50.3,
    "gsm8k": 0,
    "winogrande": 74.11,
    "average": 50.62
  },
  "Ejafa/vicuna_7B_vanilla_1.1": {
    "arc": 53.67,
    "hellaswag": 77.46,
    "truthfulqa": 48.94,
    "mmlu": 45.63,
    "gsm8k": 5.53,
    "winogrande": 70.96,
    "average": 50.37
  },
  "EleutherAI/gpt-j-6B": {
    "arc": 41.38,
    "hellaswag": 67.54,
    "truthfulqa": 35.96,
    "mmlu": 26.78,
    "gsm8k": 2.96,
    "winogrande": 65.98,
    "average": 40.1
  },
  "EleutherAI/gpt-neo-1.3B": {
    "arc": 31.23,
    "hellaswag": 48.47,
    "truthfulqa": 39.63,
    "mmlu": 24.82,
    "gsm8k": 0.45,
    "winogrande": 56.91,
    "average": 33.59
  },
  "EleutherAI/gpt-neo-125m": {
    "arc": 22.95,
    "hellaswag": 30.26,
    "truthfulqa": 45.58,
    "mmlu": 25.97,
    "gsm8k": 0.3,
    "winogrande": 51.78,
    "average": 29.47
  },
  "EleutherAI/gpt-neo-2.7B": {
    "arc": 33.36,
    "hellaswag": 56.24,
    "truthfulqa": 39.78,
    "mmlu": 26.45,
    "gsm8k": 1.29,
    "winogrande": 60.06,
    "average": 36.2
  },
  "EleutherAI/gpt-neox-20b": {
    "arc": 45.73,
    "hellaswag": 73.45,
    "truthfulqa": 31.61,
    "mmlu": 25,
    "gsm8k": 5.46,
    "winogrande": 68.9,
    "average": 41.69
  },
  "EleutherAI/polyglot-ko-12.8b": {
    "arc": 27.05,
    "hellaswag": 51.68,
    "truthfulqa": 34.69,
    "mmlu": 26.64,
    "gsm8k": 0.15,
    "winogrande": 59.75,
    "average": 33.33
  },
  "EleutherAI/pythia-1.3b": {
    "arc": 31.14,
    "hellaswag": 51.43,
    "truthfulqa": 39.24,
    "mmlu": 26.55,
    "gsm8k": 0.99,
    "winogrande": 57.38,
    "average": 34.46
  },
  "EleutherAI/pythia-1.4b-deduped": {
    "arc": 32.68,
    "hellaswag": 54.96,
    "truthfulqa": 38.66,
    "mmlu": 25.56,
    "gsm8k": 0.83,
    "winogrande": 57.3,
    "average": 35
  },
  "EleutherAI/pythia-12b": {
    "arc": 39.59,
    "hellaswag": 68.82,
    "truthfulqa": 31.85,
    "mmlu": 26.76,
    "gsm8k": 1.74,
    "winogrande": 64.17,
    "average": 38.82
  },
  "EleutherAI/pythia-12b-deduped": {
    "arc": 41.38,
    "hellaswag": 70.26,
    "truthfulqa": 33,
    "mmlu": 25.63,
    "gsm8k": 1.44,
    "winogrande": 66.46,
    "average": 39.7
  },
  "EleutherAI/pythia-160m": {
    "arc": 22.78,
    "hellaswag": 30.34,
    "truthfulqa": 44.26,
    "mmlu": 24.95,
    "gsm8k": 0.23,
    "winogrande": 51.54,
    "average": 29.02
  },
  "EleutherAI/pythia-160m-deduped": {
    "arc": 24.06,
    "hellaswag": 31.39,
    "truthfulqa": 44.34,
    "mmlu": 24.86,
    "gsm8k": 0.23,
    "winogrande": 51.38,
    "average": 29.38
  },
  "EleutherAI/pythia-1b-deduped": {
    "arc": 29.1,
    "hellaswag": 49.65,
    "truthfulqa": 38.94,
    "mmlu": 24.27,
    "gsm8k": 1.14,
    "winogrande": 53.59,
    "average": 32.78
  },
  "EleutherAI/pythia-2.7b": {
    "arc": 37.37,
    "hellaswag": 60.74,
    "truthfulqa": 35.4,
    "mmlu": 25.86,
    "gsm8k": 1.06,
    "winogrande": 62.12,
    "average": 37.09
  },
  "EleutherAI/pythia-2.8b-deduped": {
    "arc": 36.26,
    "hellaswag": 60.66,
    "truthfulqa": 35.56,
    "mmlu": 26.78,
    "gsm8k": 0.83,
    "winogrande": 60.22,
    "average": 36.72
  },
  "EleutherAI/pythia-410m": {
    "arc": 26.19,
    "hellaswag": 40.85,
    "truthfulqa": 41.22,
    "winogrande": 53.12,
    "gsm8k": 0.68,
    "mmlu": 27.25,
    "average": 31.55
  },
  "EleutherAI/pythia-410m-deduped": {
    "arc": 24.83,
    "hellaswag": 41.29,
    "truthfulqa": 40.95,
    "mmlu": 25.99,
    "gsm8k": 0.3,
    "winogrande": 54.38,
    "average": 31.29
  },
  "EleutherAI/pythia-6.7b": {
    "arc": 40.1,
    "hellaswag": 65,
    "truthfulqa": 32.85,
    "mmlu": 24.64,
    "gsm8k": 1.06,
    "winogrande": 64.72,
    "average": 38.06
  },
  "EleutherAI/pythia-6.9b-deduped": {
    "arc": 41.3,
    "hellaswag": 67.05,
    "truthfulqa": 35.19,
    "mmlu": 26.48,
    "gsm8k": 1.67,
    "winogrande": 64.09,
    "average": 39.3
  },
  "EleutherAI/pythia-70m": {
    "arc": 21.59,
    "hellaswag": 27.29,
    "truthfulqa": 47.06,
    "mmlu": 25.9,
    "gsm8k": 0.3,
    "winogrande": 51.46,
    "average": 28.93
  },
  "EleutherAI/pythia-70m-deduped": {
    "arc": 21.08,
    "hellaswag": 27.17,
    "truthfulqa": 47.51,
    "mmlu": 25.26,
    "gsm8k": 0,
    "winogrande": 49.64,
    "average": 28.44
  },
  "Enno-Ai/ennodata-13b-8bit-raw-15epoch": {
    "arc": 61.6,
    "hellaswag": 82.2,
    "truthfulqa": 53.58,
    "mmlu": 57.55,
    "gsm8k": 1.44,
    "winogrande": 77.51,
    "average": 55.65
  },
  "Enno-Ai/ennodata-7b": {
    "arc": 51.02,
    "hellaswag": 77.62,
    "truthfulqa": 33.53,
    "mmlu": 33.95,
    "gsm8k": 3.71,
    "winogrande": 70.96,
    "average": 45.13
  },
  "Enno-Ai/ennodata-raw-pankajmathur-13b-peft": {
    "arc": 61.95,
    "hellaswag": 82.21,
    "truthfulqa": 53.57,
    "mmlu": 57.44,
    "gsm8k": 1.29,
    "winogrande": 75.93,
    "average": 55.4
  },
  "Enno-Ai/vigogne2-enno-13b-sft-lora-4bit": {
    "arc": 62.03,
    "hellaswag": 82.65,
    "truthfulqa": 42.98,
    "mmlu": 54.11,
    "gsm8k": 0.15,
    "winogrande": 76.95,
    "average": 53.15
  },
  "Enoch/llama-65b-hf": {
    "arc": 63.31,
    "hellaswag": 86.09,
    "truthfulqa": 43.43,
    "winogrande": 82.48,
    "gsm8k": 44.81,
    "mmlu": 63.84,
    "average": 63.99
  },
  "Envoid/Libra-19B": {
    "arc": 60.58,
    "hellaswag": 82.04,
    "truthfulqa": 48.41,
    "mmlu": 55.57,
    "gsm8k": 0.08,
    "winogrande": 76.32,
    "average": 53.83
  },
  "Envoid/Yousei-22B": {
    "arc": 55.89,
    "hellaswag": 78.55,
    "truthfulqa": 50.68,
    "mmlu": 52.31,
    "gsm8k": 0.45,
    "winogrande": 71.51,
    "average": 51.57
  },
  "Expert68/llama2_13b_instructed_version2": {
    "arc": 60.07,
    "hellaswag": 84.05,
    "truthfulqa": 46.12,
    "winogrande": 75.61,
    "gsm8k": 10.99,
    "mmlu": 55.61,
    "average": 55.41
  },
  "FINDA-FIT/llama-r": {
    "arc": 21.59,
    "hellaswag": 30.18,
    "truthfulqa": 45.38,
    "mmlu": 26.13,
    "gsm8k": 0.61,
    "winogrande": 52.17,
    "average": 29.34
  },
  "FPHam/Free_Sydney_13b_HF": {
    "arc": 59.39,
    "hellaswag": 81.4,
    "truthfulqa": 45.63,
    "mmlu": 53.73,
    "gsm8k": 9.17,
    "winogrande": 76.01,
    "average": 54.22
  },
  "FPHam/Karen_TheEditor_V2_STRICT_Mistral_7B": {
    "arc": 59.56,
    "hellaswag": 81.79,
    "truthfulqa": 49.36,
    "winogrande": 74.35,
    "gsm8k": 30.17,
    "mmlu": 59.56,
    "average": 59.13
  },
  "FabbriSimo01/Bloom_1b_Quantized": {
    "arc": 27.73,
    "hellaswag": 42.83,
    "truthfulqa": 41.82,
    "mmlu": 26.28,
    "gsm8k": 0.15,
    "winogrande": 55.64,
    "average": 32.41
  },
  "FabbriSimo01/Cerebras_1.3b_Quantized": {
    "arc": 25.94,
    "hellaswag": 38.56,
    "truthfulqa": 42.67,
    "mmlu": 26.79,
    "gsm8k": 0.38,
    "winogrande": 53.51,
    "average": 31.31
  },
  "FabbriSimo01/Facebook_opt_1.3b_Quantized": {
    "gsm8k": 0.15,
    "winogrande": 59.67
  },
  "FabbriSimo01/GPT_Large_Quantized": {
    "arc": 27.05,
    "hellaswag": 26.29,
    "truthfulqa": 48.46,
    "mmlu": 24.12,
    "gsm8k": 0,
    "winogrande": 49.33,
    "average": 29.21
  },
  "Faradaylab/ARIA-70B-V2": {
    "arc": 62.12,
    "hellaswag": 85.68,
    "truthfulqa": 49.8,
    "mmlu": 63.49,
    "gsm8k": 28.81,
    "winogrande": 81.69,
    "average": 61.93
  },
  "Faradaylab/ARIA-70B-V3": {
    "arc": 63.91,
    "hellaswag": 86.21,
    "truthfulqa": 51.32,
    "mmlu": 64.75,
    "gsm8k": 28.13,
    "winogrande": 82.08,
    "average": 62.73
  },
  "Faradaylab/Aria-70B": {
    "arc": 64.51,
    "hellaswag": 85.87,
    "truthfulqa": 52.8,
    "mmlu": 63.88
  },
  "FelixChao/CodeLlama13B-Finetune-v1": {
    "arc": 45.82,
    "hellaswag": 69.36,
    "truthfulqa": 44.97,
    "mmlu": 45.05,
    "gsm8k": 10.99,
    "winogrande": 66.93,
    "average": 47.19
  },
  "FelixChao/llama2-13b-math1.1": {
    "arc": 56.83,
    "hellaswag": 80.69,
    "truthfulqa": 48.48,
    "mmlu": 53.43,
    "gsm8k": 10.69,
    "winogrande": 74.43,
    "average": 54.09
  },
  "FelixChao/llama2-13b-math1.2": {
    "arc": 57.08,
    "hellaswag": 80.61,
    "truthfulqa": 48.3,
    "mmlu": 53.05,
    "gsm8k": 10.99,
    "winogrande": 74.27,
    "average": 54.05
  },
  "FelixChao/vicuna-33b-coder": {
    "arc": 60.67,
    "hellaswag": 83.3,
    "truthfulqa": 51.83,
    "mmlu": 56.92,
    "gsm8k": 12.89,
    "winogrande": 76.87,
    "average": 57.08
  },
  "FelixChao/vicuna-7B-chemical": {
    "arc": 49.83,
    "hellaswag": 74.42,
    "truthfulqa": 51.7,
    "mmlu": 44.1,
    "gsm8k": 3.34,
    "winogrande": 67.17,
    "average": 48.43
  },
  "FelixChao/vicuna-7B-physics": {
    "arc": 49.49,
    "hellaswag": 75.88,
    "truthfulqa": 49.31,
    "mmlu": 46.58,
    "gsm8k": 4.25,
    "winogrande": 69.38,
    "average": 49.15
  },
  "Felladrin/TinyMistral-248M-SFT-v3": {
    "arc": 21.93,
    "hellaswag": 28.26,
    "truthfulqa": 40.03,
    "winogrande": 51.54,
    "gsm8k": 0,
    "mmlu": 22.91,
    "average": 27.44
  },
  "FlagAlpha/Llama2-Chinese-13b-Chat": {
    "arc": 55.97,
    "hellaswag": 82.05,
    "truthfulqa": 48.9,
    "mmlu": 54.74,
    "gsm8k": 12.59,
    "winogrande": 76.16,
    "average": 55.07
  },
  "FlagAlpha/Llama2-Chinese-7b-Chat": {
    "arc": 52.39,
    "hellaswag": 77.52,
    "truthfulqa": 46.87,
    "mmlu": 47.72,
    "gsm8k": 8.04,
    "winogrande": 74.27,
    "average": 51.14
  },
  "Fredithefish/CrimsonPajama": {
    "arc": 40.19,
    "hellaswag": 65.47,
    "truthfulqa": 33.78,
    "mmlu": 25.95,
    "gsm8k": 0.53,
    "winogrande": 65.19,
    "average": 38.52
  },
  "Fredithefish/Guanaco-13B-Uncensored": {
    "arc": 59.56,
    "hellaswag": 82.7,
    "truthfulqa": 43.26,
    "mmlu": 53.65,
    "gsm8k": 9.1,
    "winogrande": 76.32,
    "average": 54.1
  },
  "Fredithefish/Guanaco-3B-Uncensored": {
    "arc": 42.49,
    "hellaswag": 66.99,
    "truthfulqa": 34.71,
    "mmlu": 25.55,
    "gsm8k": 0.53,
    "winogrande": 63.38,
    "average": 38.94
  },
  "Fredithefish/Guanaco-3B-Uncensored-v2": {
    "arc": 42.15,
    "hellaswag": 66.72,
    "truthfulqa": 35.21,
    "mmlu": 26.18,
    "gsm8k": 0.3,
    "winogrande": 63.3,
    "average": 38.98
  },
  "Fredithefish/Guanaco-7B-Uncensored": {
    "arc": 52.13,
    "hellaswag": 78.77,
    "truthfulqa": 44.45,
    "mmlu": 43.42,
    "gsm8k": 4.25,
    "winogrande": 73.09,
    "average": 49.35
  },
  "Fredithefish/ReasonixPajama-3B-HF": {
    "arc": 39.25,
    "hellaswag": 63.47,
    "truthfulqa": 55.42,
    "mmlu": 26.09,
    "gsm8k": 0.53,
    "winogrande": 63.69,
    "average": 41.41
  },
  "Fredithefish/RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4": {
    "arc": 41.64,
    "hellaswag": 66.23,
    "truthfulqa": 36.1,
    "mmlu": 27.26,
    "gsm8k": 0.68,
    "winogrande": 64.4,
    "average": 39.39
  },
  "Fredithefish/RedPajama-INCITE-Chat-3B-ShareGPT-11K": {
    "arc": 40.61,
    "hellaswag": 64.84,
    "truthfulqa": 35.41,
    "mmlu": 26.13,
    "gsm8k": 0.3,
    "winogrande": 63.54,
    "average": 38.47
  },
  "Fredithefish/ScarletPajama-3B-HF": {
    "arc": 39.76,
    "hellaswag": 64.89,
    "truthfulqa": 37.6,
    "mmlu": 27.28,
    "gsm8k": 0.23,
    "winogrande": 64.48,
    "average": 39.04
  },
  "FreedomIntelligence/phoenix-inst-chat-7b": {
    "arc": 44.71,
    "hellaswag": 63.23,
    "truthfulqa": 47.08,
    "mmlu": 39.06,
    "gsm8k": 1.29,
    "winogrande": 62.83,
    "average": 43.03
  },
  "GOAT-AI/GOAT-7B-Community": {
    "arc": 48.81,
    "hellaswag": 74.63,
    "truthfulqa": 42.48,
    "mmlu": 49.58,
    "gsm8k": 4.47,
    "winogrande": 72.3,
    "average": 48.71
  },
  "GeneZC/MiniChat-1.5-3B": {
    "arc": 46.5,
    "hellaswag": 68.28,
    "truthfulqa": 50.71,
    "winogrande": 65.04,
    "gsm8k": 24.18,
    "mmlu": 46.67,
    "average": 50.23
  },
  "GeneZC/MiniChat-3B": {
    "arc": 44.03,
    "hellaswag": 67.19,
    "truthfulqa": 45.67,
    "winogrande": 65.27,
    "gsm8k": 10.54,
    "mmlu": 39.17,
    "average": 45.31
  },
  "GeneZC/MiniMA-3B": {
    "arc": 43.43,
    "hellaswag": 68.06,
    "truthfulqa": 39.76,
    "winogrande": 65.98,
    "gsm8k": 2.73,
    "mmlu": 28.69,
    "average": 41.44
  },
  "GeorgiaTechResearchInstitute/galactica-6.7b-evol-instruct-70k": {
    "arc": 42.58,
    "hellaswag": 49.3,
    "truthfulqa": 42.1,
    "mmlu": 32.96,
    "gsm8k": 0.38,
    "winogrande": 56.27,
    "average": 37.27
  },
  "GeorgiaTechResearchInstitute/galpaca-30b": {
    "arc": 49.32,
    "hellaswag": 58.31,
    "truthfulqa": 41.09,
    "mmlu": 42.1,
    "gsm8k": 2.81,
    "winogrande": 62.51,
    "average": 42.69
  },
  "GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct": {
    "arc": 32.68,
    "hellaswag": 47.6,
    "truthfulqa": 40.41,
    "mmlu": 28.63,
    "gsm8k": 0,
    "winogrande": 55.56,
    "average": 34.15
  },
  "GigaML/X1-large": {},
  "Gryphe/MythoBoros-13b": {
    "arc": 58.19,
    "hellaswag": 81.75,
    "truthfulqa": 48.93,
    "mmlu": 50.13,
    "gsm8k": 8.64,
    "winogrande": 75.77,
    "average": 53.9
  },
  "Gryphe/MythoLogic-13b": {
    "arc": 58.45,
    "hellaswag": 81.56,
    "truthfulqa": 49.47,
    "mmlu": 49.36,
    "gsm8k": 8.64,
    "winogrande": 75.61,
    "average": 53.85
  },
  "Gryphe/MythoLogic-L2-13b": {
    "arc": 61.01,
    "hellaswag": 83.93,
    "truthfulqa": 48.64,
    "mmlu": 55.7,
    "gsm8k": 11.75,
    "winogrande": 76.09,
    "average": 56.19
  },
  "Gryphe/MythoMax-L2-13b": {
    "arc": 60.92,
    "hellaswag": 83.56,
    "truthfulqa": 51.97,
    "mmlu": 55.33,
    "gsm8k": 9.02,
    "winogrande": 75.22,
    "average": 56
  },
  "Gryphe/MythoMist-7b": {
    "arc": 65.87,
    "hellaswag": 83.55,
    "truthfulqa": 59.98,
    "winogrande": 78.06,
    "gsm8k": 20.24,
    "mmlu": 62.32,
    "average": 61.67
  },
  "Gryphe/MythoMix-L2-13b": {
    "arc": 61.09,
    "hellaswag": 83.86,
    "truthfulqa": 52.08,
    "mmlu": 55.42,
    "gsm8k": 9.93,
    "winogrande": 75.45,
    "average": 56.31
  },
  "HWERI/Llama2-7b-sharegpt4": {
    "arc": 55.72,
    "hellaswag": 80.94,
    "truthfulqa": 48.34,
    "mmlu": 47.47,
    "gsm8k": 2.65,
    "winogrande": 71.19,
    "average": 51.05
  },
  "HWERI/pythia-1.4b-deduped-sharegpt": {
    "arc": 34.3,
    "hellaswag": 54.49,
    "truthfulqa": 41.81,
    "mmlu": 24,
    "gsm8k": 0.83,
    "winogrande": 55.25,
    "average": 35.11
  },
  "HWERI/pythia-70m-deduped-cleansharegpt": {
    "arc": 25.68,
    "hellaswag": 25.4,
    "truthfulqa": 51.15,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 52.01,
    "average": 29.56
  },
  "HWERI/pythia-70m-deduped-cleansharegpt-en": {
    "arc": 21.16,
    "hellaswag": 27.16,
    "truthfulqa": 48.57,
    "mmlu": 25.24,
    "gsm8k": 0,
    "winogrande": 50.12,
    "average": 28.71
  },
  "HanningZhang/Robin-v2": {
    "arc": 48.81,
    "hellaswag": 74.48,
    "truthfulqa": 42.33,
    "mmlu": 39.27
  },
  "Harshvir/LaMini-Neo-1.3B-Mental-Health_lora": {
    "arc": 25.77,
    "hellaswag": 25.67,
    "truthfulqa": 48.21,
    "mmlu": 27,
    "gsm8k": 0,
    "winogrande": 49.17,
    "average": 29.3
  },
  "Harshvir/Llama-2-7B-physics": {
    "arc": 52.9,
    "hellaswag": 77.71,
    "truthfulqa": 48.93,
    "mmlu": 48.83,
    "gsm8k": 7.05,
    "winogrande": 71.9,
    "average": 51.22
  },
  "Henk717/airochronos-33B": {
    "arc": 64.42,
    "hellaswag": 85.21,
    "truthfulqa": 50.59,
    "mmlu": 59.79,
    "gsm8k": 13.72,
    "winogrande": 79.32,
    "average": 58.84
  },
  "Henk717/chronoboros-33B": {
    "arc": 63.91,
    "hellaswag": 85,
    "truthfulqa": 49.83,
    "mmlu": 59.44,
    "gsm8k": 15.01,
    "winogrande": 80.35,
    "average": 58.92
  },
  "HiTZ/GoLLIE-7B": {
    "arc": 36.09,
    "hellaswag": 57.93,
    "truthfulqa": 39.27,
    "winogrande": 58.96,
    "gsm8k": 3.26,
    "mmlu": 29.38,
    "average": 37.48
  },
  "HiTZ/alpaca-lora-65b-en-pt-es-ca": {
    "arc": 65.02,
    "hellaswag": 84.88,
    "truthfulqa": 46.06,
    "mmlu": 62.19,
    "gsm8k": 26.69,
    "winogrande": 80.51,
    "average": 60.89
  },
  "HuggingFaceH4/mistral-7b-sft-beta": {
    "arc": 57.42,
    "hellaswag": 82.23,
    "truthfulqa": 43.58,
    "winogrande": 77.58,
    "gsm8k": 36.47,
    "mmlu": 61.42,
    "average": 59.78
  },
  "HuggingFaceH4/starchat-alpha": {
    "arc": 31.57,
    "hellaswag": 49.43,
    "truthfulqa": 43.66,
    "mmlu": 30.76,
    "gsm8k": 2.43,
    "winogrande": 55.09,
    "average": 35.49
  },
  "HuggingFaceH4/starchat-beta": {
    "arc": 52.47,
    "hellaswag": 80.59,
    "truthfulqa": 47.22,
    "mmlu": 42.85,
    "gsm8k": 5.16,
    "winogrande": 69.69,
    "average": 49.66
  },
  "HuggingFaceH4/zephyr-7b-alpha": {
    "arc": 61.01,
    "hellaswag": 84.04,
    "truthfulqa": 57.9,
    "mmlu": 61.39,
    "gsm8k": 14.03,
    "winogrande": 78.61,
    "average": 59.5
  },
  "HuggingFaceH4/zephyr-7b-beta": {
    "arc": 62.46,
    "hellaswag": 84.35,
    "truthfulqa": 57.83,
    "winogrande": 77.11,
    "gsm8k": 27.07,
    "mmlu": 60.7,
    "average": 61.59
  },
  "HyperbeeAI/Tulpar-7b-v0": {
    "arc": 56.31,
    "hellaswag": 79.01,
    "truthfulqa": 51.68,
    "mmlu": 52.55,
    "gsm8k": 2.73,
    "winogrande": 73.88,
    "average": 52.69
  },
  "HyperbeeAI/Tulpar-7b-v1": {
    "arc": 57,
    "hellaswag": 79.69,
    "truthfulqa": 51.83,
    "mmlu": 51.33,
    "gsm8k": 0.68,
    "winogrande": 72.45,
    "average": 52.16
  },
  "ICBU-NPU/FashionGPT-70B-V1": {
    "arc": 71.08,
    "hellaswag": 87.32,
    "truthfulqa": 63.92,
    "mmlu": 70.7,
    "gsm8k": 28.13,
    "winogrande": 83.66,
    "average": 67.47
  },
  "ICBU-NPU/FashionGPT-70B-V1.1": {
    "arc": 71.76,
    "hellaswag": 88.2,
    "truthfulqa": 65.26,
    "mmlu": 70.99,
    "gsm8k": 41.47,
    "winogrande": 82.64,
    "average": 70.05
  },
  "ICBU-NPU/FashionGPT-70B-V1.2": {
    "arc": 73.04,
    "hellaswag": 88.15,
    "truthfulqa": 65.15,
    "mmlu": 70.11,
    "gsm8k": 24.03,
    "winogrande": 82.56,
    "average": 67.17
  },
  "IDEA-CCNL/Ziya-LLaMA-13B-Pretrain-v1": {
    "arc": 27.99,
    "hellaswag": 26,
    "truthfulqa": 48.59,
    "mmlu": 27.04,
    "gsm8k": 0,
    "winogrande": 50.12,
    "average": 29.96
  },
  "IDEA-CCNL/Ziya-LLaMA-13B-v1": {
    "arc": 27.73,
    "hellaswag": 25.96,
    "truthfulqa": 48.65,
    "mmlu": 27.04,
    "gsm8k": 0,
    "winogrande": 49.57,
    "average": 29.83
  },
  "IGeniusDev/llama13B-quant8-testv1-openorca-customdataset": {
    "arc": 60.15,
    "hellaswag": 82.99,
    "truthfulqa": 37.27,
    "mmlu": 54.33,
    "gsm8k": 10.08,
    "winogrande": 75.69,
    "average": 53.42
  },
  "IkariDev/Athena-tmp": {
    "arc": 59.22,
    "hellaswag": 82.13,
    "truthfulqa": 55.37,
    "mmlu": 58.87
  },
  "IkariDev/Athena-v1": {
    "arc": 60.07,
    "hellaswag": 82.64,
    "truthfulqa": 46.58,
    "mmlu": 55.61,
    "gsm8k": 4.93,
    "winogrande": 74.82,
    "average": 54.11
  },
  "IkariDev/Athena-v3": {
    "arc": 61.69,
    "hellaswag": 84.34,
    "truthfulqa": 51.26,
    "mmlu": 57.87,
    "gsm8k": 11.6,
    "winogrande": 75.77,
    "average": 57.09
  },
  "IkariDev/Athena-v4": {
    "arc": 62.54,
    "hellaswag": 84.19,
    "truthfulqa": 50.87,
    "mmlu": 57.33,
    "gsm8k": 11.98,
    "winogrande": 76.48,
    "average": 57.23
  },
  "Intel/neural-chat-7b-v3": {
    "arc": 67.15,
    "hellaswag": 83.29,
    "truthfulqa": 58.77,
    "winogrande": 78.06,
    "gsm8k": 1.21,
    "mmlu": 62.26,
    "average": 58.46
  },
  "Intel/neural-chat-7b-v3-1": {
    "arc": 65.7,
    "hellaswag": 83.54,
    "truthfulqa": 59.48,
    "winogrande": 78.61,
    "gsm8k": 20.09,
    "mmlu": 62.12,
    "average": 61.59
  },
  "Intel/neural-chat-7b-v3-2": {
    "arc": 67.49,
    "hellaswag": 83.92,
    "truthfulqa": 59.68,
    "winogrande": 79.95,
    "gsm8k": 55.12,
    "mmlu": 63.55,
    "average": 68.29
  },
  "Jiayi-Pan/Tiny-Vicuna-1B": {
    "arc": 33.45,
    "hellaswag": 55.92,
    "truthfulqa": 33.82,
    "winogrande": 58.41,
    "gsm8k": 1.52,
    "mmlu": 25.45,
    "average": 34.76
  },
  "JosephusCheung/Guanaco": {
    "arc": 50.17,
    "hellaswag": 72.69,
    "truthfulqa": 37.64,
    "mmlu": 30.3,
    "gsm8k": 0,
    "winogrande": 68.67,
    "average": 43.25
  },
  "JosephusCheung/LL7M": {
    "arc": 44.97,
    "hellaswag": 68.81,
    "truthfulqa": 41.39,
    "mmlu": 34.44,
    "gsm8k": 0.61,
    "winogrande": 64.09,
    "average": 42.39
  },
  "JosephusCheung/Pwen-14B-Chat-20_30": {
    "arc": 56.14,
    "hellaswag": 79.78,
    "truthfulqa": 47.02,
    "mmlu": 60.01,
    "gsm8k": 26.99,
    "winogrande": 76.48,
    "average": 57.74
  },
  "JosephusCheung/Pwen-7B-Chat-20_30": {
    "arc": 51.45,
    "hellaswag": 73.99,
    "truthfulqa": 47.01,
    "mmlu": 62.08,
    "gsm8k": 20.62,
    "winogrande": 68.43,
    "average": 53.93
  },
  "JosephusCheung/Pwen-VL-Chat-20_30": {
    "arc": 50.17,
    "hellaswag": 72.21,
    "truthfulqa": 42.52,
    "mmlu": 56.34,
    "gsm8k": 19.11,
    "winogrande": 68.35,
    "average": 51.45
  },
  "JosephusCheung/Qwen-LLaMAfied-7B-Chat": {
    "arc": 50.94,
    "hellaswag": 83.47,
    "truthfulqa": 46.09,
    "mmlu": 53.52,
    "gsm8k": 4.78,
    "winogrande": 73.16,
    "average": 51.99
  },
  "JosephusCheung/Qwen-VL-LLaMAfied-7B-Chat": {
    "arc": 47.35,
    "hellaswag": 69.97,
    "truthfulqa": 42.87,
    "mmlu": 44.12,
    "gsm8k": 0,
    "winogrande": 65.67,
    "average": 45
  },
  "JosephusCheung/Yee-34B-200K-Chat": {
    "arc": 65.61,
    "hellaswag": 84.33,
    "truthfulqa": 53.88,
    "winogrande": 79.79,
    "gsm8k": 34.8,
    "mmlu": 74.91,
    "average": 65.55
  },
  "Juniplayground/Mist_LLaMA-2-7B-1024_V3": {
    "arc": 51.37,
    "hellaswag": 77.74,
    "truthfulqa": 41.21,
    "mmlu": 41.34,
    "gsm8k": 4.85,
    "winogrande": 73.32,
    "average": 48.31
  },
  "KevinNi/mistral-class-bio-tutor": {
    "gsm8k": 0
  },
  "Kiddyz/testllm-c2": {
    "arc": 60.58,
    "hellaswag": 81.91,
    "truthfulqa": 49.87,
    "winogrande": 77.82,
    "gsm8k": 47.38,
    "mmlu": 61.2,
    "average": 63.13
  },
  "Kiddyz/testlm": {
    "arc": 53.5,
    "hellaswag": 75.8,
    "truthfulqa": 48.41,
    "mmlu": 51.21
  },
  "Kiddyz/testlm-1": {
    "arc": 53.5,
    "hellaswag": 75.8,
    "truthfulqa": 48.41,
    "mmlu": 51.21
  },
  "Kiddyz/testlm-1-1": {
    "arc": 53.5,
    "hellaswag": 75.8,
    "truthfulqa": 48.41,
    "mmlu": 51.21
  },
  "Kiddyz/testlm-3": {
    "arc": 53.58,
    "hellaswag": 78.48,
    "truthfulqa": 46.42,
    "mmlu": 51.77
  },
  "Kiddyz/testlm2": {
    "arc": 52.99,
    "hellaswag": 75.64,
    "truthfulqa": 48.68,
    "mmlu": 51.53
  },
  "KnutJaegersberg/CausalLM-Platypus-14B": {
    "arc": 56.91,
    "hellaswag": 80.06,
    "truthfulqa": 47.57,
    "winogrande": 76.01,
    "gsm8k": 57.24,
    "mmlu": 64.98,
    "average": 63.8
  },
  "KnutJaegersberg/Deacon-1b": {
    "arc": 32.42,
    "hellaswag": 58.62,
    "truthfulqa": 35.05,
    "winogrande": 59.59,
    "gsm8k": 0.68,
    "mmlu": 24.89,
    "average": 35.21
  },
  "KnutJaegersberg/Galactica-6.7B-EssayWriter": {
    "arc": 40.1,
    "hellaswag": 50.29,
    "truthfulqa": 40.27,
    "winogrande": 58.48,
    "gsm8k": 3.49,
    "mmlu": 33.88,
    "average": 37.75
  },
  "KnutJaegersberg/Galpaca-30b-MiniOrca": {
    "arc": 48.89,
    "hellaswag": 57.8,
    "truthfulqa": 41.1,
    "winogrande": 60.06,
    "gsm8k": 1.82,
    "mmlu": 43.72,
    "average": 42.23
  },
  "KnutJaegersberg/LLongMA-3b-LIMA": {
    "arc": 39.08,
    "hellaswag": 67.15,
    "truthfulqa": 34.71,
    "mmlu": 26.43,
    "gsm8k": 0.3,
    "winogrande": 63.38,
    "average": 38.51
  },
  "KnutJaegersberg/MistralInstructLongish": {
    "arc": 60.75,
    "hellaswag": 81.86,
    "truthfulqa": 40.55,
    "winogrande": 76.56,
    "gsm8k": 1.52,
    "mmlu": 60.49,
    "average": 53.62
  },
  "KnutJaegersberg/RWKV-4-PilePlus-169M-20230520-done-ctx4096": {
    "arc": 23.98,
    "hellaswag": 32.25,
    "truthfulqa": 42.29,
    "mmlu": 23.37,
    "gsm8k": 0.38,
    "winogrande": 49.17,
    "average": 28.57
  },
  "KnutJaegersberg/RWKV-4-PilePlus-1B5-20230520-2942-486Gtokens-ctx4096": {
    "arc": 30.63,
    "hellaswag": 52.63,
    "truthfulqa": 34.96,
    "mmlu": 25.04,
    "gsm8k": 0,
    "winogrande": 52.8,
    "average": 32.68
  },
  "KnutJaegersberg/RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098": {
    "arc": 26.02,
    "hellaswag": 40.39,
    "truthfulqa": 37.57,
    "mmlu": 24.45,
    "gsm8k": 0.23,
    "winogrande": 52.41,
    "average": 30.18
  },
  "KnutJaegersberg/RWKV-pileplus-1B5-evol_instruct_v2": {
    "arc": 31.83,
    "hellaswag": 55.51,
    "truthfulqa": 35.21,
    "mmlu": 25.13
  },
  "KnutJaegersberg/black_goo_recipe_a": {
    "arc": 38.14,
    "hellaswag": 66.56,
    "truthfulqa": 37.46,
    "mmlu": 25.75,
    "gsm8k": 0.53,
    "winogrande": 63.93,
    "average": 38.73
  },
  "KnutJaegersberg/black_goo_recipe_b": {
    "arc": 37.63,
    "hellaswag": 66.72,
    "truthfulqa": 37.09,
    "mmlu": 25.68,
    "gsm8k": 0.08,
    "winogrande": 63.77,
    "average": 38.5
  },
  "KnutJaegersberg/black_goo_recipe_c": {
    "arc": 38.74,
    "hellaswag": 66.83,
    "truthfulqa": 36.54,
    "mmlu": 26.57,
    "gsm8k": 0.68,
    "winogrande": 64.72,
    "average": 39.01
  },
  "KnutJaegersberg/black_goo_recipe_d": {
    "arc": 37.8,
    "hellaswag": 66.5,
    "truthfulqa": 36.46,
    "mmlu": 26.64,
    "gsm8k": 0.38,
    "winogrande": 63.61,
    "average": 38.57
  },
  "KnutJaegersberg/deacon-13b": {
    "arc": 57.85,
    "hellaswag": 82.63,
    "truthfulqa": 39.33,
    "mmlu": 55.25,
    "gsm8k": 10.39,
    "winogrande": 76.32,
    "average": 53.63
  },
  "KnutJaegersberg/deacon-3b": {
    "arc": 39.68,
    "hellaswag": 66.42,
    "truthfulqa": 36.07,
    "mmlu": 27.13,
    "gsm8k": 0.38,
    "winogrande": 64.64,
    "average": 39.05
  },
  "KnutJaegersberg/falcon-1b-t-sft": {
    "arc": 32.94,
    "hellaswag": 57.24,
    "truthfulqa": 38.49,
    "winogrande": 55.88,
    "gsm8k": 0.3,
    "mmlu": 25.26,
    "average": 35.02
  },
  "KnutJaegersberg/galactica-orca-wizardlm-1.3b": {
    "arc": 30.89,
    "hellaswag": 36.02,
    "truthfulqa": 41.27,
    "mmlu": 25.94
  },
  "KnutJaegersberg/gpt-2-xl-EvolInstruct": {
    "arc": 27.39,
    "hellaswag": 38.46,
    "truthfulqa": 42.76,
    "mmlu": 25.67,
    "gsm8k": 0.15,
    "winogrande": 53.51,
    "average": 31.32
  },
  "KnutJaegersberg/megatron-GPT-2-345m-EvolInstruct": {
    "arc": 24.06,
    "hellaswag": 35.12,
    "truthfulqa": 41.25,
    "mmlu": 24.48,
    "gsm8k": 0.38,
    "winogrande": 54.78,
    "average": 30.01
  },
  "KnutJaegersberg/megatron-gpt2-345m-evol_instruct_v2": {
    "arc": 26.37,
    "hellaswag": 38.39,
    "truthfulqa": 41.19,
    "mmlu": 23.6,
    "gsm8k": 0,
    "winogrande": 52.33,
    "average": 30.31
  },
  "KnutJaegersberg/openllama_3b_EvolInstruct_lora_merged": {
    "arc": 40.27,
    "hellaswag": 71.6,
    "truthfulqa": 34.78,
    "mmlu": 27.12,
    "gsm8k": 0.91,
    "winogrande": 67.01,
    "average": 40.28
  },
  "KnutJaegersberg/webMistral-7B": {
    "arc": 59.04,
    "hellaswag": 80.89,
    "truthfulqa": 39.71,
    "winogrande": 76.32,
    "gsm8k": 8.87,
    "mmlu": 59,
    "average": 53.97
  },
  "KoboldAI/GPT-J-6B-Adventure": {
    "arc": 37.12,
    "hellaswag": 61.26,
    "truthfulqa": 34.56,
    "mmlu": 25.94,
    "gsm8k": 0.83,
    "winogrande": 55.96,
    "average": 35.95
  },
  "KoboldAI/GPT-J-6B-Janeway": {
    "arc": 40.87,
    "hellaswag": 67.11,
    "truthfulqa": 35.74,
    "mmlu": 27.45,
    "gsm8k": 1.36,
    "winogrande": 64.72,
    "average": 39.54
  },
  "KoboldAI/GPT-J-6B-Shinen": {
    "arc": 39.85,
    "hellaswag": 67.06,
    "truthfulqa": 36.94,
    "mmlu": 27.72,
    "gsm8k": 1.97,
    "winogrande": 64.09,
    "average": 39.6
  },
  "KoboldAI/GPT-J-6B-Skein": {
    "arc": 42.58,
    "hellaswag": 68.69,
    "truthfulqa": 38.7,
    "mmlu": 24.88,
    "gsm8k": 1.44,
    "winogrande": 63.85,
    "average": 40.02
  },
  "KoboldAI/GPT-NeoX-20B-Erebus": {
    "arc": 45.48,
    "hellaswag": 72.79,
    "truthfulqa": 32.15,
    "mmlu": 26.77,
    "gsm8k": 2.27,
    "winogrande": 68.11,
    "average": 41.26
  },
  "KoboldAI/GPT-NeoX-20B-Skein": {
    "arc": 44.97,
    "hellaswag": 72.68,
    "truthfulqa": 31.64,
    "mmlu": 25.99,
    "gsm8k": 2.88,
    "winogrande": 68.43,
    "average": 41.1
  },
  "KoboldAI/LLaMA2-13B-Holomax": {
    "arc": 60.49,
    "hellaswag": 82.86,
    "truthfulqa": 42.97,
    "mmlu": 54.67,
    "gsm8k": 11.45,
    "winogrande": 74.66,
    "average": 54.52
  },
  "KoboldAI/LLaMA2-13B-Psyfighter2": {
    "arc": 60.07,
    "hellaswag": 84.02,
    "truthfulqa": 53,
    "winogrande": 74.35,
    "gsm8k": 1.44,
    "mmlu": 55.07,
    "average": 54.66
  },
  "KoboldAI/LLaMA2-13B-Tiefighter": {
    "arc": 59.9,
    "hellaswag": 84,
    "truthfulqa": 53.02,
    "winogrande": 74.51,
    "gsm8k": 0.68,
    "mmlu": 54.98,
    "average": 54.52
  },
  "KoboldAI/OPT-13B-Erebus": {
    "arc": 40.02,
    "hellaswag": 70.07,
    "truthfulqa": 34.93,
    "mmlu": 25.32,
    "gsm8k": 0.76,
    "winogrande": 66.54,
    "average": 39.61
  },
  "KoboldAI/OPT-13B-Nerybus-Mix": {
    "arc": 39.85,
    "hellaswag": 70.6,
    "truthfulqa": 34.02,
    "mmlu": 24.9,
    "gsm8k": 0.38,
    "winogrande": 67.88,
    "average": 39.6
  },
  "KoboldAI/OPT-13B-Nerys-v2": {
    "arc": 39.68,
    "hellaswag": 70.53,
    "truthfulqa": 33.5,
    "mmlu": 25.36,
    "gsm8k": 0.23,
    "winogrande": 67.88,
    "average": 39.53
  },
  "KoboldAI/OPT-2.7B-Erebus": {
    "arc": 34.39,
    "hellaswag": 60.91,
    "truthfulqa": 37.82,
    "mmlu": 26.7,
    "gsm8k": 0.3,
    "winogrande": 61.64,
    "average": 36.96
  },
  "KoboldAI/OPT-2.7B-Nerybus-Mix": {
    "arc": 33.7,
    "hellaswag": 61.21,
    "truthfulqa": 37.57,
    "mmlu": 26.6,
    "gsm8k": 0.15,
    "winogrande": 62.04,
    "average": 36.88
  },
  "KoboldAI/OPT-2.7B-Nerys-v2": {
    "arc": 33.28,
    "hellaswag": 61.23,
    "truthfulqa": 37.23,
    "mmlu": 26.44,
    "gsm8k": 0.3,
    "winogrande": 62.04,
    "average": 36.75
  },
  "KoboldAI/OPT-30B-Erebus": {
    "arc": 36.69,
    "hellaswag": 65.6,
    "truthfulqa": 38.76,
    "mmlu": 24.8,
    "gsm8k": 0.23,
    "winogrande": 65.11,
    "average": 38.53
  },
  "KoboldAI/OPT-350M-Erebus": {
    "arc": 23.81,
    "hellaswag": 34.35,
    "truthfulqa": 43.58,
    "mmlu": 26.23,
    "gsm8k": 0.3,
    "winogrande": 52.57,
    "average": 30.14
  },
  "KoboldAI/OPT-350M-Nerys-v2": {
    "arc": 23.63,
    "hellaswag": 35.49,
    "truthfulqa": 42.08,
    "mmlu": 25.91,
    "gsm8k": 0.68,
    "winogrande": 51.62,
    "average": 29.9
  },
  "KoboldAI/OPT-6.7B-Erebus": {
    "arc": 39.16,
    "hellaswag": 68.66,
    "truthfulqa": 35.12,
    "mmlu": 24.58,
    "gsm8k": 1.06,
    "winogrande": 65.98,
    "average": 39.09
  },
  "KoboldAI/OPT-6.7B-Nerybus-Mix": {
    "arc": 39.16,
    "hellaswag": 68.63,
    "truthfulqa": 34.84,
    "mmlu": 24.47,
    "gsm8k": 0.76,
    "winogrande": 65.11,
    "average": 38.83
  },
  "KoboldAI/OPT-6B-nerys-v2": {
    "arc": 38.4,
    "hellaswag": 68.57,
    "truthfulqa": 34.73,
    "mmlu": 24.34,
    "gsm8k": 0.68,
    "winogrande": 65.59,
    "average": 38.72
  },
  "KoboldAI/PPO_Pygway-6b-Mix": {
    "arc": 41.81,
    "hellaswag": 67.77,
    "truthfulqa": 32.5,
    "mmlu": 28.42,
    "gsm8k": 1.67,
    "winogrande": 64.4,
    "average": 39.43
  },
  "KoboldAI/fairseq-dense-1.3B": {
    "arc": 31.14,
    "hellaswag": 58.39,
    "truthfulqa": 37.43,
    "mmlu": 24.98,
    "gsm8k": 0,
    "winogrande": 59.04,
    "average": 35.16
  },
  "KoboldAI/fairseq-dense-125M": {
    "arc": 24.06,
    "hellaswag": 34.14,
    "truthfulqa": 43.72,
    "mmlu": 23.98,
    "gsm8k": 0,
    "winogrande": 50.59,
    "average": 29.42
  },
  "KoboldAI/fairseq-dense-13B": {
    "arc": 40.36,
    "hellaswag": 75.51,
    "truthfulqa": 32.83,
    "mmlu": 27.07,
    "gsm8k": 0,
    "winogrande": 67.96,
    "average": 40.62
  },
  "KoboldAI/fairseq-dense-2.7B": {
    "arc": 33.79,
    "hellaswag": 65.74,
    "truthfulqa": 34.57,
    "mmlu": 26.44,
    "gsm8k": 0,
    "winogrande": 63.93,
    "average": 37.41
  },
  "KoboldAI/fairseq-dense-355M": {
    "arc": 25.43,
    "hellaswag": 46.67,
    "truthfulqa": 39.19,
    "mmlu": 25.3,
    "gsm8k": 0,
    "winogrande": 52.88,
    "average": 31.58
  },
  "KoboldAI/fairseq-dense-6.7B": {
    "arc": 39.42,
    "hellaswag": 71.26,
    "truthfulqa": 32.73,
    "mmlu": 26.91,
    "gsm8k": 0,
    "winogrande": 65.27,
    "average": 39.26
  },
  "Korabbit/Llama-2-7b-chat-hf-afr-100step-flan": {
    "arc": 52.9,
    "hellaswag": 78.44,
    "truthfulqa": 45.67,
    "winogrande": 72.38,
    "gsm8k": 19.48,
    "mmlu": 48.4,
    "average": 52.88
  },
  "Korabbit/Llama-2-7b-chat-hf-afr-100step-v2": {
    "arc": 52.65,
    "hellaswag": 78.25,
    "truthfulqa": 45.18,
    "winogrande": 72.3,
    "gsm8k": 8.49,
    "mmlu": 48.47,
    "average": 50.89
  },
  "Korabbit/Llama-2-7b-chat-hf-afr-200step-flan": {
    "arc": 52.47,
    "hellaswag": 78.02,
    "truthfulqa": 45.47,
    "winogrande": 72.69,
    "gsm8k": 18.65,
    "mmlu": 48.42,
    "average": 52.62
  },
  "Korabbit/Llama-2-7b-chat-hf-afr-200step-merged": {
    "arc": 52.05,
    "hellaswag": 77.38,
    "truthfulqa": 44.6,
    "winogrande": 71.9,
    "gsm8k": 18.95,
    "mmlu": 48.65,
    "average": 52.26
  },
  "Korabbit/Llama-2-7b-chat-hf-afr-200step-v2": {
    "arc": 51.79,
    "hellaswag": 77.41,
    "truthfulqa": 43.69,
    "winogrande": 71.9,
    "gsm8k": 7.88,
    "mmlu": 48.55,
    "average": 50.2
  },
  "Kunhao/pile-7b": {
    "arc": 26.79,
    "hellaswag": 38.76,
    "truthfulqa": 42.41,
    "mmlu": 26.55
  },
  "Kunhao/pile-7b-250b-tokens": {
    "arc": 29.27,
    "hellaswag": 46.29,
    "truthfulqa": 40.49,
    "mmlu": 25.25,
    "gsm8k": 0.53,
    "winogrande": 52.8,
    "average": 32.44
  },
  "L-R/LLmRa-1.3B": {
    "arc": 32.68,
    "hellaswag": 58.77,
    "truthfulqa": 36.21,
    "mmlu": 23.23,
    "gsm8k": 0.08,
    "winogrande": 59.04,
    "average": 35
  },
  "L-R/LLmRa-1.3B_V2": {
    "arc": 30.46,
    "hellaswag": 53.03,
    "truthfulqa": 36.46,
    "winogrande": 59.27,
    "gsm8k": 0,
    "mmlu": 26.06,
    "average": 34.21
  },
  "L-R/LLmRa-2.7B": {
    "arc": 37.03,
    "hellaswag": 60.65,
    "truthfulqa": 35.23,
    "winogrande": 61.56,
    "gsm8k": 0.3,
    "mmlu": 25.58,
    "average": 36.73
  },
  "LLMs/AlpacaGPT4-7B-elina": {
    "arc": 55.03,
    "hellaswag": 78.79,
    "truthfulqa": 41.53,
    "mmlu": 37.5,
    "gsm8k": 4.55,
    "winogrande": 72.69,
    "average": 48.35
  },
  "LLMs/Stable-Vicuna-13B": {
    "arc": 53.41,
    "hellaswag": 78.57,
    "truthfulqa": 48.36,
    "mmlu": 50.37,
    "gsm8k": 0,
    "winogrande": 56.99,
    "average": 47.95
  },
  "LLMs/WizardLM-13B-V1.0": {
    "arc": 57.25,
    "hellaswag": 80.88,
    "truthfulqa": 50.55,
    "mmlu": 52.92,
    "gsm8k": 14.1,
    "winogrande": 74.11,
    "average": 54.97
  },
  "LLMs/WizardLM-30B-V1.0": {
    "arc": 62.54,
    "hellaswag": 83.27,
    "truthfulqa": 52.49,
    "mmlu": 59.05,
    "gsm8k": 21.83,
    "winogrande": 77.51,
    "average": 59.45
  },
  "LMFlow/Robin-7b-v2": {
    "arc": 48.81,
    "hellaswag": 74.48,
    "truthfulqa": 42.33,
    "mmlu": 39.27
  },
  "LMFlow/Robin-v2": {
    "arc": 48.81,
    "hellaswag": 74.48,
    "truthfulqa": 42.33,
    "mmlu": 39.27
  },
  "LTC-AI-Labs/Guanaco-Vicuna-7B-L2": {
    "arc": 53.24,
    "hellaswag": 78.89,
    "truthfulqa": 42.75,
    "mmlu": 46.77,
    "gsm8k": 7.96,
    "winogrande": 75.37,
    "average": 50.83
  },
  "LTC-AI-Labs/L2-7b-Base-WVG-Uncensored": {
    "arc": 53.24,
    "hellaswag": 79.13,
    "truthfulqa": 42.59,
    "mmlu": 46.65,
    "gsm8k": 7.05,
    "winogrande": 75.14,
    "average": 50.63
  },
  "LTC-AI-Labs/L2-7b-Base-test-WVG": {
    "arc": 54.27,
    "hellaswag": 77.81,
    "truthfulqa": 46.28,
    "mmlu": 51.07,
    "gsm8k": 6.97,
    "winogrande": 73.56,
    "average": 51.66
  },
  "LTC-AI-Labs/L2-7b-Beluga-WVG-Test": {
    "arc": 53.75,
    "hellaswag": 78.38,
    "truthfulqa": 45.76,
    "mmlu": 51.57,
    "gsm8k": 7.88,
    "winogrande": 74.9,
    "average": 52.04
  },
  "LTC-AI-Labs/L2-7b-Hermes-WVG-Test": {
    "arc": 54.95,
    "hellaswag": 78.48,
    "truthfulqa": 45.72,
    "mmlu": 48.36,
    "gsm8k": 5.84,
    "winogrande": 74.74,
    "average": 51.35
  },
  "LTC-AI-Labs/L2-7b-Synthia-WVG-Test": {
    "arc": 55.97,
    "hellaswag": 77.89,
    "truthfulqa": 44.11,
    "mmlu": 49.48,
    "gsm8k": 5.91,
    "winogrande": 74.11,
    "average": 51.25
  },
  "Lajonbot/Llama-2-13b-hf-instruct-pl-lora_unload": {
    "arc": 59.47,
    "hellaswag": 82.16,
    "truthfulqa": 41.45,
    "mmlu": 54.83,
    "gsm8k": 11.9,
    "winogrande": 76.24,
    "average": 54.34
  },
  "Lajonbot/Llama-2-7b-chat-hf-instruct-pl-lora_unload": {
    "arc": 52.99,
    "hellaswag": 77.49,
    "truthfulqa": 42.61,
    "mmlu": 47.12,
    "gsm8k": 6.9,
    "winogrande": 72.06,
    "average": 49.86
  },
  "Lajonbot/WizardLM-13B-V1.2-PL-lora_unload": {
    "arc": 58.53,
    "hellaswag": 81.1,
    "truthfulqa": 46.18,
    "mmlu": 55.15,
    "gsm8k": 11.14,
    "winogrande": 71.03,
    "average": 53.86
  },
  "Lajonbot/tableBeluga-7B-instruct-pl-lora_unload": {
    "arc": 56.23,
    "hellaswag": 79.12,
    "truthfulqa": 50.19,
    "mmlu": 52.7,
    "gsm8k": 7.81,
    "winogrande": 75.22,
    "average": 53.54
  },
  "Lajonbot/vicuna-13b-v1.3-PL-lora_unload": {
    "arc": 54.86,
    "hellaswag": 80.41,
    "truthfulqa": 49.62,
    "mmlu": 52.2,
    "gsm8k": 9.02,
    "winogrande": 76.09,
    "average": 53.7
  },
  "Lajonbot/vicuna-7b-v1.5-PL-lora_unload": {
    "arc": 53.5,
    "hellaswag": 76.74,
    "truthfulqa": 49.68,
    "mmlu": 49.69,
    "gsm8k": 7.2,
    "winogrande": 71.98,
    "average": 51.47
  },
  "Lazycuber/Janemalion-6B": {
    "arc": 42.41,
    "hellaswag": 68.4,
    "truthfulqa": 34.59,
    "mmlu": 28.28
  },
  "Lazycuber/L2-7b-Base-Guanaco-Uncensored": {
    "arc": 52.22,
    "hellaswag": 79.08,
    "truthfulqa": 42.97,
    "mmlu": 46.63,
    "gsm8k": 7.28,
    "winogrande": 74.51,
    "average": 50.45
  },
  "Lazycuber/L2-7b-Guanaco-Random-Test": {
    "arc": 50.6,
    "hellaswag": 77.21,
    "truthfulqa": 42.33,
    "mmlu": 47.66
  },
  "Lazycuber/L2-7b-Guanaco-Uncensored": {
    "arc": 50.6,
    "hellaswag": 76.99,
    "truthfulqa": 43.42,
    "mmlu": 48.93,
    "gsm8k": 7.96,
    "winogrande": 75.37,
    "average": 50.54
  },
  "Lazycuber/L2-7b-Orca-WVG-Test": {
    "arc": 54.86,
    "hellaswag": 78.25,
    "truthfulqa": 43.68,
    "mmlu": 51.13,
    "gsm8k": 8.04,
    "winogrande": 74.35,
    "average": 51.72
  },
  "Lazycuber/pyg-instruct-wizardlm": {
    "arc": 40.96,
    "hellaswag": 66.71,
    "truthfulqa": 31.93,
    "mmlu": 26.33,
    "gsm8k": 1.59,
    "winogrande": 63.69,
    "average": 38.54
  },
  "LeoLM/leo-hessianai-13b": {
    "arc": 57.25,
    "hellaswag": 81.94,
    "truthfulqa": 38.03,
    "mmlu": 53.65,
    "gsm8k": 8.95,
    "winogrande": 76.09,
    "average": 52.65
  },
  "LeoLM/leo-hessianai-7b": {
    "arc": 51.96,
    "hellaswag": 75.84,
    "truthfulqa": 37.94,
    "mmlu": 42.85,
    "gsm8k": 5.61,
    "winogrande": 72.14,
    "average": 47.72
  },
  "LeoLM/leo-hessianai-7b-chat": {
    "arc": 52.56,
    "hellaswag": 77.61,
    "truthfulqa": 44.89,
    "mmlu": 45.58,
    "gsm8k": 5.16,
    "winogrande": 69.93,
    "average": 49.29
  },
  "LeoLM/leo-hessianai-7b-chat-bilingual": {
    "arc": 51.02,
    "hellaswag": 76.03,
    "truthfulqa": 47.16,
    "mmlu": 44.68,
    "gsm8k": 2.73,
    "winogrande": 70.72,
    "average": 48.72
  },
  "LinkSoul/Chinese-Llama-2-7b": {
    "arc": 52.99,
    "hellaswag": 75.64,
    "truthfulqa": 48.94,
    "mmlu": 50.74,
    "gsm8k": 14.48,
    "winogrande": 72.77,
    "average": 52.59
  },
  "Linly-AI/Chinese-LLaMA-2-13B-hf": {
    "arc": 33.62,
    "hellaswag": 39.59,
    "truthfulqa": 45.71,
    "mmlu": 33.97
  },
  "Linly-AI/Chinese-LLaMA-2-7B-hf": {
    "arc": 48.04,
    "hellaswag": 73.25,
    "truthfulqa": 39.92,
    "mmlu": 35.04,
    "gsm8k": 6.22,
    "winogrande": 70.17,
    "average": 45.44
  },
  "Locutusque/TinyMistral-248m": {
    "arc": 22.87,
    "hellaswag": 28.02,
    "truthfulqa": 42.52,
    "winogrande": 49.8,
    "gsm8k": 0,
    "mmlu": 23.15,
    "average": 27.73
  },
  "Locutusque/gpt2-conversational-or-qa": {
    "arc": 21.42,
    "hellaswag": 27.61,
    "truthfulqa": 47.31,
    "mmlu": 26.51,
    "gsm8k": 0.08,
    "winogrande": 51.14,
    "average": 29.01
  },
  "Locutusque/gpt2-large-conversational": {
    "arc": 26.96,
    "hellaswag": 44.98,
    "truthfulqa": 39.6,
    "mmlu": 26.33,
    "gsm8k": 0.08,
    "winogrande": 56.04,
    "average": 32.33
  },
  "LoupGarou/WizardCoder-Guanaco-15B-V1.0": {
    "arc": 30.46,
    "hellaswag": 45.59,
    "truthfulqa": 46.39,
    "mmlu": 26.79,
    "gsm8k": 1.44,
    "winogrande": 53.12,
    "average": 33.97
  },
  "LoupGarou/WizardCoder-Guanaco-15B-V1.1": {
    "arc": 32.59,
    "hellaswag": 45.42,
    "truthfulqa": 42.33,
    "mmlu": 25.88,
    "gsm8k": 2.88,
    "winogrande": 56.04,
    "average": 34.19
  },
  "MBZUAI/LaMini-GPT-1.5B": {
    "arc": 31.4,
    "hellaswag": 48.38,
    "truthfulqa": 42.47,
    "mmlu": 29.92,
    "gsm8k": 0,
    "winogrande": 55.88,
    "average": 34.68
  },
  "MBZUAI/LaMini-GPT-124M": {
    "arc": 24.32,
    "hellaswag": 30.82,
    "truthfulqa": 36.57,
    "mmlu": 24.99,
    "gsm8k": 0,
    "winogrande": 51.38,
    "average": 28.01
  },
  "MBZUAI/LaMini-GPT-774M": {
    "arc": 27.65,
    "hellaswag": 43.81,
    "truthfulqa": 40.26,
    "mmlu": 26.3,
    "gsm8k": 0,
    "winogrande": 56.59,
    "average": 32.44
  },
  "MBZUAI/lamini-cerebras-1.3b": {
    "arc": 26.88,
    "hellaswag": 37.96,
    "truthfulqa": 36.45,
    "mmlu": 28.43,
    "gsm8k": 0,
    "winogrande": 50.59,
    "average": 30.05
  },
  "MBZUAI/lamini-cerebras-111m": {
    "arc": 22.1,
    "hellaswag": 27.12,
    "truthfulqa": 43.79,
    "mmlu": 25.51,
    "gsm8k": 0,
    "winogrande": 51.22,
    "average": 28.29
  },
  "MBZUAI/lamini-cerebras-256m": {
    "arc": 21.76,
    "hellaswag": 28.7,
    "truthfulqa": 41.81,
    "mmlu": 26.66,
    "gsm8k": 0,
    "winogrande": 52.01,
    "average": 28.49
  },
  "MBZUAI/lamini-cerebras-590m": {
    "arc": 24.32,
    "hellaswag": 31.58,
    "truthfulqa": 40.72,
    "mmlu": 25.57,
    "gsm8k": 0.15,
    "winogrande": 47.91,
    "average": 28.38
  },
  "MBZUAI/lamini-neo-1.3b": {
    "arc": 32.76,
    "hellaswag": 49.13,
    "truthfulqa": 41.05,
    "mmlu": 28.79,
    "gsm8k": 0.15,
    "winogrande": 56.51,
    "average": 34.73
  },
  "MBZUAI/lamini-neo-125m": {
    "arc": 24.57,
    "hellaswag": 30.22,
    "truthfulqa": 42.85,
    "mmlu": 26.74,
    "gsm8k": 0,
    "winogrande": 52.25,
    "average": 29.44
  },
  "MayaPH/FinOPT-Franklin": {
    "arc": 27.73,
    "hellaswag": 24.91,
    "truthfulqa": 52.4,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 50.51,
    "average": 29.78
  },
  "MayaPH/FinOPT-Lincoln": {
    "arc": 26.71,
    "hellaswag": 25.6,
    "truthfulqa": 50.59,
    "mmlu": 23,
    "gsm8k": 0,
    "winogrande": 49.72,
    "average": 29.27
  },
  "MayaPH/FinOPT-Washington": {
    "arc": 25.17,
    "hellaswag": 26.25,
    "truthfulqa": 45.8,
    "mmlu": 24.83,
    "gsm8k": 0,
    "winogrande": 51.07,
    "average": 28.85
  },
  "MayaPH/GodziLLa-30B": {
    "arc": 61.52,
    "hellaswag": 82.13,
    "truthfulqa": 55.91,
    "mmlu": 54.21,
    "gsm8k": 0.38,
    "winogrande": 76.16,
    "average": 55.05
  },
  "MayaPH/GodziLLa-30B-instruct": {
    "arc": 29.01,
    "hellaswag": 26.49,
    "truthfulqa": 48.84,
    "mmlu": 24.9
  },
  "MayaPH/GodziLLa-30B-plus": {
    "arc": 29.18,
    "hellaswag": 25.35,
    "truthfulqa": 48.56,
    "mmlu": 24.23
  },
  "MayaPH/GodziLLa2-70B": {
    "arc": 71.42,
    "hellaswag": 87.53,
    "truthfulqa": 61.54,
    "mmlu": 69.88,
    "gsm8k": 43.21,
    "winogrande": 83.19,
    "average": 69.46
  },
  "MayaPH/opt-flan-iml-6.7b": {
    "arc": 30.12,
    "hellaswag": 58.82,
    "truthfulqa": 36.74,
    "mmlu": 25.12,
    "gsm8k": 0,
    "winogrande": 64.25,
    "average": 35.84
  },
  "Medilora/medilora-mistral-7b": {
    "arc": 61.69,
    "hellaswag": 83.13,
    "truthfulqa": 49.91,
    "winogrande": 77.66,
    "gsm8k": 51.86,
    "mmlu": 62.22,
    "average": 64.41
  },
  "Medilora/medilora-qwen-14b": {
    "arc": 56.66,
    "hellaswag": 79.08,
    "truthfulqa": 47.75,
    "winogrande": 74.9,
    "gsm8k": 58.61,
    "mmlu": 65.86,
    "average": 63.81
  },
  "MetaIX/GPT4-X-Alpasta-30b": {
    "arc": 63.05,
    "hellaswag": 83.56,
    "truthfulqa": 51.52,
    "mmlu": 57.71,
    "gsm8k": 30.48,
    "winogrande": 78.22,
    "average": 60.76
  },
  "Mikael110/llama-2-13b-guanaco-fp16": {
    "arc": 60.92,
    "hellaswag": 83.18,
    "truthfulqa": 44,
    "mmlu": 54.58,
    "gsm8k": 11.6,
    "winogrande": 74.9,
    "average": 54.86
  },
  "Mikael110/llama-2-7b-guanaco-fp16": {
    "arc": 54.86,
    "hellaswag": 79.65,
    "truthfulqa": 43.83,
    "mmlu": 46.38,
    "gsm8k": 6.29,
    "winogrande": 75.22,
    "average": 51.04
  },
  "Mikivis/gpt2-large-lora-sft": {
    "arc": 26.79,
    "hellaswag": 44.15,
    "truthfulqa": 39.06,
    "mmlu": 25.82,
    "gsm8k": 0,
    "winogrande": 55.09,
    "average": 31.82
  },
  "Mikivis/gpt2-large-lora-sft1": {
    "arc": 24.66,
    "hellaswag": 42.67,
    "truthfulqa": 39.37,
    "mmlu": 24.89,
    "gsm8k": 0,
    "winogrande": 54.46,
    "average": 31.01
  },
  "Mikivis/gpt2-large-lora-sft2": {
    "arc": 26.62,
    "hellaswag": 42.68,
    "truthfulqa": 40.31,
    "mmlu": 24.72,
    "gsm8k": 0,
    "winogrande": 53.67,
    "average": 31.33
  },
  "Mikivis/gpt2-large-lora-stf4": {
    "arc": 26.88,
    "hellaswag": 42.17,
    "truthfulqa": 40.84,
    "mmlu": 25.53,
    "gsm8k": 0,
    "winogrande": 53.59,
    "average": 31.5
  },
  "Mikivis/xuanxuan": {
    "arc": 23.46,
    "hellaswag": 31.12,
    "truthfulqa": 35.97,
    "mmlu": 26.27,
    "gsm8k": 0,
    "winogrande": 50.43,
    "average": 27.88
  },
  "Minirecord/Mini_DPO_test02": {
    "arc": 59.73,
    "hellaswag": 83.89,
    "truthfulqa": 48.47,
    "winogrande": 78.37,
    "gsm8k": 35.03,
    "mmlu": 61.9,
    "average": 61.23
  },
  "Mohammed-Altaf/Medical-ChatBot": {
    "arc": 30.55,
    "hellaswag": 38.63,
    "truthfulqa": 41.25,
    "winogrande": 55.41,
    "gsm8k": 0.99,
    "mmlu": 25.98,
    "average": 32.14
  },
  "Monero/Manticore-13b-Chat-Pyg-Guanaco": {
    "arc": 56.83,
    "hellaswag": 82.3,
    "truthfulqa": 52.29,
    "mmlu": 47.81,
    "gsm8k": 8.64,
    "winogrande": 73.95,
    "average": 53.64
  },
  "Monero/WizardLM-13b-OpenAssistant-Uncensored": {
    "arc": 48.55,
    "hellaswag": 76.03,
    "truthfulqa": 49.4,
    "mmlu": 43.15,
    "gsm8k": 3.03,
    "winogrande": 69.77,
    "average": 48.32
  },
  "Monero/WizardLM-30B-Uncensored-Guanaco-SuperCOT-30b": {
    "arc": 55.55,
    "hellaswag": 80.37,
    "truthfulqa": 51.3,
    "mmlu": 54.01,
    "gsm8k": 3.41,
    "winogrande": 72.38,
    "average": 52.84
  },
  "Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b": {
    "arc": 59.64,
    "hellaswag": 79.9,
    "truthfulqa": 55.95,
    "mmlu": 54.42,
    "gsm8k": 5.53,
    "winogrande": 70.88,
    "average": 54.39
  },
  "MrNJK/gpt2-xl-sft": {
    "arc": 30.03,
    "hellaswag": 49.17,
    "truthfulqa": 38.78,
    "mmlu": 25.56,
    "gsm8k": 0.76,
    "winogrande": 55.56,
    "average": 33.31
  },
  "NEU-HAI/mental-alpaca": {
    "arc": 28.58,
    "hellaswag": 26.02,
    "truthfulqa": 48.61,
    "winogrande": 48.38,
    "gsm8k": 0,
    "mmlu": 27.04,
    "average": 29.77
  },
  "NYTK/PULI-GPTrio": {
    "arc": 30.72,
    "hellaswag": 53.49,
    "truthfulqa": 39.03,
    "mmlu": 24.73,
    "gsm8k": 0.76,
    "winogrande": 57.77,
    "average": 34.42
  },
  "NbAiLab/nb-gpt-j-6B-alpaca": {
    "arc": 36.86,
    "hellaswag": 57.46,
    "truthfulqa": 38,
    "mmlu": 27.53
  },
  "Neko-Institute-of-Science/metharme-7b": {
    "arc": 53.67,
    "hellaswag": 78.62,
    "truthfulqa": 39.16,
    "mmlu": 35.91,
    "gsm8k": 5,
    "winogrande": 72.53,
    "average": 47.48
  },
  "Neko-Institute-of-Science/pygmalion-7b": {
    "arc": 51.37,
    "hellaswag": 77.81,
    "truthfulqa": 34.54,
    "mmlu": 35.68,
    "gsm8k": 4.62,
    "winogrande": 72.22,
    "average": 46.04
  },
  "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus": {
    "arc": 58.87,
    "hellaswag": 82.14,
    "truthfulqa": 42.84,
    "mmlu": 54.98,
    "gsm8k": 9.4,
    "winogrande": 77.11,
    "average": 54.22
  },
  "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-8bit-att": {
    "arc": 57.51,
    "hellaswag": 82.14,
    "truthfulqa": 42.21,
    "mmlu": 54.56,
    "gsm8k": 9.55,
    "winogrande": 76.56,
    "average": 53.76
  },
  "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu": {
    "arc": 57.51,
    "hellaswag": 82.49,
    "truthfulqa": 43.81,
    "mmlu": 54.83,
    "gsm8k": 10.46,
    "winogrande": 77.27,
    "average": 54.4
  },
  "NeverSleep/Mistral-11B-SynthIAirOmniMix": {
    "arc": 62.46,
    "hellaswag": 83.13,
    "truthfulqa": 55.69,
    "winogrande": 76.4,
    "gsm8k": 11.9,
    "mmlu": 63.47,
    "average": 58.84
  },
  "NewstaR/Koss-7B-chat": {
    "arc": 53.67,
    "hellaswag": 78.79,
    "truthfulqa": 43.97,
    "mmlu": 46.72,
    "gsm8k": 7.35,
    "winogrande": 71.74,
    "average": 50.37
  },
  "NewstaR/Morningstar-13b-hf": {
    "arc": 59.04,
    "hellaswag": 81.93,
    "truthfulqa": 44.12,
    "mmlu": 54.63,
    "gsm8k": 15.24,
    "winogrande": 74.51,
    "average": 54.91
  },
  "NewstaR/Starlight-13B": {
    "arc": 59.3,
    "hellaswag": 82.15,
    "truthfulqa": 37.39,
    "mmlu": 55.67,
    "gsm8k": 10.84,
    "winogrande": 76.64,
    "average": 53.67
  },
  "NewstaR/Starlight-7B": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.8,
    "gsm8k": 7.13,
    "winogrande": 74.03,
    "average": 49.73
  },
  "NickyNicky/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3": {
    "arc": 60.58,
    "hellaswag": 83.34,
    "truthfulqa": 48.21,
    "winogrande": 77.74,
    "gsm8k": 36.16,
    "mmlu": 61.53,
    "average": 61.26
  },
  "NoIdeaLand/test-2048-1500ck": {
    "arc": 36.69,
    "hellaswag": 62.56,
    "truthfulqa": 40.96,
    "mmlu": 25.72
  },
  "NoIdeaLand/test-3k-mx": {
    "arc": 38.05,
    "hellaswag": 66.43,
    "truthfulqa": 40.93,
    "mmlu": 25.39
  },
  "NoIdeaLand/test-4k-fn": {
    "arc": 39.93,
    "hellaswag": 68.13,
    "truthfulqa": 38.86,
    "mmlu": 27.44
  },
  "NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEcons": {
    "arc": 59.39,
    "hellaswag": 83.19,
    "truthfulqa": 40.56,
    "mmlu": 55.15,
    "gsm8k": 7.81,
    "winogrande": 74.03,
    "average": 53.36
  },
  "NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEconsE4": {
    "arc": 59.9,
    "hellaswag": 84.11,
    "truthfulqa": 41.94,
    "mmlu": 54.67,
    "gsm8k": 7.81,
    "winogrande": 74.03,
    "average": 53.74
  },
  "NobodyExistsOnTheInternet/PuffedConvo13bLoraE4": {
    "arc": 59.64,
    "hellaswag": 84.37,
    "truthfulqa": 39.82,
    "mmlu": 53.72,
    "gsm8k": 8.79,
    "winogrande": 75.22,
    "average": 53.59
  },
  "NobodyExistsOnTheInternet/PuffedLIMA13bQLORA": {
    "arc": 59.9,
    "hellaswag": 84.39,
    "truthfulqa": 39.9,
    "mmlu": 53.68,
    "gsm8k": 8.72,
    "winogrande": 75.22,
    "average": 53.64
  },
  "Norquinal/Mistral-7B-claude-instruct": {
    "arc": 63.23,
    "hellaswag": 84.99,
    "truthfulqa": 47.47,
    "winogrande": 78.14,
    "gsm8k": 17.97,
    "mmlu": 63.84,
    "average": 59.27
  },
  "Norquinal/llama-2-7b-claude-chat": {
    "arc": 54.44,
    "hellaswag": 80.66,
    "truthfulqa": 41.39,
    "mmlu": 46.74,
    "gsm8k": 7.73,
    "winogrande": 74.9,
    "average": 50.98
  },
  "Norquinal/llama-2-7b-claude-chat-rp": {
    "arc": 54.95,
    "hellaswag": 80.05,
    "truthfulqa": 43.47,
    "mmlu": 47.03,
    "gsm8k": 7.28,
    "winogrande": 74.74,
    "average": 51.25
  },
  "NousResearch/Capybara-7B": {
    "arc": 55.2,
    "hellaswag": 80.76,
    "truthfulqa": 51.07,
    "mmlu": 48.8,
    "gsm8k": 6.9,
    "winogrande": 73.4,
    "average": 52.69
  },
  "NousResearch/CodeLlama-13b-hf": {
    "arc": 40.87,
    "hellaswag": 63.35,
    "truthfulqa": 43.79,
    "mmlu": 32.81,
    "gsm8k": 12.13,
    "winogrande": 67.17,
    "average": 43.35
  },
  "NousResearch/CodeLlama-34b-hf": {
    "arc": 37.54,
    "hellaswag": 31.84,
    "truthfulqa": 38.89,
    "mmlu": 37.2,
    "gsm8k": 21.61,
    "winogrande": 73.4,
    "average": 40.08
  },
  "NousResearch/CodeLlama-7b-hf": {
    "arc": 39.85,
    "hellaswag": 59.58,
    "truthfulqa": 38.62,
    "mmlu": 30.47,
    "gsm8k": 5.46,
    "winogrande": 64.88,
    "average": 39.81
  },
  "NousResearch/Nous-Capybara-7B": {
    "arc": 55.29,
    "hellaswag": 80.73,
    "truthfulqa": 51.13,
    "mmlu": 48.72,
    "gsm8k": 6.97,
    "winogrande": 73.32,
    "average": 52.69
  },
  "NousResearch/Nous-Hermes-13b": {
    "arc": 56.57,
    "hellaswag": 82.11,
    "truthfulqa": 51.5,
    "mmlu": 50.44,
    "gsm8k": 8.34,
    "winogrande": 75.3,
    "average": 54.04
  },
  "NousResearch/Nous-Hermes-Llama2-13b": {
    "arc": 61.26,
    "hellaswag": 83.26,
    "truthfulqa": 50.41,
    "mmlu": 55.04,
    "gsm8k": 10.08,
    "winogrande": 75.45,
    "average": 55.92
  },
  "NousResearch/Nous-Hermes-Llama2-70b": {
    "arc": 67.58,
    "hellaswag": 86.81,
    "truthfulqa": 55.04,
    "mmlu": 69.72
  },
  "NousResearch/Nous-Hermes-llama-2-7b": {
    "arc": 55.12,
    "hellaswag": 78.94,
    "truthfulqa": 49.01,
    "mmlu": 48.34,
    "gsm8k": 5.76,
    "winogrande": 74.03,
    "average": 51.87
  },
  "NousResearch/Nous-Puffin-70B": {
    "arc": 67.41,
    "hellaswag": 87.37,
    "truthfulqa": 46.77,
    "mmlu": 69.77,
    "gsm8k": 34.27,
    "winogrande": 83.9,
    "average": 64.92
  },
  "NousResearch/Redmond-Puffin-13B": {
    "arc": 60.49,
    "hellaswag": 83.21,
    "truthfulqa": 42.08,
    "mmlu": 54.95,
    "gsm8k": 11.22,
    "winogrande": 76.48,
    "average": 54.74
  },
  "NousResearch/Yarn-Mistral-7b-128k": {
    "arc": 59.64,
    "hellaswag": 82.5,
    "truthfulqa": 41.78,
    "winogrande": 76.95,
    "gsm8k": 32.6,
    "mmlu": 63.02,
    "average": 59.42
  },
  "NousResearch/Yarn-Mistral-7b-64k": {
    "arc": 59.9,
    "hellaswag": 82.51,
    "truthfulqa": 41.86,
    "winogrande": 77.27,
    "gsm8k": 33.28,
    "mmlu": 62.96,
    "average": 59.63
  },
  "NucleusAI/nucleus-22B-token-500B": {
    "arc": 40.7,
    "hellaswag": 69.39,
    "truthfulqa": 39.16,
    "winogrande": 67.64,
    "gsm8k": 0.99,
    "mmlu": 30.11,
    "average": 41.33
  },
  "NurtureAI/Orca-2-13B-16k": {
    "arc": 53.67,
    "hellaswag": 69.48,
    "truthfulqa": 45.3,
    "winogrande": 60.06,
    "gsm8k": 1.82,
    "mmlu": 41.02,
    "average": 45.22
  },
  "NurtureAI/Orca-2-7B-16k": {
    "arc": 50.6,
    "hellaswag": 63.89,
    "truthfulqa": 45.37,
    "winogrande": 54.22,
    "gsm8k": 1.52,
    "mmlu": 36.68,
    "average": 42.05
  },
  "NurtureAI/Starling-LM-11B-alpha-v1": {
    "arc": 62.2,
    "hellaswag": 83.24,
    "truthfulqa": 45.7,
    "winogrande": 80.51,
    "gsm8k": 50.95,
    "mmlu": 64.03,
    "average": 64.44
  },
  "NurtureAI/openchat_3.5-16k": {
    "arc": 63.31,
    "hellaswag": 83.58,
    "truthfulqa": 43.47,
    "winogrande": 80.11,
    "gsm8k": 21.83,
    "mmlu": 61.9,
    "average": 59.03
  },
  "Open-Orca/LlongOrca-13B-16k": {
    "arc": 62.46,
    "hellaswag": 82.75,
    "truthfulqa": 50.11,
    "mmlu": 55.54,
    "gsm8k": 12.28,
    "winogrande": 76.4,
    "average": 56.59
  },
  "Open-Orca/LlongOrca-7B-16k": {
    "arc": 57.51,
    "hellaswag": 79.44,
    "truthfulqa": 49.84,
    "mmlu": 49.35,
    "gsm8k": 7.51,
    "winogrande": 74.51,
    "average": 53.03
  },
  "Open-Orca/Mistral-7B-OpenOrca": {
    "arc": 64.08,
    "hellaswag": 83.99,
    "truthfulqa": 53.05,
    "mmlu": 62.24,
    "gsm8k": 19.94,
    "winogrande": 77.74,
    "average": 60.17
  },
  "Open-Orca/Mistral-7B-SlimOrca": {
    "arc": 62.54,
    "hellaswag": 83.86,
    "truthfulqa": 54.23,
    "mmlu": 62.77,
    "gsm8k": 21.38,
    "winogrande": 77.43,
    "average": 60.37
  },
  "Open-Orca/OpenOrca-Platypus2-13B": {
    "arc": 61.52,
    "hellaswag": 82.27,
    "truthfulqa": 50.11,
    "mmlu": 58.85,
    "gsm8k": 9.02,
    "winogrande": 76.24,
    "average": 56.34
  },
  "Open-Orca/OpenOrca-Preview1-13B": {
    "arc": 54.95,
    "hellaswag": 78.19,
    "truthfulqa": 49.05,
    "mmlu": 50.12,
    "gsm8k": 4.93,
    "winogrande": 71.03,
    "average": 51.38
  },
  "Open-Orca/OpenOrcaxOpenChat-Preview2-13B": {
    "arc": 62.71,
    "hellaswag": 81.99,
    "truthfulqa": 47.45,
    "mmlu": 57.51,
    "gsm8k": 15.09,
    "winogrande": 77.82,
    "average": 57.09
  },
  "OpenAssistant/codellama-13b-oasst-sft-v10": {
    "arc": 47.35,
    "hellaswag": 68.44,
    "truthfulqa": 43.23,
    "mmlu": 45.62,
    "gsm8k": 13.19,
    "winogrande": 67.8,
    "average": 47.61
  },
  "OpenAssistant/galactica-6.7b-finetuned": {
    "arc": 41.55,
    "hellaswag": 51.01,
    "truthfulqa": 41.65,
    "mmlu": 38.03,
    "gsm8k": 3.11,
    "winogrande": 57.7,
    "average": 38.84
  },
  "OpenAssistant/llama2-13b-megacode2-oasst": {
    "arc": 60.67,
    "hellaswag": 81.93,
    "truthfulqa": 47.85,
    "mmlu": 57.38,
    "gsm8k": 15.54,
    "winogrande": 76.16,
    "average": 56.59
  },
  "OpenAssistant/llama2-13b-orca-8k-3319": {
    "arc": 60.75,
    "hellaswag": 81.91,
    "truthfulqa": 42.64,
    "mmlu": 57.06,
    "gsm8k": 10.99,
    "winogrande": 77.19,
    "average": 55.09
  },
  "OpenAssistant/llama2-13b-orca-v2-8k-3166": {
    "arc": 56.48,
    "hellaswag": 80.27,
    "truthfulqa": 46.76,
    "mmlu": 55.42
  },
  "OpenAssistant/llama2-70b-oasst-sft-v10": {
    "arc": 67.06,
    "hellaswag": 86.38,
    "truthfulqa": 56.45,
    "mmlu": 67.7,
    "gsm8k": 27.22,
    "winogrande": 82,
    "average": 64.47
  },
  "OpenAssistant/oasst-sft-1-pythia-12b": {
    "arc": 46.42,
    "hellaswag": 70,
    "truthfulqa": 39.19,
    "mmlu": 26.19,
    "gsm8k": 0.61,
    "winogrande": 62.19,
    "average": 40.77
  },
  "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5": {
    "arc": 45.73,
    "hellaswag": 68.59,
    "truthfulqa": 37.81,
    "mmlu": 26.82,
    "gsm8k": 3.03,
    "winogrande": 65.9,
    "average": 41.31
  },
  "OpenAssistant/pythia-12b-pre-v8-12.5k-steps": {
    "arc": 41.47,
    "hellaswag": 68.8,
    "truthfulqa": 36.82,
    "mmlu": 26.58,
    "gsm8k": 7.66,
    "winogrande": 65.27,
    "average": 41.1
  },
  "OpenAssistant/pythia-12b-sft-v8-2.5k-steps": {
    "arc": 42.32,
    "hellaswag": 70.15,
    "truthfulqa": 36.75,
    "mmlu": 27.36,
    "gsm8k": 9.55,
    "winogrande": 65.67,
    "average": 41.97
  },
  "OpenAssistant/pythia-12b-sft-v8-7k-steps": {
    "arc": 44.03,
    "hellaswag": 70.28,
    "truthfulqa": 36.53,
    "mmlu": 26.55,
    "gsm8k": 10.61,
    "winogrande": 65.27,
    "average": 42.21
  },
  "OpenAssistant/pythia-12b-sft-v8-rlhf-2k-steps": {
    "arc": 43.43,
    "hellaswag": 70.08,
    "truthfulqa": 36.06,
    "mmlu": 26.12,
    "gsm8k": 9.55,
    "winogrande": 64.64,
    "average": 41.65
  },
  "OpenAssistant/stablelm-7b-sft-v7-epoch-3": {
    "arc": 36.01,
    "hellaswag": 55.81,
    "truthfulqa": 37.02,
    "mmlu": 25.01,
    "gsm8k": 0.38,
    "winogrande": 54.85,
    "average": 34.85
  },
  "OpenBuddy/openbuddy-atom-13b-v9-bf16": {
    "arc": 51.19,
    "hellaswag": 75.99,
    "truthfulqa": 48.66,
    "mmlu": 49.33,
    "gsm8k": 15.39,
    "winogrande": 73.32,
    "average": 52.31
  },
  "OpenBuddy/openbuddy-codellama2-34b-v11.1-bf16": {
    "arc": 50,
    "hellaswag": 71.19,
    "truthfulqa": 53.01,
    "mmlu": 55.71,
    "gsm8k": 34.57,
    "winogrande": 70.8,
    "average": 55.88
  },
  "OpenBuddy/openbuddy-falcon-180b-v12-preview0": {
    "arc": 63.4,
    "hellaswag": 84.6,
    "truthfulqa": 54.14,
    "mmlu": 58.97,
    "gsm8k": 41.24,
    "winogrande": 82.08,
    "average": 64.07
  },
  "OpenBuddy/openbuddy-falcon-180b-v13-preview0": {
    "arc": 65.1,
    "hellaswag": 86.19,
    "truthfulqa": 54.97,
    "mmlu": 64.6,
    "gsm8k": 41.62,
    "winogrande": 82.64,
    "average": 65.85
  },
  "OpenBuddy/openbuddy-llama-65b-v8-bf16": {
    "arc": 62.8,
    "hellaswag": 83.6,
    "truthfulqa": 55.09,
    "mmlu": 62.01,
    "gsm8k": 43.37,
    "winogrande": 79.95,
    "average": 64.47
  },
  "OpenBuddy/openbuddy-llama2-13b-v11-bf16": {
    "arc": 52.99,
    "hellaswag": 75.38,
    "truthfulqa": 47.94,
    "mmlu": 51.36,
    "gsm8k": 18.88,
    "winogrande": 71.03,
    "average": 52.93
  },
  "OpenBuddy/openbuddy-llama2-13b-v11.1-bf16": {
    "arc": 51.62,
    "hellaswag": 76.23,
    "truthfulqa": 49.7,
    "mmlu": 56.45,
    "gsm8k": 24.34,
    "winogrande": 73.48,
    "average": 55.3
  },
  "OpenBuddy/openbuddy-llama2-13b-v8.1-fp16": {
    "arc": 55.97,
    "hellaswag": 79.79,
    "truthfulqa": 51.16,
    "mmlu": 54.95,
    "gsm8k": 30.33,
    "winogrande": 74.35,
    "average": 57.76
  },
  "OpenBuddy/openbuddy-llama2-34b-v11.1-bf16": {
    "arc": 50,
    "hellaswag": 71.19,
    "truthfulqa": 53.01,
    "mmlu": 55.71,
    "gsm8k": 34.57,
    "winogrande": 70.8,
    "average": 55.88
  },
  "OpenBuddy/openbuddy-llama2-70b-v10.1-bf16": {
    "arc": 61.86,
    "hellaswag": 83.13,
    "truthfulqa": 56.18,
    "mmlu": 67.41,
    "gsm8k": 60.27,
    "winogrande": 80.11,
    "average": 68.16
  },
  "OpenBuddy/openbuddy-mistral-7b-v13": {
    "arc": 52.3,
    "hellaswag": 75.09,
    "truthfulqa": 50.81,
    "mmlu": 56.34,
    "gsm8k": 14.71,
    "winogrande": 71.74,
    "average": 53.5
  },
  "OpenBuddy/openbuddy-mistral-7b-v13-base": {
    "arc": 52.9,
    "hellaswag": 76.12,
    "truthfulqa": 52.82,
    "mmlu": 57.54,
    "gsm8k": 1.21,
    "winogrande": 71.35,
    "average": 51.99
  },
  "OpenBuddy/openbuddy-mistral-7b-v13.1": {
    "arc": 52.56,
    "hellaswag": 75.73,
    "truthfulqa": 50.44,
    "mmlu": 56.68,
    "gsm8k": 8.72,
    "winogrande": 71.59,
    "average": 52.62
  },
  "OpenBuddy/openbuddy-openllama-13b-v7-fp16": {
    "arc": 47.61,
    "hellaswag": 72.24,
    "truthfulqa": 48.73,
    "mmlu": 47.74,
    "gsm8k": 9.86,
    "winogrande": 69.69,
    "average": 49.31
  },
  "OpenBuddy/openbuddy-openllama-3b-v10-bf16": {
    "arc": 36.26,
    "hellaswag": 58.38,
    "truthfulqa": 42.04,
    "mmlu": 23.89,
    "gsm8k": 0.99,
    "winogrande": 59.67,
    "average": 36.87
  },
  "OpenBuddy/openbuddy-openllama-7b-v12-bf16": {
    "arc": 42.06,
    "hellaswag": 62.01,
    "truthfulqa": 45.18,
    "mmlu": 46.53,
    "gsm8k": 10.84,
    "winogrande": 65.04,
    "average": 45.28
  },
  "OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16": {
    "arc": 62.46,
    "hellaswag": 82.3,
    "truthfulqa": 52.57,
    "mmlu": 58.15,
    "gsm8k": 31.61,
    "winogrande": 77.51,
    "average": 60.77
  },
  "OpenLemur/lemur-70b-chat-v1": {
    "arc": 66.98,
    "hellaswag": 85.73,
    "truthfulqa": 56.58,
    "mmlu": 65.99,
    "gsm8k": 35.33,
    "winogrande": 81.69,
    "average": 65.38
  },
  "OpenLemur/lemur-70b-v1": {
    "arc": 64.33,
    "hellaswag": 85.72,
    "truthfulqa": 44.78,
    "mmlu": 65.85,
    "gsm8k": 28.73,
    "winogrande": 83.03,
    "average": 62.07
  },
  "OptimalScale/robin-13b-v2-delta": {
    "arc": 56.57,
    "hellaswag": 80.35,
    "truthfulqa": 50.54,
    "mmlu": 48.39
  },
  "OptimalScale/robin-65b-v2-delta": {
    "arc": 28.5,
    "hellaswag": 25.97,
    "truthfulqa": 48.61,
    "mmlu": 23.12
  },
  "OptimalScale/robin-7b-v2-delta": {
    "arc": 49.15,
    "hellaswag": 74.43,
    "truthfulqa": 42.27,
    "mmlu": 38.96
  },
  "OrionStarAI/OrionStar-Yi-34B-Chat-Llama": {
    "arc": 64.93,
    "hellaswag": 84.34,
    "truthfulqa": 53.35,
    "winogrande": 78.85,
    "gsm8k": 53.9,
    "mmlu": 73.67,
    "average": 68.17
  },
  "PSanni/Deer-3b": {
    "arc": 38.48,
    "hellaswag": 57.41,
    "truthfulqa": 39.98,
    "mmlu": 25.64,
    "gsm8k": 0.3,
    "winogrande": 57.46,
    "average": 36.55
  },
  "PY007/TinyLlama-1.1B-Chat-v0.1": {
    "arc": 32,
    "hellaswag": 54.21,
    "truthfulqa": 39.03,
    "mmlu": 26.71,
    "gsm8k": 0.53,
    "winogrande": 54.93,
    "average": 34.57
  },
  "PY007/TinyLlama-1.1B-Chat-v0.3": {
    "arc": 35.07,
    "hellaswag": 57.7,
    "truthfulqa": 36.67,
    "mmlu": 25.53,
    "gsm8k": 0.68,
    "winogrande": 57.7,
    "average": 35.56
  },
  "PY007/TinyLlama-1.1B-intermediate-step-240k-503b": {
    "arc": 29.27,
    "hellaswag": 49.71,
    "truthfulqa": 40.17,
    "mmlu": 26.26,
    "gsm8k": 0.3,
    "winogrande": 56.59,
    "average": 33.72
  },
  "PY007/TinyLlama-1.1B-intermediate-step-480k-1T": {
    "arc": 30.89,
    "hellaswag": 52.97,
    "truthfulqa": 39.55,
    "mmlu": 25,
    "gsm8k": 0.53,
    "winogrande": 57.3,
    "average": 34.37
  },
  "PY007/TinyLlama-1.1B-step-50K-105b": {
    "arc": 25.85,
    "hellaswag": 44.1,
    "truthfulqa": 39.51,
    "mmlu": 26.78,
    "gsm8k": 0.53,
    "winogrande": 54.38,
    "average": 31.86
  },
  "Panchovix/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k": {
    "arc": 25.43,
    "hellaswag": 31.97,
    "truthfulqa": 47,
    "mmlu": 23.43,
    "gsm8k": 0,
    "winogrande": 51.07,
    "average": 29.82
  },
  "Panchovix/airoboros-33b-gpt4-1.2-SuperHOT-8k": {
    "arc": 24.66,
    "hellaswag": 31.23,
    "truthfulqa": 47.44,
    "mmlu": 23.13,
    "gsm8k": 0,
    "winogrande": 50.43,
    "average": 29.48
  },
  "PeanutJar/LLaMa-2-PeanutButter_v10-7B": {
    "arc": 55.29,
    "hellaswag": 81.69,
    "truthfulqa": 43.78,
    "mmlu": 46.97,
    "gsm8k": 5.91,
    "winogrande": 70.88,
    "average": 50.75
  },
  "PeanutJar/LLaMa-2-PeanutButter_v14-7B": {
    "arc": 54.18,
    "hellaswag": 80.38,
    "truthfulqa": 44.68,
    "mmlu": 45.97
  },
  "PeanutJar/LLaMa-2-PeanutButter_v18_A-7B": {
    "arc": 53.16,
    "hellaswag": 78.11,
    "truthfulqa": 40.37,
    "mmlu": 45.54,
    "gsm8k": 7.2,
    "winogrande": 74.9,
    "average": 49.88
  },
  "PeanutJar/LLaMa-2-PeanutButter_v18_B-7B": {
    "arc": 54.61,
    "hellaswag": 81,
    "truthfulqa": 41.93,
    "mmlu": 47.07,
    "gsm8k": 6.52,
    "winogrande": 74.51,
    "average": 50.94
  },
  "PeanutJar/LLaMa-2-PeanutButter_v19_R8-7B": {
    "arc": 53.33,
    "hellaswag": 78.72,
    "truthfulqa": 39.61,
    "mmlu": 46.48
  },
  "PeanutJar/LLaMa-2-PeanutButter_v37_SFT-R1-DPO-R2-7B": {
    "arc": 54.1,
    "hellaswag": 79.1,
    "truthfulqa": 42,
    "mmlu": 47.32
  },
  "PeanutJar/LLaMa-2-PeanutButter_v4-7B": {
    "arc": 54.86,
    "hellaswag": 80.78,
    "truthfulqa": 42.31,
    "mmlu": 47.24
  },
  "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.0-7B": {
    "arc": 62.2,
    "hellaswag": 84.1,
    "truthfulqa": 46.94,
    "mmlu": 64.14,
    "gsm8k": 18.5,
    "winogrande": 78.69,
    "average": 59.1
  },
  "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.2-7B": {
    "arc": 61.77,
    "hellaswag": 84.11,
    "truthfulqa": 45.92,
    "winogrande": 78.37,
    "gsm8k": 17.44,
    "mmlu": 64.38,
    "average": 58.67
  },
  "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA": {
    "arc": 61.26,
    "hellaswag": 84.52,
    "truthfulqa": 45.75,
    "winogrande": 78.61,
    "gsm8k": 18.12,
    "mmlu": 63.63,
    "average": 58.65
  },
  "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA": {
    "arc": 60.75,
    "hellaswag": 84.24,
    "truthfulqa": 44.94,
    "winogrande": 78.69,
    "gsm8k": 17.13,
    "mmlu": 63.66,
    "average": 58.23
  },
  "Phind/Phind-CodeLlama-34B-Python-v1": {
    "arc": 24.66,
    "hellaswag": 29.77,
    "truthfulqa": 45.27,
    "mmlu": 27.95,
    "gsm8k": 21.53,
    "winogrande": 68.82,
    "average": 36.33
  },
  "Phind/Phind-CodeLlama-34B-v1": {
    "arc": 27.13,
    "hellaswag": 28.28,
    "truthfulqa": 44.94,
    "mmlu": 28.94,
    "gsm8k": 20.47,
    "winogrande": 72.61,
    "average": 37.06
  },
  "Phind/Phind-CodeLlama-34B-v2": {
    "arc": 24.57,
    "hellaswag": 27.6,
    "truthfulqa": 48.37,
    "mmlu": 25.76,
    "gsm8k": 23.2,
    "winogrande": 71.82,
    "average": 36.89
  },
  "Pirr/pythia-13b-deduped-green_devil": {
    "arc": 42.32,
    "hellaswag": 68.89,
    "truthfulqa": 35.56,
    "mmlu": 26.01,
    "gsm8k": 2.12,
    "winogrande": 66.93,
    "average": 40.31
  },
  "PocketDoc/Dans-AdventurousWinds-7b": {
    "arc": 61.01,
    "hellaswag": 83.47,
    "truthfulqa": 42.65,
    "mmlu": 63.69,
    "gsm8k": 15.69,
    "winogrande": 78.22,
    "average": 57.46
  },
  "PocketDoc/Dans-AdventurousWinds-Mk2-7b": {
    "arc": 58.19,
    "hellaswag": 83.48,
    "truthfulqa": 43.56,
    "winogrande": 76.32,
    "gsm8k": 14.94,
    "mmlu": 61.8,
    "average": 56.38
  },
  "PocketDoc/Dans-CreepingSenseOfDoom": {
    "arc": 53.33,
    "hellaswag": 78.9,
    "truthfulqa": 37.84,
    "mmlu": 48.09,
    "gsm8k": 0,
    "winogrande": 73.32,
    "average": 48.58
  },
  "PocketDoc/Dans-MysteryModel-13b": {
    "arc": 57,
    "hellaswag": 80.35,
    "truthfulqa": 45,
    "mmlu": 52.06,
    "gsm8k": 0,
    "winogrande": 74.82,
    "average": 51.54
  },
  "PocketDoc/Dans-PersonalityEngine-13b": {
    "arc": 58.45,
    "hellaswag": 82.3,
    "truthfulqa": 41.12,
    "mmlu": 47.58,
    "gsm8k": 9.33,
    "winogrande": 77.51,
    "average": 52.72
  },
  "PocketDoc/Dans-PersonalityEngine-30b": {
    "arc": 63.48,
    "hellaswag": 84.37,
    "truthfulqa": 46.98,
    "mmlu": 58.99,
    "gsm8k": 15.54,
    "winogrande": 80.98,
    "average": 58.39
  },
  "PocketDoc/Dans-PileOfSets-Mk1-llama-13b-merged": {
    "arc": 58.79,
    "hellaswag": 81.79,
    "truthfulqa": 41.24,
    "mmlu": 48.12,
    "gsm8k": 8.49,
    "winogrande": 76.16,
    "average": 52.43
  },
  "PocketDoc/Dans-RetroRodeo-13b": {
    "arc": 53.84,
    "hellaswag": 79.63,
    "truthfulqa": 38.73,
    "mmlu": 48.93,
    "gsm8k": 0,
    "winogrande": 73.8,
    "average": 49.16
  },
  "PocketDoc/Dans-TotSirocco-7b": {
    "arc": 62.03,
    "hellaswag": 84.23,
    "truthfulqa": 46.49,
    "mmlu": 64.19,
    "gsm8k": 13.19,
    "winogrande": 79.48,
    "average": 58.27
  },
  "PulsarAI/2x-LoRA-Assemble-13B": {
    "arc": 63.65,
    "hellaswag": 83.47,
    "truthfulqa": 55.94,
    "mmlu": 59.82,
    "gsm8k": 9.25,
    "winogrande": 76.48,
    "average": 58.1
  },
  "PulsarAI/2x-LoRA-Assemble-Nova-13B": {
    "arc": 62.63,
    "hellaswag": 83.24,
    "truthfulqa": 51.88,
    "mmlu": 58.64,
    "gsm8k": 10.24,
    "winogrande": 76.95,
    "average": 57.26
  },
  "PulsarAI/2x-LoRA-Assemble-Platypus2-13B": {
    "arc": 60.58,
    "hellaswag": 82.56,
    "truthfulqa": 54.77,
    "mmlu": 58.25,
    "gsm8k": 0.91,
    "winogrande": 74.9,
    "average": 55.33
  },
  "PulsarAI/Chat-AYB-Nova-13B": {
    "arc": 62.97,
    "hellaswag": 84.28,
    "truthfulqa": 51.28,
    "mmlu": 58.58,
    "gsm8k": 12.36,
    "winogrande": 77.58,
    "average": 57.84
  },
  "PulsarAI/Chat-AYB-Platypus2-13B": {
    "arc": 60.49,
    "hellaswag": 84.03,
    "truthfulqa": 54.52,
    "mmlu": 57.83,
    "gsm8k": 2.96,
    "winogrande": 75.77,
    "average": 55.93
  },
  "PulsarAI/CollectiveCognition-v1.1-Nebula-7B": {
    "arc": 58.11,
    "hellaswag": 82.39,
    "truthfulqa": 53.53,
    "winogrande": 73.72,
    "gsm8k": 9.55,
    "mmlu": 57.03,
    "average": 55.72
  },
  "PulsarAI/EnsembleV5-Nova-13B": {
    "arc": 62.71,
    "hellaswag": 82.55,
    "truthfulqa": 49.86,
    "mmlu": 56.79,
    "gsm8k": 10.77,
    "winogrande": 76.24,
    "average": 56.49
  },
  "PulsarAI/GenAI-Nova-13B": {
    "arc": 62.29,
    "hellaswag": 83.27,
    "truthfulqa": 51.79,
    "mmlu": 59.47,
    "gsm8k": 7.73,
    "winogrande": 77.35,
    "average": 56.98
  },
  "PulsarAI/Nebula-7B": {
    "arc": 59.3,
    "hellaswag": 83.46,
    "truthfulqa": 45.56,
    "mmlu": 57,
    "gsm8k": 14.86,
    "winogrande": 76.4,
    "average": 56.1
  },
  "PulsarAI/Nebula-v2-7B": {
    "arc": 58.7,
    "hellaswag": 83.06,
    "truthfulqa": 46.72,
    "winogrande": 75.14,
    "gsm8k": 31.69,
    "mmlu": 57.61,
    "average": 58.82
  },
  "PulsarAI/SlimOpenOrca-Mistral-7B-v2": {
    "arc": 62.88,
    "hellaswag": 83.41,
    "truthfulqa": 56.65,
    "winogrande": 77.58,
    "gsm8k": 18.95,
    "mmlu": 62.05,
    "average": 60.25
  },
  "PygmalionAI/metharme-1.3b": {
    "arc": 34.39,
    "hellaswag": 55.94,
    "truthfulqa": 37.68,
    "mmlu": 25.07,
    "gsm8k": 0.76,
    "winogrande": 56.43,
    "average": 35.04
  },
  "PygmalionAI/mythalion-13b": {
    "arc": 61.26,
    "hellaswag": 83.81,
    "truthfulqa": 46.56,
    "mmlu": 56.53,
    "gsm8k": 13.27,
    "winogrande": 77.43,
    "average": 56.48
  },
  "PygmalionAI/pygmalion-1.3b": {
    "arc": 28.07,
    "hellaswag": 46.96,
    "truthfulqa": 37.64,
    "mmlu": 24.12,
    "gsm8k": 0,
    "winogrande": 50.04,
    "average": 31.14
  },
  "PygmalionAI/pygmalion-2-13b": {
    "arc": 60.32,
    "hellaswag": 82.37,
    "truthfulqa": 42.22,
    "mmlu": 56.02,
    "gsm8k": 11.75,
    "winogrande": 78.06,
    "average": 55.12
  },
  "PygmalionAI/pygmalion-2-7b": {
    "arc": 54.01,
    "hellaswag": 78.23,
    "truthfulqa": 43.78,
    "mmlu": 49.11,
    "gsm8k": 6.37,
    "winogrande": 75.14,
    "average": 51.11
  },
  "PygmalionAI/pygmalion-2.7b": {
    "arc": 32.76,
    "hellaswag": 54.13,
    "truthfulqa": 37.17,
    "mmlu": 23.28,
    "gsm8k": 0,
    "winogrande": 56.51,
    "average": 33.98
  },
  "PygmalionAI/pygmalion-350m": {
    "arc": 25,
    "hellaswag": 37.8,
    "truthfulqa": 40.41,
    "mmlu": 25.68,
    "gsm8k": 0.53,
    "winogrande": 50.28,
    "average": 29.95
  },
  "PygmalionAI/pygmalion-6b": {
    "arc": 40.53,
    "hellaswag": 67.47,
    "truthfulqa": 32.53,
    "mmlu": 25.73,
    "gsm8k": 2.05,
    "winogrande": 62.51,
    "average": 38.47
  },
  "Q-bert/Bumblebee-7B": {
    "arc": 63.4,
    "hellaswag": 84.16,
    "truthfulqa": 50.96,
    "winogrande": 78.22,
    "gsm8k": 65.66,
    "mmlu": 64,
    "average": 67.73
  },
  "Q-bert/Optimus-7B": {
    "arc": 65.44,
    "hellaswag": 85.41,
    "truthfulqa": 55.79,
    "winogrande": 78.77,
    "gsm8k": 65.5,
    "mmlu": 63.61,
    "average": 69.09
  },
  "Quake24/easyTermsSummerizer": {
    "arc": 25.77,
    "hellaswag": 25.81,
    "truthfulqa": 47.69,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 50.75,
    "average": 28.86
  },
  "Qwen/Qwen-14B": {
    "arc": 58.28,
    "hellaswag": 83.99,
    "truthfulqa": 49.43,
    "mmlu": 67.7,
    "gsm8k": 58.98,
    "winogrande": 76.8,
    "average": 65.86
  },
  "Qwen/Qwen-7B": {
    "arc": 51.37,
    "hellaswag": 78.47,
    "truthfulqa": 47.79,
    "mmlu": 59.84,
    "gsm8k": 44.96,
    "winogrande": 72.69,
    "average": 59.19
  },
  "RWKV/rwkv-4-14b-pile": {
    "arc": 44.45,
    "hellaswag": 71.07,
    "truthfulqa": 32.04,
    "mmlu": 26.12,
    "gsm8k": 0.38,
    "winogrande": 65.43,
    "average": 39.92
  },
  "RWKV/rwkv-4-169m-pile": {
    "arc": 23.63,
    "hellaswag": 31.74,
    "truthfulqa": 41.92,
    "mmlu": 23.18,
    "gsm8k": 0.45,
    "winogrande": 50.91,
    "average": 28.64
  },
  "RWKV/rwkv-4-1b5-pile": {
    "arc": 31.83,
    "hellaswag": 52.25,
    "truthfulqa": 35.8,
    "mmlu": 25.77,
    "gsm8k": 0,
    "winogrande": 53.83,
    "average": 33.25
  },
  "RWKV/rwkv-4-3b-pile": {
    "arc": 36.01,
    "hellaswag": 59.66,
    "truthfulqa": 32.14,
    "mmlu": 24.67,
    "gsm8k": 0.68,
    "winogrande": 58.33,
    "average": 35.25
  },
  "RWKV/rwkv-4-430m-pile": {
    "arc": 26.71,
    "hellaswag": 40.01,
    "truthfulqa": 39.58,
    "mmlu": 24.85,
    "gsm8k": 0.38,
    "winogrande": 51.14,
    "average": 30.45
  },
  "RWKV/rwkv-4-7b-pile": {
    "arc": 39.68,
    "hellaswag": 66.31,
    "truthfulqa": 33.65,
    "mmlu": 24.96,
    "gsm8k": 0.76,
    "winogrande": 62.35,
    "average": 37.95
  },
  "RWKV/rwkv-raven-14b": {
    "arc": 44.62,
    "hellaswag": 71.25,
    "truthfulqa": 41.93,
    "mmlu": 25.92,
    "gsm8k": 2.12,
    "winogrande": 66.69,
    "average": 42.09
  },
  "RWKV/rwkv-raven-1b5": {
    "arc": 31.83,
    "hellaswag": 52.6,
    "truthfulqa": 37.09,
    "mmlu": 25.96,
    "gsm8k": 0,
    "winogrande": 53.91,
    "average": 33.57
  },
  "RWKV/rwkv-raven-3b": {
    "arc": 36.69,
    "hellaswag": 59.78,
    "truthfulqa": 35.6,
    "mmlu": 24.87,
    "gsm8k": 0.45,
    "winogrande": 57.46,
    "average": 35.81
  },
  "RWKV/rwkv-raven-7b": {
    "arc": 39.42,
    "hellaswag": 66.48,
    "truthfulqa": 38.56,
    "mmlu": 23.64,
    "gsm8k": 0.3,
    "winogrande": 62.9,
    "average": 38.55
  },
  "Rachneet/gpt2-xl-alpaca": {
    "arc": 26.79,
    "hellaswag": 43.85,
    "truthfulqa": 39.4,
    "mmlu": 26.31,
    "gsm8k": 0,
    "winogrande": 56.91,
    "average": 32.21
  },
  "Rallio67/3B-redpajama-conditional-alpha": {
    "arc": 36.26,
    "hellaswag": 61.9,
    "truthfulqa": 36.31,
    "mmlu": 25.42,
    "gsm8k": 0.61,
    "winogrande": 60.77,
    "average": 36.88
  },
  "Rallio67/7B-redpajama-conditional-alpha": {
    "arc": 42.58,
    "hellaswag": 69.91,
    "truthfulqa": 36.42,
    "mmlu": 26.53,
    "gsm8k": 0.76,
    "winogrande": 67.17,
    "average": 40.56
  },
  "Rardilit/Panther_v1": {
    "gsm8k": 0,
    "winogrande": 49.57
  },
  "Riiid/sheep-duck-llama-2": {
    "arc": 72.27,
    "hellaswag": 87.78,
    "truthfulqa": 63.8,
    "mmlu": 70.81
  },
  "Riiid/sheep-duck-llama-2-13b": {
    "arc": 63.14,
    "hellaswag": 84.52,
    "truthfulqa": 55.48,
    "mmlu": 59.89,
    "gsm8k": 9.17,
    "winogrande": 76.95,
    "average": 58.19
  },
  "Riiid/sheep-duck-llama-2-70b-v1.1": {
    "arc": 73.04,
    "hellaswag": 87.81,
    "truthfulqa": 64.58,
    "mmlu": 70.84
  },
  "RobbeD/OpenLlama-Platypus-3B": {
    "arc": 41.21,
    "hellaswag": 71.67,
    "truthfulqa": 36.45,
    "mmlu": 29.86,
    "gsm8k": 1.14,
    "winogrande": 65.98,
    "average": 41.05
  },
  "RobbeD/Orca-Platypus-3B": {
    "arc": 43.09,
    "hellaswag": 65.33,
    "truthfulqa": 41.93,
    "mmlu": 26.75
  },
  "RoversX/llama-2-7b-hf-small-shards-Samantha-V1-SFT": {
    "arc": 53.16,
    "hellaswag": 77.71,
    "truthfulqa": 45.28,
    "mmlu": 43.47,
    "gsm8k": 6.37,
    "winogrande": 73.8,
    "average": 49.97
  },
  "S4sch/zephyr-neural-chat-frankenmerge11b": {
    "arc": 61.52,
    "hellaswag": 84.09,
    "truthfulqa": 60.63,
    "winogrande": 76.24,
    "gsm8k": 7.43,
    "mmlu": 61.51,
    "average": 58.57
  },
  "SLAM-group/NewHope": {
    "arc": 60.92,
    "hellaswag": 84,
    "truthfulqa": 44.87,
    "mmlu": 55.72
  },
  "SUSTech/SUS-Chat-34B": {
    "arc": 66.3,
    "hellaswag": 83.91,
    "truthfulqa": 57.04,
    "winogrande": 83.5,
    "gsm8k": 72.18,
    "mmlu": 76.41,
    "average": 73.22
  },
  "Salesforce/codegen-16B-nl": {
    "arc": 46.76,
    "hellaswag": 71.87,
    "truthfulqa": 33.95,
    "mmlu": 32.35,
    "gsm8k": 2.65,
    "winogrande": 67.96,
    "average": 42.59
  },
  "Salesforce/codegen-6B-multi": {
    "arc": 27.22,
    "hellaswag": 41.11,
    "truthfulqa": 45.65,
    "mmlu": 25.71,
    "gsm8k": 0.99,
    "winogrande": 53.91,
    "average": 32.43
  },
  "Salesforce/codegen-6B-nl": {
    "arc": 42.32,
    "hellaswag": 68.59,
    "truthfulqa": 34.47,
    "mmlu": 25.93,
    "gsm8k": 2.2,
    "winogrande": 66.46,
    "average": 39.99
  },
  "Sao10K/BrainDerp": {
    "arc": 60.75,
    "hellaswag": 82.1,
    "truthfulqa": 56.9,
    "mmlu": 58.81,
    "gsm8k": 8.26,
    "winogrande": 75.85,
    "average": 57.11
  },
  "Sao10K/BrainDerp2": {
    "arc": 60.92,
    "hellaswag": 81.94,
    "truthfulqa": 57.19,
    "mmlu": 58.9,
    "gsm8k": 9.02,
    "winogrande": 75.93,
    "average": 57.32
  },
  "Sao10K/BrainDerp3": {
    "arc": 60.92,
    "hellaswag": 82.1,
    "truthfulqa": 57.18,
    "mmlu": 58.91,
    "gsm8k": 8.04,
    "winogrande": 75.61,
    "average": 57.13
  },
  "Sao10K/Chat-Stheno-L2-13B": {
    "arc": 58.45,
    "hellaswag": 80.96,
    "truthfulqa": 43.31,
    "mmlu": 54.8,
    "gsm8k": 14.78,
    "winogrande": 75.37,
    "average": 54.61
  },
  "Sao10K/Euryale-1.3-L2-70B": {
    "arc": 70.82,
    "hellaswag": 87.92,
    "truthfulqa": 59.85,
    "mmlu": 70.39,
    "gsm8k": 34.19,
    "winogrande": 82.79,
    "average": 67.66
  },
  "Sao10K/Euryale-L2-70B": {
    "arc": 68.94,
    "hellaswag": 87.07,
    "truthfulqa": 54.49,
    "mmlu": 68.84,
    "gsm8k": 26.54,
    "winogrande": 82.08,
    "average": 64.66
  },
  "Sao10K/Medusa-1.1-L2-7B": {
    "arc": 56.48,
    "hellaswag": 78.57,
    "truthfulqa": 47.7,
    "mmlu": 51.56,
    "gsm8k": 1.44,
    "winogrande": 75.06,
    "average": 51.8
  },
  "Sao10K/Medusa-13b": {
    "arc": 58.19,
    "hellaswag": 81.35,
    "truthfulqa": 51.24,
    "mmlu": 57.39,
    "gsm8k": 6.82,
    "winogrande": 73.32,
    "average": 54.72
  },
  "Sao10K/Mythical-Destroyer-L2-13B": {
    "arc": 58.7,
    "hellaswag": 82,
    "truthfulqa": 56.35,
    "mmlu": 57.66,
    "gsm8k": 8.95,
    "winogrande": 74.66,
    "average": 56.39
  },
  "Sao10K/Mythical-Destroyer-V2-L2-13B": {
    "arc": 59.3,
    "hellaswag": 82.66,
    "truthfulqa": 57.09,
    "mmlu": 57.39,
    "gsm8k": 0,
    "winogrande": 74.74,
    "average": 55.2
  },
  "Sao10K/Stheno-1.1-L2-13B": {
    "arc": 60.75,
    "hellaswag": 83.64,
    "truthfulqa": 50.3,
    "mmlu": 56.39,
    "gsm8k": 7.96,
    "winogrande": 75.22,
    "average": 55.71
  },
  "Sao10K/Stheno-1.2-L2-13B": {
    "arc": 60.75,
    "hellaswag": 83.67,
    "truthfulqa": 50.32,
    "mmlu": 56.27,
    "gsm8k": 10.92,
    "winogrande": 74.98,
    "average": 56.15
  },
  "Sao10K/Stheno-1.3-L2-13B": {
    "arc": 56.83,
    "hellaswag": 81.7,
    "truthfulqa": 50.23,
    "mmlu": 52.79,
    "gsm8k": 0.23,
    "winogrande": 71.11,
    "average": 52.15
  },
  "Sao10K/Stheno-1.8-L2-13B": {
    "arc": 63.48,
    "hellaswag": 84.12,
    "truthfulqa": 52.86,
    "mmlu": 58.57,
    "gsm8k": 13.27,
    "winogrande": 76.4,
    "average": 58.12
  },
  "Sao10K/Stheno-Inverted-1.2-L2-13B": {
    "arc": 59.39,
    "hellaswag": 83.01,
    "truthfulqa": 51.22,
    "mmlu": 55.77,
    "gsm8k": 8.95,
    "winogrande": 74.66,
    "average": 55.5
  },
  "Sao10K/Stheno-Inverted-L2-13B": {
    "arc": 59.3,
    "hellaswag": 82.9,
    "truthfulqa": 52.04,
    "mmlu": 56.45,
    "gsm8k": 13.19,
    "winogrande": 74.74,
    "average": 56.44
  },
  "Sao10K/Stheno-L2-13B": {
    "arc": 61.01,
    "hellaswag": 83.95,
    "truthfulqa": 50.18,
    "mmlu": 56.33,
    "gsm8k": 11.98,
    "winogrande": 75.14,
    "average": 56.43
  },
  "Sao10K/Stheno-Mix-L2-20B": {
    "arc": 57.76,
    "hellaswag": 79.63,
    "truthfulqa": 51.8,
    "mmlu": 52.51,
    "gsm8k": 0.08,
    "winogrande": 68.98,
    "average": 51.79
  },
  "Sao10K/Stheno-V2-Delta-fp16": {
    "arc": 62.46,
    "hellaswag": 83.45,
    "truthfulqa": 55.25,
    "winogrande": 73.88,
    "gsm8k": 12.81,
    "mmlu": 59.04,
    "average": 57.82
  },
  "Sao10K/SthenoWriter-L2-13B": {
    "arc": 62.29,
    "hellaswag": 83.28,
    "truthfulqa": 44.72,
    "mmlu": 56.14,
    "gsm8k": 11.22,
    "winogrande": 74.35,
    "average": 55.33
  },
  "Sao10K/Zephyrus-L1-33B": {
    "arc": 64.51,
    "hellaswag": 84.15,
    "truthfulqa": 53.87,
    "mmlu": 57.37,
    "gsm8k": 23.58,
    "winogrande": 80.19,
    "average": 60.61
  },
  "Sayan01/Llama-Flan-XL2base": {
    "arc": 20.65,
    "hellaswag": 25.33,
    "truthfulqa": 50.58,
    "winogrande": 50.91,
    "gsm8k": 0,
    "mmlu": 23.19,
    "average": 28.44
  },
  "SaylorTwift/gpt2_test": {
    "arc": 21.84,
    "hellaswag": 31.6,
    "truthfulqa": 40.67,
    "mmlu": 25.86,
    "gsm8k": 0.3,
    "winogrande": 50.12,
    "average": 28.4
  },
  "SciPhi/SciPhi-Self-RAG-Mistral-7B-32k": {
    "arc": 57.34,
    "hellaswag": 80.44,
    "truthfulqa": 45.63,
    "winogrande": 74.82,
    "gsm8k": 19.71,
    "mmlu": 60.81,
    "average": 56.46
  },
  "SebastianSchramm/Cerebras-GPT-111M-instruction": {
    "arc": 24.4,
    "hellaswag": 26.05,
    "truthfulqa": 49.46,
    "mmlu": 25.87,
    "gsm8k": 0,
    "winogrande": 51.62,
    "average": 29.57
  },
  "Secbone/llama-2-13B-instructed": {
    "arc": 59.39,
    "hellaswag": 83.88,
    "truthfulqa": 46.89,
    "mmlu": 55.57,
    "gsm8k": 8.04,
    "winogrande": 74.03,
    "average": 54.63
  },
  "Secbone/llama-33B-instructed": {
    "arc": 64.59,
    "hellaswag": 86.17,
    "truthfulqa": 44.12,
    "mmlu": 60.5,
    "gsm8k": 14.4,
    "winogrande": 79.32,
    "average": 58.18
  },
  "Severian/ANIMA-Phi-Neptune-Mistral-7B": {
    "arc": 55.97,
    "hellaswag": 76.22,
    "truthfulqa": 59.76,
    "mmlu": 52.89,
    "gsm8k": 14.94,
    "winogrande": 73.48,
    "average": 55.54
  },
  "Severian/ANIMA-Phi-Neptune-Mistral-7B-v1": {
    "arc": 52.9,
    "hellaswag": 74.68,
    "truthfulqa": 59.36,
    "mmlu": 52.18
  },
  "Severian/ANIMA-Phi-Neptune-Mistral-7B-v3": {
    "arc": 56.83,
    "hellaswag": 78.82,
    "truthfulqa": 59.4,
    "mmlu": 53.84
  },
  "Severian/ANIMA-Phi-Neptune-Mistral-7B-v4": {
    "arc": 55.46,
    "hellaswag": 77.63,
    "truthfulqa": 59.01,
    "mmlu": 53.12,
    "gsm8k": 14.94,
    "winogrande": 73.48,
    "average": 55.61
  },
  "Severian/ANIMA-Phi-Neptune-Mistral-LoRa": {
    "arc": 53.07,
    "hellaswag": 74.66,
    "truthfulqa": 59.38,
    "mmlu": 52.13
  },
  "SkunkworksAI/Mistralic-7B-1": {
    "arc": 60.84,
    "hellaswag": 82.29,
    "truthfulqa": 52.38,
    "mmlu": 60.8,
    "gsm8k": 11.07,
    "winogrande": 77.03,
    "average": 57.4
  },
  "StudentLLM/Alpagasus-2-13B-QLoRA-pipeline": {
    "arc": 58.28,
    "hellaswag": 80.98,
    "truthfulqa": 34.21,
    "mmlu": 54.14,
    "gsm8k": 9.25,
    "winogrande": 75.93,
    "average": 52.13
  },
  "StudentLLM/Alpagasus-2-13b-QLoRA-merged": {
    "arc": 60.84,
    "hellaswag": 82.43,
    "truthfulqa": 38.65,
    "mmlu": 55.55,
    "gsm8k": 11.14,
    "winogrande": 77.35,
    "average": 54.33
  },
  "SummerSigh/GPTNeo350M-Instruct-SFT": {
    "arc": 25.94,
    "hellaswag": 38.55,
    "truthfulqa": 45.25,
    "mmlu": 25.76,
    "gsm8k": 0.3,
    "winogrande": 50.2,
    "average": 31
  },
  "TFLai/Airboros2.1-Platypus2-13B-QLora-0.80-epoch": {
    "arc": 58.96,
    "hellaswag": 82.46,
    "truthfulqa": 47.71,
    "mmlu": 54.62,
    "gsm8k": 0,
    "winogrande": 75.14,
    "average": 53.15
  },
  "TFLai/Athena-Platypus2-13B-QLora-0.80-epoch": {
    "arc": 56.66,
    "hellaswag": 80.56,
    "truthfulqa": 53.62,
    "mmlu": 55.43,
    "gsm8k": 0.08,
    "winogrande": 72.61,
    "average": 53.16
  },
  "TFLai/Ensemble5-Platypus2-13B-QLora-0.80-epoch": {
    "arc": 59.73,
    "hellaswag": 82.66,
    "truthfulqa": 52.92,
    "mmlu": 56.94,
    "gsm8k": 1.9,
    "winogrande": 74.43,
    "average": 54.76
  },
  "TFLai/EnsembleV5-Nova-13B": {
    "arc": 62.71,
    "hellaswag": 82.55,
    "truthfulqa": 49.86,
    "mmlu": 56.79,
    "gsm8k": 10.77,
    "winogrande": 76.24,
    "average": 56.49
  },
  "TFLai/Limarp-Platypus2-13B-QLoRA-0.80-epoch": {
    "arc": 60.49,
    "hellaswag": 82.76,
    "truthfulqa": 44.14,
    "mmlu": 56.52,
    "gsm8k": 6.07,
    "winogrande": 76.8,
    "average": 54.46
  },
  "TFLai/Luban-Platypus2-13B-QLora-0.80-epoch": {
    "arc": 60.24,
    "hellaswag": 82.22,
    "truthfulqa": 55.26,
    "mmlu": 58.03,
    "gsm8k": 0.91,
    "winogrande": 75.37,
    "average": 55.34
  },
  "TFLai/MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch": {
    "arc": 57.34,
    "hellaswag": 81.24,
    "truthfulqa": 55.98,
    "mmlu": 55.64,
    "gsm8k": 0,
    "winogrande": 73.88,
    "average": 54.01
  },
  "TFLai/MythoMix-Platypus2-13B-QLoRA-0.80-epoch": {
    "arc": 60.32,
    "hellaswag": 83.72,
    "truthfulqa": 52.18,
    "mmlu": 55.74,
    "gsm8k": 0.91,
    "winogrande": 75.53,
    "average": 54.73
  },
  "TFLai/Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch": {
    "arc": 59.9,
    "hellaswag": 83.29,
    "truthfulqa": 51.08,
    "mmlu": 56.69,
    "gsm8k": 1.44,
    "winogrande": 75.22,
    "average": 54.6
  },
  "TFLai/Nova-13B": {
    "arc": 62.71,
    "hellaswag": 82.57,
    "truthfulqa": 51.34,
    "mmlu": 57.98,
    "gsm8k": 6.75,
    "winogrande": 77.27,
    "average": 56.44
  },
  "TFLai/Nova-13B-50-step": {
    "arc": 61.6,
    "hellaswag": 82.31,
    "truthfulqa": 51.53,
    "mmlu": 57.27,
    "gsm8k": 4.4,
    "winogrande": 76.56,
    "average": 55.61
  },
  "TFLai/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch": {
    "arc": 62.37,
    "hellaswag": 82.99,
    "truthfulqa": 52.2,
    "mmlu": 59.38,
    "gsm8k": 11.14,
    "winogrande": 75.77,
    "average": 57.31
  },
  "TFLai/OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch": {
    "arc": 59.81,
    "hellaswag": 82.69,
    "truthfulqa": 52.92,
    "mmlu": 56.96,
    "gsm8k": 2.35,
    "winogrande": 74.43,
    "average": 54.86
  },
  "TFLai/Orca-Nova-13B": {
    "arc": 62.37,
    "hellaswag": 82.47,
    "truthfulqa": 45.97,
    "mmlu": 57.44,
    "gsm8k": 14.48,
    "winogrande": 77.58,
    "average": 56.72
  },
  "TFLai/OrcaMini-Platypus2-13B-QLoRA-0.80-epoch": {
    "arc": 60.84,
    "hellaswag": 82.56,
    "truthfulqa": 53.32,
    "mmlu": 56.42,
    "gsm8k": 2.27,
    "winogrande": 75.93,
    "average": 55.22
  },
  "TFLai/Platypus2-13B-QLoRA-0.80-epoch": {
    "arc": 57.76,
    "hellaswag": 81.63,
    "truthfulqa": 39.7,
    "mmlu": 55.63,
    "gsm8k": 2.96,
    "winogrande": 75.93,
    "average": 52.27
  },
  "TFLai/PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch": {
    "arc": 54.52,
    "hellaswag": 79.36,
    "truthfulqa": 54.32,
    "mmlu": 55.15,
    "gsm8k": 0,
    "winogrande": 71.11,
    "average": 52.41
  },
  "TFLai/SpeechlessV1-Nova-13B": {
    "arc": 61.77,
    "hellaswag": 82.68,
    "truthfulqa": 51.44,
    "mmlu": 57.75,
    "gsm8k": 5.76,
    "winogrande": 77.43,
    "average": 56.14
  },
  "TFLai/Stable-Platypus2-13B-QLoRA-0.80-epoch": {
    "arc": 62.29,
    "hellaswag": 82.46,
    "truthfulqa": 51.41,
    "mmlu": 57.09,
    "gsm8k": 3.56,
    "winogrande": 76.56,
    "average": 55.56
  },
  "TFLai/bloom-560m-4bit-alpaca": {
    "arc": 23.98,
    "hellaswag": 29.21,
    "truthfulqa": 45.18,
    "mmlu": 25.2,
    "gsm8k": 0.15,
    "winogrande": 50.28,
    "average": 29
  },
  "TFLai/bloomz-1b7-4bit-alpaca": {
    "arc": 29.1,
    "hellaswag": 47.42,
    "truthfulqa": 41.06,
    "mmlu": 31.8,
    "gsm8k": 0,
    "winogrande": 53.83,
    "average": 33.87
  },
  "TFLai/gpt-neo-1.3B-4bit-alpaca": {
    "arc": 28.24,
    "hellaswag": 46.35,
    "truthfulqa": 39.26,
    "mmlu": 25.19,
    "gsm8k": 0.23,
    "winogrande": 56.2,
    "average": 32.58
  },
  "TFLai/gpt-neox-20b-4bit-alpaca": {
    "arc": 43.86,
    "hellaswag": 67.4,
    "truthfulqa": 35.67,
    "mmlu": 25.06,
    "gsm8k": 1.14,
    "winogrande": 64.88,
    "average": 39.67
  },
  "TFLai/gpt2-turkish-uncased": {
    "arc": 24.49,
    "hellaswag": 25.08,
    "truthfulqa": 52.3,
    "mmlu": 26.59,
    "gsm8k": 0,
    "winogrande": 49.64,
    "average": 29.68
  },
  "TFLai/llama-13b-4bit-alpaca": {
    "arc": 55.72,
    "hellaswag": 80.88,
    "truthfulqa": 44.8,
    "mmlu": 42.42,
    "gsm8k": 5.69,
    "winogrande": 74.82,
    "average": 50.72
  },
  "TFLai/llama-2-13b-4bit-alpaca-gpt4": {
    "arc": 57.68,
    "hellaswag": 81.05,
    "truthfulqa": 45.69,
    "mmlu": 51.82,
    "gsm8k": 8.26,
    "winogrande": 75.14,
    "average": 53.27
  },
  "TFLai/llama-7b-4bit-alpaca": {
    "arc": 52.65,
    "hellaswag": 77.78,
    "truthfulqa": 34.22,
    "mmlu": 34.57,
    "gsm8k": 3.56,
    "winogrande": 70.8,
    "average": 45.6
  },
  "TFLai/pythia-2.8b-4bit-alpaca": {
    "arc": 34.73,
    "hellaswag": 58.96,
    "truthfulqa": 39.14,
    "mmlu": 25.53,
    "gsm8k": 0.61,
    "winogrande": 61.64,
    "average": 36.77
  },
  "THUDM/chatglm2-6b": {
    "arc": 38.82,
    "hellaswag": 59.02,
    "truthfulqa": 48.08,
    "mmlu": 46.66
  },
  "Taekyoon/llama2-ko-7b-test": {
    "arc": 37.8,
    "hellaswag": 63.04,
    "truthfulqa": 36,
    "mmlu": 29.55
  },
  "Tap-M/Luna-AI-Llama2-Uncensored": {
    "arc": 54.35,
    "hellaswag": 78.6,
    "truthfulqa": 45.5,
    "mmlu": 46.7,
    "gsm8k": 9.86,
    "winogrande": 72.77,
    "average": 51.3
  },
  "TaylorAI/FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model": {
    "arc": 52.47,
    "hellaswag": 79.08,
    "truthfulqa": 37.14,
    "mmlu": 47.58,
    "gsm8k": 6.82,
    "winogrande": 74.74,
    "average": 49.64
  },
  "TaylorAI/Flash-Llama-13B": {
    "arc": 59.3,
    "hellaswag": 82.15,
    "truthfulqa": 37.39,
    "mmlu": 55.67,
    "gsm8k": 10.84,
    "winogrande": 76.64,
    "average": 53.67
  },
  "TaylorAI/Flash-Llama-30M-20001": {
    "arc": 23.89,
    "hellaswag": 25.76,
    "truthfulqa": 51.29,
    "mmlu": 24.09,
    "gsm8k": 0,
    "winogrande": 50.83,
    "average": 29.31
  },
  "TaylorAI/Flash-Llama-3B": {
    "arc": 40.1,
    "hellaswag": 71.56,
    "truthfulqa": 34.74,
    "mmlu": 26.88,
    "gsm8k": 0.91,
    "winogrande": 66.61,
    "average": 40.13
  },
  "TaylorAI/Flash-Llama-7B": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.8,
    "gsm8k": 7.13,
    "winogrande": 74.03,
    "average": 49.73
  },
  "TehVenom/ChanMalion": {
    "arc": 41.89,
    "hellaswag": 68.25,
    "truthfulqa": 33.89,
    "mmlu": 27.29,
    "gsm8k": 1.67,
    "winogrande": 65.35,
    "average": 39.72
  },
  "TehVenom/DiffMerge-DollyGPT-Pygmalion": {
    "arc": 23.63,
    "hellaswag": 34.38,
    "truthfulqa": 46.48,
    "mmlu": 24.41,
    "gsm8k": 0,
    "winogrande": 53.83,
    "average": 30.46
  },
  "TehVenom/DiffMerge_Pygmalion_Main-onto-V8P4": {
    "arc": 40.53,
    "hellaswag": 67.48,
    "truthfulqa": 32.55,
    "mmlu": 25.68,
    "gsm8k": 1.14,
    "winogrande": 62.51,
    "average": 38.32
  },
  "TehVenom/Dolly_Malion-6b": {
    "arc": 42.83,
    "hellaswag": 68.43,
    "truthfulqa": 33.03,
    "mmlu": 27.13,
    "gsm8k": 1.74,
    "winogrande": 65.43,
    "average": 39.77
  },
  "TehVenom/Dolly_Shygmalion-6b": {
    "arc": 41.89,
    "hellaswag": 68.48,
    "truthfulqa": 33.91,
    "mmlu": 27.58,
    "gsm8k": 2.12,
    "winogrande": 65.35,
    "average": 39.89
  },
  "TehVenom/Dolly_Shygmalion-6b-Dev_V8P2": {
    "arc": 41.38,
    "hellaswag": 67.67,
    "truthfulqa": 36.86,
    "mmlu": 28.48,
    "gsm8k": 1.97,
    "winogrande": 64.33,
    "average": 40.12
  },
  "TehVenom/GPT-J-Pyg_PPO-6B": {
    "arc": 42.06,
    "hellaswag": 67.51,
    "truthfulqa": 31.95,
    "mmlu": 28.52,
    "gsm8k": 2.81,
    "winogrande": 64.72,
    "average": 39.6
  },
  "TehVenom/GPT-J-Pyg_PPO-6B-Dev-V8p4": {
    "arc": 40.19,
    "hellaswag": 66.43,
    "truthfulqa": 34.76,
    "mmlu": 30.39,
    "gsm8k": 1.9,
    "winogrande": 64.01,
    "average": 39.61
  },
  "TehVenom/Metharme-13b-Merged": {
    "arc": 59.9,
    "hellaswag": 81.12,
    "truthfulqa": 51.18,
    "mmlu": 47.18,
    "gsm8k": 8.72,
    "winogrande": 76.8,
    "average": 54.15
  },
  "TehVenom/Moderator-Chan_GPT-JT-6b": {
    "arc": 43.69,
    "hellaswag": 70.77,
    "truthfulqa": 36.05,
    "mmlu": 35.61,
    "gsm8k": 1.29,
    "winogrande": 65.59,
    "average": 42.17
  },
  "TehVenom/PPO_Pygway-V8p4_Dev-6b": {
    "arc": 40.36,
    "hellaswag": 67.15,
    "truthfulqa": 35.26,
    "mmlu": 29.3,
    "gsm8k": 2.65,
    "winogrande": 64.4,
    "average": 39.85
  },
  "TehVenom/PPO_Shygmalion-6b": {
    "arc": 40.27,
    "hellaswag": 66.88,
    "truthfulqa": 34.24,
    "mmlu": 27.53,
    "gsm8k": 1.82,
    "winogrande": 65.35,
    "average": 39.35
  },
  "TehVenom/PPO_Shygmalion-V8p4_Dev-6b": {
    "arc": 40.7,
    "hellaswag": 67.04,
    "truthfulqa": 35.57,
    "mmlu": 29.31,
    "gsm8k": 2.58,
    "winogrande": 63.93,
    "average": 39.86
  },
  "TehVenom/Pygmalion-13b-Merged": {
    "arc": 56.48,
    "hellaswag": 80.02,
    "truthfulqa": 35.86,
    "mmlu": 42.93,
    "gsm8k": 0.08,
    "winogrande": 75.53,
    "average": 48.48
  },
  "TehVenom/Pygmalion-Vicuna-1.1-7b": {
    "arc": 52.82,
    "hellaswag": 78.66,
    "truthfulqa": 42.21,
    "mmlu": 43.61,
    "gsm8k": 6.22,
    "winogrande": 71.98,
    "average": 49.25
  },
  "TehVenom/Pygmalion_AlpacaLora-7b": {
    "arc": 53.24,
    "hellaswag": 76.92,
    "truthfulqa": 39.44,
    "mmlu": 35.92,
    "gsm8k": 1.21,
    "winogrande": 72.22,
    "average": 46.49
  },
  "TehVenom/oasst-sft-6-llama-33b-xor-MERGED-16bit": {
    "arc": 61.52,
    "hellaswag": 83.5,
    "truthfulqa": 50.7,
    "mmlu": 57.43,
    "gsm8k": 30.48,
    "winogrande": 79.08,
    "average": 60.45
  },
  "The-Face-Of-Goonery/Chronos-Beluga-v2-13bfp16": {
    "arc": 60.75,
    "hellaswag": 81.94,
    "truthfulqa": 53.23,
    "mmlu": 54.08,
    "gsm8k": 4.62,
    "winogrande": 73.8,
    "average": 54.74
  },
  "The-Face-Of-Goonery/Huginn-13b-FP16": {
    "arc": 60.58,
    "hellaswag": 82.53,
    "truthfulqa": 54.46,
    "mmlu": 53.71,
    "gsm8k": 4.32,
    "winogrande": 73.72,
    "average": 54.89
  },
  "The-Face-Of-Goonery/Huginn-13b-V4": {
    "arc": 60.67,
    "hellaswag": 82.34,
    "truthfulqa": 50.62,
    "mmlu": 52.32,
    "gsm8k": 4.62,
    "winogrande": 73.64,
    "average": 54.04
  },
  "The-Face-Of-Goonery/Huginn-13b-v1.2": {
    "arc": 60.92,
    "hellaswag": 83.56,
    "truthfulqa": 51.97,
    "mmlu": 55.33,
    "gsm8k": 9.17,
    "winogrande": 75.22,
    "average": 56.03
  },
  "The-Face-Of-Goonery/Huginn-13b-v4.5": {
    "arc": 60.67,
    "hellaswag": 82.34,
    "truthfulqa": 50.62,
    "mmlu": 52.32,
    "gsm8k": 4.62,
    "winogrande": 73.64,
    "average": 54.04
  },
  "The-Face-Of-Goonery/Huginn-19b-prototype": {
    "arc": 59.22,
    "hellaswag": 81.03,
    "truthfulqa": 41.15,
    "mmlu": 55.73,
    "gsm8k": 4.4,
    "winogrande": 76.4,
    "average": 52.99
  },
  "The-Face-Of-Goonery/Huginn-22b-Prototype": {
    "arc": 57.68,
    "hellaswag": 80.69,
    "truthfulqa": 52.11,
    "mmlu": 49.81,
    "gsm8k": 2.27,
    "winogrande": 71.59,
    "average": 52.36
  },
  "The-Face-Of-Goonery/Huginn-v3-13b": {
    "arc": 60.67,
    "hellaswag": 82.34,
    "truthfulqa": 50.62,
    "mmlu": 52.32,
    "gsm8k": 4.62,
    "winogrande": 73.64,
    "average": 54.04
  },
  "The-Face-Of-Goonery/huginnv1.2": {
    "arc": 62.37,
    "hellaswag": 84.28,
    "truthfulqa": 47.81,
    "mmlu": 57.02,
    "gsm8k": 9.17,
    "winogrande": 75.22,
    "average": 55.98
  },
  "TheBloke/Airoboros-L2-13B-2.1-GPTQ": {
    "arc": 58.96,
    "hellaswag": 81.72,
    "truthfulqa": 44.68,
    "mmlu": 53.16,
    "gsm8k": 5.99,
    "winogrande": 74.35,
    "average": 53.14
  },
  "TheBloke/Airoboros-L2-70B-2.1-GPTQ": {
    "arc": 70.39,
    "hellaswag": 86.54,
    "truthfulqa": 55.55,
    "mmlu": 68.89,
    "gsm8k": 15.24,
    "winogrande": 81.61,
    "average": 63.04
  },
  "TheBloke/BigTranslate-13B-GPTQ": {
    "arc": 45.31,
    "hellaswag": 75.1,
    "truthfulqa": 40.6,
    "mmlu": 31.18,
    "gsm8k": 0,
    "winogrande": 70.96,
    "average": 43.86
  },
  "TheBloke/CAMEL-33B-Combined-Data-SuperHOT-8K-fp16": {
    "arc": 25.85,
    "hellaswag": 31.57,
    "truthfulqa": 48.13,
    "mmlu": 23.69
  },
  "TheBloke/Chinese-Alpaca-33B-SuperHOT-8K-fp16": {
    "arc": 26.79,
    "hellaswag": 29.56,
    "truthfulqa": 47.75,
    "mmlu": 24.07
  },
  "TheBloke/CodeLlama-13B-Instruct-fp16": {
    "arc": 44.62,
    "hellaswag": 64.94,
    "truthfulqa": 45.88,
    "mmlu": 38.77,
    "gsm8k": 12.66,
    "winogrande": 68.03,
    "average": 45.82
  },
  "TheBloke/CodeLlama-13B-Python-fp16": {
    "arc": 33.19,
    "hellaswag": 44.5,
    "truthfulqa": 43.99,
    "mmlu": 25.94,
    "gsm8k": 10.08,
    "winogrande": 67.4,
    "average": 37.52
  },
  "TheBloke/CodeLlama-34B-Instruct-fp16": {
    "arc": 40.78,
    "hellaswag": 35.66,
    "truthfulqa": 44.29,
    "mmlu": 39.72,
    "gsm8k": 23.05,
    "winogrande": 74.51,
    "average": 43
  },
  "TheBloke/CodeLlama-34B-Python-fp16": {
    "arc": 38.14,
    "hellaswag": 34.8,
    "truthfulqa": 43.57,
    "mmlu": 32.95,
    "gsm8k": 20.02,
    "winogrande": 72.14,
    "average": 40.27
  },
  "TheBloke/EverythingLM-13B-16K-GPTQ": {
    "arc": 29.27,
    "hellaswag": 26.24,
    "truthfulqa": 48.58,
    "mmlu": 25.4,
    "gsm8k": 5.38,
    "winogrande": 71.35,
    "average": 34.37
  },
  "TheBloke/GPlatty-30B-SuperHOT-8K-fp16": {
    "arc": 28.33,
    "hellaswag": 33.48,
    "truthfulqa": 46.27,
    "mmlu": 24.92
  },
  "TheBloke/Genz-70b-GPTQ": {
    "arc": 71.08,
    "hellaswag": 87.64,
    "truthfulqa": 62.28,
    "mmlu": 70.26
  },
  "TheBloke/Guanaco-3B-Uncensored-v2-GPTQ": {
    "arc": 41.64,
    "hellaswag": 64.76,
    "truthfulqa": 36.58,
    "mmlu": 26.25,
    "gsm8k": 0.15,
    "winogrande": 64.33,
    "average": 38.95
  },
  "TheBloke/Kimiko-13B-fp16": {
    "arc": 59.22,
    "hellaswag": 82.35,
    "truthfulqa": 39.55,
    "mmlu": 55.85,
    "gsm8k": 8.79,
    "winogrande": 76.72,
    "average": 53.75
  },
  "TheBloke/Kimiko-v2-13B-fp16": {
    "arc": 61.01,
    "hellaswag": 83.32,
    "truthfulqa": 40.65,
    "mmlu": 55.17,
    "gsm8k": 12.51,
    "winogrande": 76.8,
    "average": 54.91
  },
  "TheBloke/Lemur-70B-Chat-v1-GPTQ": {
    "arc": 65.27,
    "hellaswag": 84.41,
    "truthfulqa": 57.11,
    "mmlu": 64.75
  },
  "TheBloke/Llama-2-13B-GPTQ": {
    "arc": 59.13,
    "hellaswag": 81.48,
    "truthfulqa": 37.07,
    "mmlu": 54.45,
    "gsm8k": 11.3,
    "winogrande": 76.16,
    "average": 53.27
  },
  "TheBloke/Llama-2-13B-fp16": {
    "arc": 59.3,
    "hellaswag": 82.15,
    "truthfulqa": 37.39,
    "mmlu": 55.67,
    "gsm8k": 10.84,
    "winogrande": 76.64,
    "average": 53.67
  },
  "TheBloke/Llama-2-70B-chat-GPTQ": {
    "arc": 62.63,
    "hellaswag": 84.81,
    "truthfulqa": 50.98,
    "mmlu": 62.74,
    "gsm8k": 18.65,
    "winogrande": 78.69,
    "average": 59.75
  },
  "TheBloke/Llama-2-70B-fp16": {
    "arc": 67.32,
    "hellaswag": 87.33,
    "truthfulqa": 44.92,
    "mmlu": 69.83,
    "gsm8k": 33.97,
    "winogrande": 83.74,
    "average": 64.52
  },
  "TheBloke/Llama-2-7B-GPTQ": {
    "arc": 52.05,
    "hellaswag": 77.59,
    "truthfulqa": 39.32,
    "mmlu": 43.99,
    "gsm8k": 5,
    "winogrande": 72.93,
    "average": 48.48
  },
  "TheBloke/Llama-2-7b-Chat-AWQ": {
    "arc": 27.22,
    "hellaswag": 25.48,
    "truthfulqa": 49.95,
    "mmlu": 24.67,
    "gsm8k": 0,
    "winogrande": 47.51,
    "average": 29.14
  },
  "TheBloke/LongChat-13B-GPTQ": {
    "arc": 28.33,
    "hellaswag": 26.12,
    "truthfulqa": 48.27,
    "mmlu": 25.56,
    "gsm8k": 0,
    "winogrande": 51.14,
    "average": 29.9
  },
  "TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ": {
    "arc": 52.82,
    "hellaswag": 79.63,
    "truthfulqa": 52.55,
    "mmlu": 39.83,
    "gsm8k": 0.15,
    "winogrande": 71.82,
    "average": 49.47
  },
  "TheBloke/Nous-Hermes-13B-SuperHOT-8K-fp16": {
    "arc": 55.29,
    "hellaswag": 81.87,
    "truthfulqa": 51.19,
    "mmlu": 48.23,
    "gsm8k": 1.21,
    "winogrande": 75.3,
    "average": 52.18
  },
  "TheBloke/OpenAssistant-SFT-7-Llama-30B-HF": {
    "arc": 60.58,
    "hellaswag": 82.17,
    "truthfulqa": 46.94,
    "mmlu": 57.93,
    "gsm8k": 29.8,
    "winogrande": 78.61,
    "average": 59.34
  },
  "TheBloke/OpenOrca-Platypus2-13B-GPTQ": {
    "arc": 62.54,
    "hellaswag": 82.67,
    "truthfulqa": 51.93,
    "mmlu": 58.56,
    "gsm8k": 9.4,
    "winogrande": 76.8,
    "average": 56.98
  },
  "TheBloke/OpenOrcaxOpenChat-Preview2-13B-GPTQ": {
    "arc": 61.26,
    "hellaswag": 82.14,
    "truthfulqa": 50.22,
    "mmlu": 57.85,
    "gsm8k": 12.43,
    "winogrande": 77.11,
    "average": 56.84
  },
  "TheBloke/Orca-2-13B-GPTQ": {
    "arc": 59.81,
    "hellaswag": 79.12,
    "truthfulqa": 55.14,
    "winogrande": 76.64,
    "gsm8k": 15.54,
    "mmlu": 59.35,
    "average": 57.6
  },
  "TheBloke/Planner-7B-fp16": {
    "arc": 51.02,
    "hellaswag": 77.82,
    "truthfulqa": 34.33,
    "mmlu": 35.71,
    "gsm8k": 3.56,
    "winogrande": 71.43,
    "average": 45.65
  },
  "TheBloke/Platypus-30B-SuperHOT-8K-fp16": {
    "arc": 25.68,
    "hellaswag": 30.82,
    "truthfulqa": 47.13,
    "mmlu": 23.61
  },
  "TheBloke/Platypus2-70B-Instruct-GPTQ": {
    "arc": 71.25,
    "hellaswag": 87.55,
    "truthfulqa": 62.54,
    "mmlu": 69.89
  },
  "TheBloke/Project-Baize-v2-13B-GPTQ": {
    "arc": 27.56,
    "hellaswag": 26.42,
    "truthfulqa": 48.22,
    "mmlu": 25.91
  },
  "TheBloke/Project-Baize-v2-7B-GPTQ": {
    "arc": 45.99,
    "hellaswag": 73.44,
    "truthfulqa": 39.92,
    "mmlu": 35.46,
    "gsm8k": 2.5,
    "winogrande": 69.69,
    "average": 44.5
  },
  "TheBloke/UltraLM-13B-fp16": {
    "arc": 57.59,
    "hellaswag": 80.2,
    "truthfulqa": 51.56,
    "mmlu": 51.85,
    "gsm8k": 10.69,
    "winogrande": 75.85,
    "average": 54.62
  },
  "TheBloke/VicUnlocked-30B-LoRA-HF": {
    "arc": 59.73,
    "hellaswag": 84.02,
    "truthfulqa": 48.54,
    "mmlu": 57.81,
    "gsm8k": 14.4,
    "winogrande": 79.48,
    "average": 57.33
  },
  "TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16": {
    "arc": 65.61,
    "hellaswag": 85.15,
    "truthfulqa": 52.47,
    "mmlu": 63.13,
    "gsm8k": 27.82,
    "winogrande": 81.29,
    "average": 62.58
  },
  "TheBloke/Vicuna-13B-CoT-fp16": {
    "arc": 52.73,
    "hellaswag": 80.14,
    "truthfulqa": 52.08,
    "mmlu": 51.9,
    "gsm8k": 8.64,
    "winogrande": 74.19,
    "average": 53.28
  },
  "TheBloke/Vicuna-33B-1-3-SuperHOT-8K-fp16": {
    "arc": 25.43,
    "hellaswag": 34.61,
    "truthfulqa": 46.93,
    "mmlu": 23.62
  },
  "TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ": {
    "arc": 29.61,
    "hellaswag": 25.47,
    "truthfulqa": 50.25,
    "mmlu": 25.34,
    "gsm8k": 9.93,
    "winogrande": 75.77,
    "average": 36.06
  },
  "TheBloke/Wizard-Vicuna-13B-Uncensored-HF": {
    "arc": 58.96,
    "hellaswag": 81.95,
    "truthfulqa": 51.69,
    "mmlu": 47.92,
    "gsm8k": 8.64,
    "winogrande": 75.69,
    "average": 54.14
  },
  "TheBloke/Wizard-Vicuna-30B-Superhot-8K-fp16": {
    "arc": 26.19,
    "hellaswag": 32.96,
    "truthfulqa": 47.48,
    "mmlu": 23.46
  },
  "TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ": {
    "arc": 61.09,
    "hellaswag": 82.4,
    "truthfulqa": 49.9,
    "mmlu": 56.46,
    "gsm8k": 23.28,
    "winogrande": 77.66,
    "average": 58.47
  },
  "TheBloke/Wizard-Vicuna-30B-Uncensored-fp16": {
    "arc": 62.12,
    "hellaswag": 83.45,
    "truthfulqa": 50.81,
    "mmlu": 58.24,
    "gsm8k": 14.25,
    "winogrande": 78.45,
    "average": 57.89
  },
  "TheBloke/Wizard-Vicuna-7B-Uncensored-HF": {
    "arc": 53.41,
    "hellaswag": 78.85,
    "truthfulqa": 43.48,
    "mmlu": 37.09,
    "gsm8k": 4.55,
    "winogrande": 72.22,
    "average": 48.27
  },
  "TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ": {
    "arc": 57,
    "hellaswag": 80.32,
    "truthfulqa": 53.46,
    "mmlu": 47.08,
    "gsm8k": 0.68,
    "winogrande": 74.35,
    "average": 52.15
  },
  "TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-fp16": {
    "arc": 58.62,
    "hellaswag": 81.07,
    "truthfulqa": 54.19,
    "mmlu": 48.32,
    "gsm8k": 0.76,
    "winogrande": 76.01,
    "average": 53.16
  },
  "TheBloke/WizardLM-13B-V1.1-GPTQ": {
    "arc": 58.53,
    "hellaswag": 80.66,
    "truthfulqa": 54.35,
    "mmlu": 49.59,
    "gsm8k": 8.11,
    "winogrande": 74.43,
    "average": 54.28
  },
  "TheBloke/WizardLM-30B-GPTQ": {
    "arc": 28.84,
    "hellaswag": 26.08,
    "truthfulqa": 49.14,
    "mmlu": 24.62,
    "gsm8k": 34.42,
    "winogrande": 76.32,
    "average": 39.9
  },
  "TheBloke/WizardLM-30B-Uncensored-GPTQ": {
    "arc": 29.44,
    "hellaswag": 26.47,
    "truthfulqa": 49.15,
    "mmlu": 24.35,
    "gsm8k": 21.08,
    "winogrande": 73.16,
    "average": 37.28
  },
  "TheBloke/WizardLM-30B-fp16": {
    "arc": 62.54,
    "hellaswag": 83.28,
    "truthfulqa": 52.49,
    "mmlu": 59.03,
    "gsm8k": 22.21,
    "winogrande": 77.51,
    "average": 59.51
  },
  "TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ": {
    "arc": 27.39,
    "hellaswag": 26.03,
    "truthfulqa": 48.9,
    "mmlu": 25.81,
    "gsm8k": 24.56,
    "winogrande": 77.9,
    "average": 38.43
  },
  "TheBloke/WizardLM-70B-V1.0-GPTQ": {
    "arc": 63.82,
    "hellaswag": 83.85,
    "truthfulqa": 54.54,
    "mmlu": 63.68,
    "gsm8k": 18.5,
    "winogrande": 78.61,
    "average": 60.5
  },
  "TheBloke/WizardLM-7B-uncensored-GPTQ": {
    "arc": 28.5,
    "hellaswag": 25.37,
    "truthfulqa": 50.86,
    "mmlu": 24.85,
    "gsm8k": 0,
    "winogrande": 49.57,
    "average": 29.86
  },
  "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ": {
    "arc": 28.41,
    "hellaswag": 26.05,
    "truthfulqa": 49.54,
    "mmlu": 24.71,
    "gsm8k": 5.31,
    "winogrande": 68.67,
    "average": 33.78
  },
  "TheBloke/airoboros-13B-HF": {
    "arc": 58.28,
    "hellaswag": 81.05,
    "truthfulqa": 51.57,
    "mmlu": 50.03,
    "gsm8k": 7.13,
    "winogrande": 76.24,
    "average": 54.05
  },
  "TheBloke/airoboros-33B-gpt4-1-4-SuperHOT-8K-fp16": {
    "arc": 26.02,
    "hellaswag": 30.65,
    "truthfulqa": 47.92,
    "mmlu": 23.57
  },
  "TheBloke/airoboros-7b-gpt4-fp16": {
    "arc": 53.07,
    "hellaswag": 78.67,
    "truthfulqa": 40.73,
    "mmlu": 38.88,
    "gsm8k": 1.74,
    "winogrande": 73.09,
    "average": 47.7
  },
  "TheBloke/alpaca-lora-65B-HF": {
    "arc": 64.85,
    "hellaswag": 85.59,
    "truthfulqa": 45.15,
    "mmlu": 63.11,
    "gsm8k": 28.05,
    "winogrande": 81.22,
    "average": 61.33
  },
  "TheBloke/chronos-wizardlm-uc-scot-st-13B-GPTQ": {
    "arc": 27.99,
    "hellaswag": 26.1,
    "truthfulqa": 49.68,
    "mmlu": 25.72,
    "gsm8k": 6.9,
    "winogrande": 74.51,
    "average": 35.15
  },
  "TheBloke/dromedary-65b-lora-HF": {
    "arc": 61.6,
    "hellaswag": 82.53,
    "truthfulqa": 38.82,
    "mmlu": 63.08,
    "gsm8k": 27.45,
    "winogrande": 78.93,
    "average": 58.73
  },
  "TheBloke/fiction.live-Kimiko-V2-70B-fp16": {
    "arc": 67.66,
    "hellaswag": 87.65,
    "truthfulqa": 49.28,
    "mmlu": 69.82,
    "gsm8k": 34.57,
    "winogrande": 83.9,
    "average": 65.48
  },
  "TheBloke/gpt4-alpaca-lora-13B-HF": {
    "arc": 59.56,
    "hellaswag": 82.09,
    "truthfulqa": 48.96,
    "mmlu": 47.48,
    "gsm8k": 9.1,
    "winogrande": 76.72,
    "average": 53.98
  },
  "TheBloke/gpt4-alpaca-lora-30b-HF": {
    "arc": 64.85,
    "hellaswag": 85.72,
    "truthfulqa": 52.24,
    "mmlu": 58.51,
    "gsm8k": 15.54,
    "winogrande": 80.19,
    "average": 59.51
  },
  "TheBloke/gpt4-alpaca-lora_mlp-65B-HF": {
    "arc": 65.02,
    "hellaswag": 86.13,
    "truthfulqa": 59.16,
    "mmlu": 62.73,
    "gsm8k": 28.28,
    "winogrande": 80.66,
    "average": 63.66
  },
  "TheBloke/gpt4-x-vicuna-13B-HF": {
    "arc": 53.41,
    "hellaswag": 80.12,
    "truthfulqa": 53.58,
    "mmlu": 51.22
  },
  "TheBloke/guanaco-13B-HF": {
    "arc": 57.85,
    "hellaswag": 83.84,
    "truthfulqa": 46.73,
    "mmlu": 48.28,
    "gsm8k": 8.72,
    "winogrande": 75.85,
    "average": 53.54
  },
  "TheBloke/guanaco-33B-GPTQ": {
    "arc": 28.16,
    "hellaswag": 26.34,
    "truthfulqa": 48.98,
    "mmlu": 24.94,
    "gsm8k": 23.81,
    "winogrande": 78.85,
    "average": 38.51
  },
  "TheBloke/guanaco-65B-HF": {
    "arc": 65.44,
    "hellaswag": 86.47,
    "truthfulqa": 52.81,
    "mmlu": 62.92,
    "gsm8k": 26,
    "winogrande": 82.4,
    "average": 62.67
  },
  "TheBloke/guanaco-7B-HF": {
    "arc": 52.99,
    "hellaswag": 80.05,
    "truthfulqa": 39.2,
    "mmlu": 35.32,
    "gsm8k": 5.08,
    "winogrande": 71.43,
    "average": 47.35
  },
  "TheBloke/h2ogpt-oasst1-512-30B-HF": {
    "arc": 57.34,
    "hellaswag": 81.37,
    "truthfulqa": 45.46,
    "mmlu": 48.09
  },
  "TheBloke/koala-13B-HF": {
    "arc": 52.99,
    "hellaswag": 77.59,
    "truthfulqa": 50.23,
    "mmlu": 45.32,
    "gsm8k": 6.82,
    "winogrande": 74.03,
    "average": 51.16
  },
  "TheBloke/koala-7B-HF": {
    "arc": 47.1,
    "hellaswag": 73.58,
    "truthfulqa": 45.96,
    "mmlu": 25.53,
    "gsm8k": 3.64,
    "winogrande": 69.93,
    "average": 44.29
  },
  "TheBloke/landmark-attention-llama7b-fp16": {
    "arc": 47.35,
    "hellaswag": 65.81,
    "truthfulqa": 42.63,
    "mmlu": 31.59,
    "gsm8k": 1.59,
    "winogrande": 68.03,
    "average": 42.83
  },
  "TheBloke/llama-2-70b-Guanaco-QLoRA-fp16": {
    "arc": 68.26,
    "hellaswag": 88.32,
    "truthfulqa": 55.69,
    "mmlu": 70.23,
    "gsm8k": 29.8,
    "winogrande": 83.98,
    "average": 66.05
  },
  "TheBloke/llama-30b-supercot-SuperHOT-8K-fp16": {
    "arc": 25.85,
    "hellaswag": 30.53,
    "truthfulqa": 47.04,
    "mmlu": 23.5
  },
  "TheBloke/manticore-13b-chat-pyg-GPTQ": {
    "arc": 57.85,
    "hellaswag": 81.07,
    "truthfulqa": 47.77,
    "mmlu": 47.56,
    "gsm8k": 8.49,
    "winogrande": 75.93,
    "average": 53.11
  },
  "TheBloke/medalpaca-13B-GPTQ-4bit": {
    "arc": 29.35,
    "hellaswag": 26.32,
    "truthfulqa": 49.51,
    "mmlu": 25.44,
    "gsm8k": 0,
    "winogrande": 53.12,
    "average": 30.62
  },
  "TheBloke/openchat_v2_openorca_preview-GPTQ": {
    "arc": 27.99,
    "hellaswag": 26.06,
    "truthfulqa": 50.08,
    "mmlu": 24.24,
    "gsm8k": 13.27,
    "winogrande": 70.64,
    "average": 35.38
  },
  "TheBloke/orca_mini_13B-GPTQ": {
    "arc": 27.3,
    "hellaswag": 25.85,
    "truthfulqa": 48.06,
    "mmlu": 25.31,
    "gsm8k": 0.08,
    "winogrande": 63.77,
    "average": 31.73
  },
  "TheBloke/orca_mini_v3_13B-GPTQ": {
    "arc": 61.95,
    "hellaswag": 81.56,
    "truthfulqa": 49.22,
    "winogrande": 75.77,
    "gsm8k": 29.49,
    "mmlu": 56.1,
    "average": 59.02
  },
  "TheBloke/orca_mini_v3_7B-GPTQ": {
    "arc": 54.52,
    "hellaswag": 78.53,
    "truthfulqa": 51.2,
    "mmlu": 51.85,
    "winogrande": 74.66,
    "gsm8k": 15.31,
    "average": 54.35
  },
  "TheBloke/robin-13B-v2-fp16": {
    "arc": 56.48,
    "hellaswag": 80.37,
    "truthfulqa": 50.63,
    "mmlu": 48.79
  },
  "TheBloke/robin-33B-v2-GPTQ": {
    "arc": 27.73,
    "hellaswag": 26.29,
    "truthfulqa": 49.54,
    "mmlu": 23.53,
    "gsm8k": 27.75,
    "winogrande": 79.79,
    "average": 39.1
  },
  "TheBloke/robin-33B-v2-fp16": {
    "arc": 62.37,
    "hellaswag": 83.63,
    "truthfulqa": 53.88,
    "mmlu": 54.71
  },
  "TheBloke/robin-65b-v2-fp16": {
    "arc": 61.95,
    "hellaswag": 84.6,
    "truthfulqa": 52.31,
    "mmlu": 62.51,
    "gsm8k": 26.99,
    "winogrande": 80.51,
    "average": 61.48
  },
  "TheBloke/stable-vicuna-13B-HF": {
    "arc": 53.33,
    "hellaswag": 78.5,
    "truthfulqa": 48.38,
    "mmlu": 50.29,
    "gsm8k": 4.09,
    "winogrande": 75.22,
    "average": 51.63
  },
  "TheBloke/tulu-13B-fp16": {
    "arc": 53.92,
    "hellaswag": 80.66,
    "truthfulqa": 43.84,
    "mmlu": 53.19,
    "gsm8k": 14.25,
    "winogrande": 75.61,
    "average": 53.58
  },
  "TheBloke/tulu-30B-fp16": {
    "arc": 59.98,
    "hellaswag": 83.4,
    "truthfulqa": 45.14,
    "mmlu": 56.1,
    "gsm8k": 19.71,
    "winogrande": 80.82,
    "average": 57.53
  },
  "TheBloke/tulu-7B-fp16": {
    "arc": 50.17,
    "hellaswag": 77.04,
    "truthfulqa": 41.61,
    "mmlu": 47.63,
    "gsm8k": 11.22,
    "winogrande": 73.8,
    "average": 50.25
  },
  "TheBloke/vicuna-13B-1.1-HF": {
    "arc": 52.73,
    "hellaswag": 80.13,
    "truthfulqa": 52.08,
    "mmlu": 51.94,
    "gsm8k": 8.64,
    "winogrande": 74.19,
    "average": 53.29
  },
  "TheBloke/vicuna-13b-v1.3.0-GPTQ": {
    "arc": 54.35,
    "hellaswag": 79.47,
    "truthfulqa": 50.88,
    "mmlu": 51.97,
    "gsm8k": 8.42,
    "winogrande": 74.66,
    "average": 53.29
  },
  "TheBloke/wizard-mega-13B-GPTQ": {
    "arc": 27.73,
    "hellaswag": 26.01,
    "truthfulqa": 48.69,
    "mmlu": 24.97,
    "gsm8k": 8.95,
    "winogrande": 74.74,
    "average": 35.18
  },
  "TheBloke/wizard-vicuna-13B-GPTQ": {
    "arc": 28.67,
    "hellaswag": 25.94,
    "truthfulqa": 48.53,
    "mmlu": 25.84,
    "gsm8k": 9.63,
    "winogrande": 74.74,
    "average": 35.56
  },
  "TheBloke/wizard-vicuna-13B-HF": {
    "arc": 54.69,
    "hellaswag": 79.18,
    "truthfulqa": 49.62,
    "mmlu": 48.88,
    "gsm8k": 9.33,
    "winogrande": 74.82,
    "average": 52.75
  },
  "TheBloke/wizardLM-13B-1.0-fp16": {
    "arc": 57.25,
    "hellaswag": 80.88,
    "truthfulqa": 50.55,
    "mmlu": 52.9,
    "gsm8k": 13.87,
    "winogrande": 74.11,
    "average": 54.93
  },
  "TheBloke/wizardLM-7B-HF": {
    "arc": 50.34,
    "hellaswag": 75.27,
    "truthfulqa": 45.58,
    "mmlu": 38.07
  },
  "TheTravellingEngineer/bloom-1b1-RLHF": {
    "arc": 27.99,
    "hellaswag": 26.19,
    "truthfulqa": 48.88,
    "mmlu": 26.86,
    "gsm8k": 0,
    "winogrande": 50.91,
    "average": 30.14
  },
  "TheTravellingEngineer/bloom-1b1-RLHF-v2": {
    "gsm8k": 0,
    "winogrande": 49.57
  },
  "TheTravellingEngineer/bloom-560m-RLHF": {
    "arc": 24.4,
    "hellaswag": 36.96,
    "truthfulqa": 40.76,
    "mmlu": 23.63,
    "gsm8k": 0.3,
    "winogrande": 53.12,
    "average": 29.86
  },
  "TheTravellingEngineer/bloom-560m-RLHF-v2": {
    "arc": 26.45,
    "hellaswag": 37.67,
    "truthfulqa": 43.51,
    "mmlu": 23.95,
    "gsm8k": 0.08,
    "winogrande": 50.91,
    "average": 30.43
  },
  "TheTravellingEngineer/llama2-7b-chat-hf-dpo": {
    "arc": 53.67,
    "hellaswag": 78.79,
    "truthfulqa": 43.97,
    "mmlu": 46.78,
    "gsm8k": 7.35,
    "winogrande": 71.74,
    "average": 50.38
  },
  "TheTravellingEngineer/llama2-7b-chat-hf-guanaco": {
    "arc": 50.51,
    "hellaswag": 76.72,
    "truthfulqa": 43.36,
    "mmlu": 48.03,
    "gsm8k": 8.57,
    "winogrande": 72.93,
    "average": 50.02
  },
  "TheTravellingEngineer/llama2-7b-chat-hf-v2": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.8,
    "gsm8k": 7.13,
    "winogrande": 74.03,
    "average": 49.73
  },
  "TheTravellingEngineer/llama2-7b-chat-hf-v3": {
    "arc": 51.96,
    "hellaswag": 76.7,
    "truthfulqa": 38.31,
    "mmlu": 45.36,
    "gsm8k": 5.99,
    "winogrande": 73.56,
    "average": 48.65
  },
  "TheTravellingEngineer/llama2-7b-chat-hf-v4": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.8,
    "gsm8k": 7.51,
    "winogrande": 74.03,
    "average": 49.79
  },
  "TheTravellingEngineer/llama2-7b-hf-guanaco": {
    "arc": 52.47,
    "hellaswag": 78.75,
    "truthfulqa": 43.9,
    "mmlu": 45.33,
    "gsm8k": 6.07,
    "winogrande": 74.19,
    "average": 50.12
  },
  "TigerResearch/tigerbot-13b-base": {
    "arc": 53.84,
    "hellaswag": 77.05,
    "truthfulqa": 44.06,
    "mmlu": 53.57,
    "gsm8k": 17.06,
    "winogrande": 74.98,
    "average": 53.43
  },
  "TigerResearch/tigerbot-70b-base": {
    "arc": 62.46,
    "hellaswag": 83.61,
    "truthfulqa": 52.76,
    "mmlu": 65.49,
    "gsm8k": 37.76,
    "winogrande": 80.19,
    "average": 63.71
  },
  "TigerResearch/tigerbot-70b-chat": {
    "arc": 76.79,
    "hellaswag": 87.83,
    "truthfulqa": 55.1,
    "mmlu": 66.08,
    "gsm8k": 45.64,
    "winogrande": 77.58,
    "average": 68.17
  },
  "TigerResearch/tigerbot-70b-chat-v2": {
    "arc": 87.03,
    "hellaswag": 82.83,
    "truthfulqa": 75.4,
    "winogrande": 79.16,
    "gsm8k": 54.36,
    "mmlu": 66,
    "average": 74.13
  },
  "TigerResearch/tigerbot-7b-base": {
    "arc": 47.7,
    "hellaswag": 72.08,
    "truthfulqa": 42.27,
    "mmlu": 45.11,
    "gsm8k": 10.84,
    "winogrande": 69.61,
    "average": 47.94
  },
  "TigerResearch/tigerbot-7b-sft": {
    "arc": 41.64,
    "hellaswag": 60.56,
    "truthfulqa": 58.18,
    "mmlu": 29.89,
    "gsm8k": 6.29,
    "winogrande": 63.54,
    "average": 43.35
  },
  "Tincando/fiction_story_generator": {
    "arc": 23.29,
    "hellaswag": 28.68,
    "truthfulqa": 43.79,
    "mmlu": 26.72,
    "gsm8k": 0,
    "winogrande": 50.12,
    "average": 28.77
  },
  "TinyLlama/TinyLlama-1.1B-Chat-v0.6": {
    "arc": 31.66,
    "hellaswag": 55.79,
    "truthfulqa": 34.72,
    "winogrande": 59.35,
    "gsm8k": 2.12,
    "mmlu": 25.98,
    "average": 34.94
  },
  "TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T": {
    "arc": 30.29,
    "hellaswag": 54.84,
    "truthfulqa": 36.07,
    "winogrande": 58.33,
    "gsm8k": 1.36,
    "mmlu": 26.47,
    "average": 34.56
  },
  "TinyPixel/elm-test": {
    "arc": 53.16,
    "hellaswag": 78.98,
    "truthfulqa": 39.51,
    "mmlu": 47.04,
    "gsm8k": 7.51,
    "winogrande": 74.35,
    "average": 50.09
  },
  "TinyPixel/lima-test": {
    "arc": 53.07,
    "hellaswag": 78.88,
    "truthfulqa": 39.4,
    "mmlu": 46.42,
    "gsm8k": 7.96,
    "winogrande": 74.03,
    "average": 49.96
  },
  "TinyPixel/llama2-7b-instruct": {
    "arc": 53.58,
    "hellaswag": 78.78,
    "truthfulqa": 39.48,
    "mmlu": 46.11
  },
  "TinyPixel/llama2-7b-oa": {
    "arc": 53.41,
    "hellaswag": 78.72,
    "truthfulqa": 41.06,
    "mmlu": 46.68
  },
  "TinyPixel/testmodel-3": {
    "arc": 53.24,
    "hellaswag": 78.72,
    "truthfulqa": 38.75,
    "mmlu": 46.57,
    "gsm8k": 7.58,
    "winogrande": 73.88,
    "average": 49.79
  },
  "TinyPixel/testmodel2": {
    "arc": 53.24,
    "hellaswag": 78.78,
    "truthfulqa": 39.17,
    "mmlu": 46.61,
    "gsm8k": 7.66,
    "winogrande": 73.8,
    "average": 49.88
  },
  "ToolBench/ToolLLaMA-7b-LoRA": {
    "arc": 52.99,
    "hellaswag": 78.62,
    "truthfulqa": 38.67,
    "mmlu": 46.87,
    "gsm8k": 6.82,
    "winogrande": 74.35,
    "average": 49.72
  },
  "TurkuNLP/gpt3-finnish-13B": {
    "arc": 24.66,
    "hellaswag": 46.76,
    "truthfulqa": 44.47,
    "mmlu": 23.49,
    "gsm8k": 0.3,
    "winogrande": 58.01,
    "average": 32.95
  },
  "TurkuNLP/gpt3-finnish-large": {
    "arc": 21.76,
    "hellaswag": 32.88,
    "truthfulqa": 44.35,
    "mmlu": 24.11,
    "gsm8k": 0,
    "winogrande": 51.54,
    "average": 29.11
  },
  "TurkuNLP/gpt3-finnish-small": {
    "arc": 20.48,
    "hellaswag": 28.09,
    "truthfulqa": 46.47,
    "mmlu": 24.47,
    "gsm8k": 0,
    "winogrande": 48.22,
    "average": 27.96
  },
  "Undi95/Amethyst-13B": {
    "arc": 62.63,
    "hellaswag": 83.17,
    "truthfulqa": 52.43,
    "mmlu": 55.91,
    "gsm8k": 10.84,
    "winogrande": 74.74,
    "average": 56.62
  },
  "Undi95/Amethyst-13B-Mistral": {
    "arc": 62.63,
    "hellaswag": 83.17,
    "truthfulqa": 52.43,
    "mmlu": 55.91,
    "gsm8k": 10.84,
    "winogrande": 74.74,
    "average": 56.62
  },
  "Undi95/CodeEngine": {
    "arc": 58.36,
    "hellaswag": 82.27,
    "truthfulqa": 45.18,
    "mmlu": 54.18,
    "gsm8k": 1.52,
    "winogrande": 74.59,
    "average": 52.68
  },
  "Undi95/CreativityEngine": {
    "arc": 59.3,
    "hellaswag": 82.42,
    "truthfulqa": 52.46,
    "mmlu": 53.55,
    "gsm8k": 9.55,
    "winogrande": 74.19,
    "average": 55.25
  },
  "Undi95/Emerald-13B": {
    "arc": 62.29,
    "hellaswag": 83.69,
    "truthfulqa": 50.94,
    "mmlu": 55.7,
    "gsm8k": 12.81,
    "winogrande": 75.93,
    "average": 56.89
  },
  "Undi95/Emerhyst-20B": {
    "arc": 61.69,
    "hellaswag": 84.98,
    "truthfulqa": 54.16,
    "mmlu": 56.98,
    "gsm8k": 8.49,
    "winogrande": 76.09,
    "average": 57.07
  },
  "Undi95/LewdEngine": {
    "arc": 60.49,
    "hellaswag": 83.08,
    "truthfulqa": 43.63,
    "mmlu": 54.84,
    "gsm8k": 12.36,
    "winogrande": 74.9,
    "average": 54.88
  },
  "Undi95/Llama2-13B-no_robots-alpaca-lora": {
    "arc": 58.87,
    "hellaswag": 82.43,
    "truthfulqa": 40.46,
    "winogrande": 75.3,
    "gsm8k": 6.44,
    "mmlu": 53.11,
    "average": 52.77
  },
  "Undi95/MLewd-Chat-v2-13B": {
    "arc": 61.86,
    "hellaswag": 83.81,
    "truthfulqa": 54.51,
    "mmlu": 57,
    "gsm8k": 10.46,
    "winogrande": 75.77,
    "average": 57.23
  },
  "Undi95/MLewd-L2-13B": {
    "arc": 58.28,
    "hellaswag": 82.32,
    "truthfulqa": 48.66,
    "mmlu": 54.67,
    "gsm8k": 1.29,
    "winogrande": 73.48,
    "average": 53.12
  },
  "Undi95/MLewd-L2-Chat-13B": {
    "arc": 62.03,
    "hellaswag": 84.19,
    "truthfulqa": 52.84,
    "mmlu": 58.75,
    "gsm8k": 11.3,
    "winogrande": 77.43,
    "average": 57.76
  },
  "Undi95/MLewd-ReMM-L2-Chat-20B": {
    "arc": 62.46,
    "hellaswag": 85.62,
    "truthfulqa": 55.63,
    "mmlu": 59.13,
    "gsm8k": 10.92,
    "winogrande": 77.19,
    "average": 58.49
  },
  "Undi95/MLewd-ReMM-L2-Chat-20B-Inverted": {
    "arc": 61.69,
    "hellaswag": 85.32,
    "truthfulqa": 53.77,
    "mmlu": 58,
    "gsm8k": 9.1,
    "winogrande": 75.61,
    "average": 57.25
  },
  "Undi95/MLewd-v2.4-13B": {
    "arc": 61.69,
    "hellaswag": 83.83,
    "truthfulqa": 53.34,
    "mmlu": 55.1,
    "gsm8k": 9.78,
    "winogrande": 74.51,
    "average": 56.37
  },
  "Undi95/MLewdBoros-L2-13B": {
    "arc": 62.54,
    "hellaswag": 83.9,
    "truthfulqa": 48.14,
    "mmlu": 56.57,
    "gsm8k": 10.99,
    "winogrande": 76.95,
    "average": 56.51
  },
  "Undi95/MM-ReMM-L2-20B": {
    "arc": 60.84,
    "hellaswag": 85.18,
    "truthfulqa": 53.33,
    "mmlu": 56.45,
    "gsm8k": 7.73,
    "winogrande": 75.77,
    "average": 56.55
  },
  "Undi95/MXLewd-L2-20B": {
    "arc": 63.23,
    "hellaswag": 85.33,
    "truthfulqa": 51.65,
    "mmlu": 57.36,
    "gsm8k": 10.92,
    "winogrande": 76.09,
    "average": 57.43
  },
  "Undi95/Mistral-11B-TestBench10": {
    "arc": 64.25,
    "hellaswag": 84.24,
    "truthfulqa": 55.57,
    "mmlu": 63.9
  },
  "Undi95/Mistral-11B-TestBench11": {
    "arc": 64.42,
    "hellaswag": 83.93,
    "truthfulqa": 56.68,
    "mmlu": 63.82,
    "gsm8k": 14.94,
    "winogrande": 77.74,
    "average": 60.26
  },
  "Undi95/Mistral-11B-TestBench3": {
    "arc": 62.03,
    "hellaswag": 83.92,
    "truthfulqa": 53.66,
    "mmlu": 63.11
  },
  "Undi95/Mistral-11B-TestBench7": {
    "arc": 63.31,
    "hellaswag": 82.86,
    "truthfulqa": 46.91,
    "mmlu": 64.09
  },
  "Undi95/Mistral-11B-TestBench9": {
    "arc": 64.08,
    "hellaswag": 84.24,
    "truthfulqa": 56.19,
    "mmlu": 64,
    "gsm8k": 16.15,
    "winogrande": 78.45,
    "average": 60.52
  },
  "Undi95/Nous-Hermes-13B-Code": {
    "arc": 61.18,
    "hellaswag": 83.21,
    "truthfulqa": 50.56,
    "mmlu": 55.13,
    "gsm8k": 10.39,
    "winogrande": 75.14,
    "average": 55.93
  },
  "Undi95/OpenRP-13B": {
    "arc": 62.12,
    "hellaswag": 82.6,
    "truthfulqa": 48.29,
    "mmlu": 57.5,
    "gsm8k": 12.89,
    "winogrande": 76.01,
    "average": 56.57
  },
  "Undi95/ReMM-L2-13B": {
    "arc": 59.73,
    "hellaswag": 83.1,
    "truthfulqa": 49.94,
    "mmlu": 54.11,
    "gsm8k": 2.96,
    "winogrande": 74.51,
    "average": 54.06
  },
  "Undi95/ReMM-L2-13B-PIPPA": {
    "arc": 59.73,
    "hellaswag": 83.12,
    "truthfulqa": 49.94,
    "mmlu": 54.1,
    "gsm8k": 2.96,
    "winogrande": 74.51,
    "average": 54.06
  },
  "Undi95/ReMM-Mistral-13B": {
    "arc": 62.2,
    "hellaswag": 83.82,
    "truthfulqa": 53.32,
    "mmlu": 55.43,
    "gsm8k": 12.05,
    "winogrande": 74.51,
    "average": 56.89
  },
  "Undi95/ReMM-SLERP-L2-13B": {
    "arc": 60.92,
    "hellaswag": 83.56,
    "truthfulqa": 51.97,
    "mmlu": 55.33,
    "gsm8k": 9.17,
    "winogrande": 75.22,
    "average": 56.03
  },
  "Undi95/ReMM-v2-L2-13B": {
    "arc": 61.95,
    "hellaswag": 84,
    "truthfulqa": 50.81,
    "mmlu": 56.14,
    "gsm8k": 13.19,
    "winogrande": 75.85,
    "average": 56.99
  },
  "Undi95/ReMM-v2.1-L2-13B": {
    "arc": 61.43,
    "hellaswag": 83.92,
    "truthfulqa": 50.3,
    "mmlu": 55.95,
    "gsm8k": 12.74,
    "winogrande": 75.93,
    "average": 56.71
  },
  "Undi95/ReMM-v2.2-L2-13B": {
    "arc": 61.26,
    "hellaswag": 84.16,
    "truthfulqa": 51.35,
    "mmlu": 56.22,
    "gsm8k": 14.03,
    "winogrande": 75.61,
    "average": 57.11
  },
  "Undi95/U-Amethyst-20B": {
    "arc": 62.2,
    "hellaswag": 83.11,
    "truthfulqa": 53.2,
    "mmlu": 55.88,
    "gsm8k": 5.31,
    "winogrande": 74.19,
    "average": 55.65
  },
  "Undi95/UndiMix-v1-13b": {
    "arc": 59.47,
    "hellaswag": 82.45,
    "truthfulqa": 49.78,
    "mmlu": 55.83,
    "gsm8k": 10.01,
    "winogrande": 75.45,
    "average": 55.5
  },
  "Undi95/UndiMix-v4-13B": {
    "arc": 61.95,
    "hellaswag": 83.88,
    "truthfulqa": 48.96,
    "mmlu": 56.9,
    "gsm8k": 13.72,
    "winogrande": 76.16,
    "average": 56.93
  },
  "Undi95/Unholy-v1-12L-13B": {
    "arc": 63.57,
    "hellaswag": 83.75,
    "truthfulqa": 51.09,
    "mmlu": 58.08,
    "gsm8k": 11.07,
    "winogrande": 77.27,
    "average": 57.47
  },
  "Undi95/llama2-to-mistral-diff": {
    "arc": 53.41,
    "hellaswag": 78.56,
    "truthfulqa": 38.71,
    "mmlu": 46.43,
    "gsm8k": 7.51,
    "winogrande": 74.03,
    "average": 49.78
  },
  "VAGOsolutions/SauerkrautLM-7b-HerO": {
    "arc": 63.23,
    "hellaswag": 83.52,
    "truthfulqa": 49.22,
    "winogrande": 78.37,
    "gsm8k": 49.28,
    "mmlu": 63.3,
    "average": 64.49
  },
  "VMware/open-llama-0.7T-7B-open-instruct-v1.1": {
    "arc": 46.67,
    "hellaswag": 67.67,
    "truthfulqa": 37.6,
    "mmlu": 28.55,
    "gsm8k": 0.76,
    "winogrande": 65.43,
    "average": 41.11
  },
  "VMware/open-llama-7b-open-instruct": {
    "arc": 49.74,
    "hellaswag": 73.67,
    "truthfulqa": 34.65,
    "mmlu": 31.52,
    "gsm8k": 0.53,
    "winogrande": 65.43,
    "average": 42.59
  },
  "VMware/open-llama-7b-v2-open-instruct": {
    "arc": 39.76,
    "hellaswag": 70.31,
    "truthfulqa": 39.53,
    "mmlu": 35.16,
    "gsm8k": 7.43,
    "winogrande": 64.33,
    "average": 42.75
  },
  "ValiantLabs/ShiningValiant": {
    "arc": 72.95,
    "hellaswag": 87.88,
    "truthfulqa": 64.88,
    "mmlu": 70.97
  },
  "ValiantLabs/ShiningValiantXS": {
    "arc": 64.42,
    "hellaswag": 83.58,
    "truthfulqa": 55,
    "winogrande": 76.8,
    "gsm8k": 34.72,
    "mmlu": 60.37,
    "average": 62.48
  },
  "Voicelab/trurl-2-13b": {
    "arc": 60.07,
    "hellaswag": 80.23,
    "truthfulqa": 45.95,
    "mmlu": 78.59,
    "gsm8k": 12.81,
    "winogrande": 74.74,
    "average": 58.73
  },
  "Voicelab/trurl-2-13b-academic": {
    "arc": 57.94,
    "hellaswag": 79.55,
    "truthfulqa": 43.46,
    "mmlu": 55.2,
    "gsm8k": 10.92,
    "winogrande": 76.56,
    "average": 53.94
  },
  "Voicelab/trurl-2-7b": {
    "arc": 53.41,
    "hellaswag": 75.29,
    "truthfulqa": 45.42,
    "mmlu": 50,
    "gsm8k": 7.13,
    "winogrande": 72.22,
    "average": 50.58
  },
  "Walmart-the-bag/Misted-7B": {
    "arc": 63.65,
    "hellaswag": 84.14,
    "truthfulqa": 52,
    "winogrande": 78.3,
    "gsm8k": 59.59,
    "mmlu": 63.94,
    "average": 66.94
  },
  "Walmart-the-bag/MysticFusion-13B": {
    "arc": 61.35,
    "hellaswag": 84.43,
    "truthfulqa": 51.98,
    "winogrande": 76.01,
    "gsm8k": 24.79,
    "mmlu": 57.29,
    "average": 59.31
  },
  "WangZeJun/bloom-820m-chat": {
    "arc": 23.38,
    "hellaswag": 34.16,
    "truthfulqa": 40.32,
    "mmlu": 25.98,
    "gsm8k": 0,
    "winogrande": 53.2,
    "average": 29.51
  },
  "WeOpenML/Alpaca-7B-v1": {
    "arc": 49.06,
    "hellaswag": 75.71,
    "truthfulqa": 36.28,
    "mmlu": 33.76,
    "gsm8k": 0.15,
    "winogrande": 71.51,
    "average": 44.41
  },
  "WeOpenML/PandaLM-Alpaca-7B-v1": {
    "arc": 50.85,
    "hellaswag": 77.36,
    "truthfulqa": 36.63,
    "mmlu": 35.91,
    "gsm8k": 0.91,
    "winogrande": 71.9,
    "average": 45.59
  },
  "WebraftAI/synapsellm-7b-mistral-v0.3-preview": {
    "arc": 53.84,
    "hellaswag": 74.86,
    "truthfulqa": 55.03,
    "winogrande": 74.59,
    "gsm8k": 28.96,
    "mmlu": 54.81,
    "average": 57.01
  },
  "Weyaxi/ChatAYT-Lora-Assamble-Marcoroni": {
    "arc": 62.46,
    "hellaswag": 83.05,
    "truthfulqa": 56.12,
    "mmlu": 58.72,
    "gsm8k": 8.87,
    "winogrande": 77.35,
    "average": 57.76
  },
  "Weyaxi/Dolphin-Nebula-7B": {
    "arc": 55.2,
    "hellaswag": 78.57,
    "truthfulqa": 57.97,
    "winogrande": 73.88,
    "gsm8k": 33.06,
    "mmlu": 53.44,
    "average": 58.69
  },
  "Weyaxi/Dolphin2.1-OpenOrca-7B": {
    "arc": 64.16,
    "hellaswag": 84.25,
    "truthfulqa": 53.83,
    "winogrande": 77.66,
    "gsm8k": 19.71,
    "mmlu": 62.7,
    "average": 60.38
  },
  "Weyaxi/HelpSteer-filtered-7B": {
    "arc": 59.56,
    "hellaswag": 83.32,
    "truthfulqa": 41.11,
    "winogrande": 76.01,
    "gsm8k": 33.43,
    "mmlu": 63.52,
    "average": 59.49
  },
  "Weyaxi/Luban-Marcoroni-13B": {
    "arc": 63.65,
    "hellaswag": 82.92,
    "truthfulqa": 55.55,
    "mmlu": 58.7,
    "gsm8k": 10.01,
    "winogrande": 77.03,
    "average": 57.98
  },
  "Weyaxi/Luban-Marcoroni-13B-v2": {
    "arc": 63.48,
    "hellaswag": 82.89,
    "truthfulqa": 55.56,
    "mmlu": 58.72,
    "gsm8k": 9.93,
    "winogrande": 76.95,
    "average": 57.92
  },
  "Weyaxi/Luban-Marcoroni-13B-v3": {
    "arc": 63.74,
    "hellaswag": 82.88,
    "truthfulqa": 55.56,
    "mmlu": 58.64,
    "gsm8k": 9.93,
    "winogrande": 76.87,
    "average": 57.94
  },
  "Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B": {
    "arc": 66.55,
    "hellaswag": 84.47,
    "truthfulqa": 61.22,
    "winogrande": 78.37,
    "gsm8k": 53.07,
    "mmlu": 63.34,
    "average": 67.84
  },
  "Weyaxi/OpenOrca-Nebula-7B": {
    "arc": 58.7,
    "hellaswag": 81.84,
    "truthfulqa": 53.18,
    "mmlu": 57.77
  },
  "Weyaxi/OpenOrca-Zephyr-7B": {
    "arc": 64.08,
    "hellaswag": 83.82,
    "truthfulqa": 54.31,
    "winogrande": 78.93,
    "gsm8k": 46.25,
    "mmlu": 62.46,
    "average": 64.97
  },
  "Weyaxi/Platypus-Nebula-v2-7B": {
    "arc": 55.38,
    "hellaswag": 83.02,
    "truthfulqa": 46.94,
    "winogrande": 72.22,
    "gsm8k": 10.08,
    "mmlu": 56.07,
    "average": 53.95
  },
  "Weyaxi/Samantha-Nebula-7B": {
    "arc": 57,
    "hellaswag": 82.25,
    "truthfulqa": 49.58,
    "mmlu": 54.21,
    "gsm8k": 11.37,
    "winogrande": 73.09,
    "average": 54.58
  },
  "Weyaxi/SlimOpenOrca-Mistral-7B": {
    "arc": 62.97,
    "hellaswag": 83.49,
    "truthfulqa": 57.39,
    "mmlu": 62.3,
    "gsm8k": 21.46,
    "winogrande": 77.43,
    "average": 60.84
  },
  "Weyaxi/SynthIA-v1.3-Nebula-v2-7B": {
    "arc": 59.39,
    "hellaswag": 82.77,
    "truthfulqa": 50.62,
    "winogrande": 74.74,
    "gsm8k": 24.87,
    "mmlu": 57.57,
    "average": 58.33
  },
  "Weyaxi/TekniumAiroboros-Nebula-7B": {
    "arc": 57.17,
    "hellaswag": 81.72,
    "truthfulqa": 51.64,
    "winogrande": 73.24,
    "gsm8k": 9.4,
    "mmlu": 55.25,
    "average": 54.74
  },
  "Weyaxi/llama-2-alpacagpt4-1000step": {
    "arc": 66.38,
    "hellaswag": 84.51,
    "truthfulqa": 55.57,
    "mmlu": 62.75,
    "gsm8k": 16.38,
    "winogrande": 80.35,
    "average": 60.99
  },
  "Weyaxi/neural-chat-7b-v3-1-Nebula-v2-7B": {
    "arc": 61.77,
    "hellaswag": 80.21,
    "truthfulqa": 58.56,
    "winogrande": 71.82,
    "gsm8k": 4.62,
    "mmlu": 59.07,
    "average": 56.01
  },
  "Weyaxi/neural-chat-7b-v3-1-OpenHermes-2.5-7B": {
    "arc": 66.13,
    "hellaswag": 84.09,
    "truthfulqa": 61.23,
    "winogrande": 77.58,
    "gsm8k": 50.87,
    "mmlu": 63.22,
    "average": 67.19
  },
  "Weyaxi/test-help-steer-filtered-orig": {
    "arc": 57.59,
    "hellaswag": 80.42,
    "truthfulqa": 41.1,
    "winogrande": 76.64,
    "gsm8k": 9.63,
    "mmlu": 57.24,
    "average": 53.77
  },
  "Weyaxi/zephyr-alpha-Nebula-v2-7B": {
    "arc": 58.62,
    "hellaswag": 83.05,
    "truthfulqa": 58.28,
    "winogrande": 73.56,
    "gsm8k": 23.88,
    "mmlu": 56.68,
    "average": 59.01
  },
  "Weyaxi/zephyr-beta-Nebula-v2-7B": {
    "arc": 56.57,
    "hellaswag": 82.53,
    "truthfulqa": 58.68,
    "winogrande": 70.48,
    "gsm8k": 17.51,
    "mmlu": 56.4,
    "average": 57.03
  },
  "WhoTookMyAmogusNickname/NewHope_HF_not_official": {
    "arc": 61.09,
    "hellaswag": 84.03,
    "truthfulqa": 44.96,
    "mmlu": 55.73,
    "gsm8k": 15.85,
    "winogrande": 74.98,
    "average": 56.11
  },
  "WizardLM/WizardCoder-15B-V1.0": {
    "arc": 32.34,
    "hellaswag": 47.2,
    "truthfulqa": 41.56,
    "mmlu": 29.43,
    "gsm8k": 2.12,
    "winogrande": 55.17,
    "average": 34.64
  },
  "WizardLM/WizardCoder-Python-34B-V1.0": {
    "arc": 52.13,
    "hellaswag": 74.78,
    "truthfulqa": 48.85,
    "mmlu": 49.15,
    "gsm8k": 9.48,
    "winogrande": 68.35,
    "average": 50.46
  },
  "WizardLM/WizardCoder-Python-7B-V1.0": {
    "arc": 41.81,
    "hellaswag": 65.06,
    "truthfulqa": 36.32,
    "mmlu": 32.29,
    "gsm8k": 4.7,
    "winogrande": 61.72,
    "average": 40.32
  },
  "WizardLM/WizardLM-13B-V1.1": {
    "arc": 60.24,
    "hellaswag": 81.39,
    "truthfulqa": 54.56,
    "mmlu": 50.92,
    "gsm8k": 8.11,
    "winogrande": 75.06,
    "average": 55.05
  },
  "WizardLM/WizardLM-13B-V1.2": {
    "arc": 59.04,
    "hellaswag": 82.21,
    "truthfulqa": 47.27,
    "mmlu": 54.64,
    "gsm8k": 13.5,
    "winogrande": 71.9,
    "average": 54.76
  },
  "WizardLM/WizardLM-30B-V1.0": {
    "arc": 27.39,
    "hellaswag": 25.94,
    "truthfulqa": 48.61,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 48.7,
    "average": 28.96
  },
  "WizardLM/WizardLM-70B-V1.0": {
    "arc": 64.08,
    "hellaswag": 85.4,
    "truthfulqa": 54.76,
    "mmlu": 64.97,
    "gsm8k": 17.97,
    "winogrande": 80.82,
    "average": 61.33
  },
  "WizardLM/WizardMath-13B-V1.0": {
    "arc": 60.07,
    "hellaswag": 82.01,
    "truthfulqa": 42.7,
    "mmlu": 54.8,
    "gsm8k": 12.36,
    "winogrande": 71.9,
    "average": 53.97
  },
  "WizardLM/WizardMath-70B-V1.0": {
    "arc": 65.96,
    "hellaswag": 85.95,
    "truthfulqa": 50.09,
    "mmlu": 67.64,
    "gsm8k": 3.94,
    "winogrande": 82.32,
    "average": 59.32
  },
  "WizardLM/WizardMath-7B-V1.0": {
    "arc": 54.1,
    "hellaswag": 79.55,
    "truthfulqa": 43.65,
    "mmlu": 45.97,
    "gsm8k": 2.73,
    "winogrande": 72.69,
    "average": 49.78
  },
  "Writer/InstructPalmyra-20b": {
    "arc": 47.1,
    "hellaswag": 73,
    "truthfulqa": 41.81,
    "mmlu": 28.26,
    "gsm8k": 2.58,
    "winogrande": 64.72,
    "average": 42.91
  },
  "Writer/camel-5b-hf": {
    "arc": 35.15,
    "hellaswag": 57.62,
    "truthfulqa": 40.65,
    "mmlu": 26.07,
    "gsm8k": 0.38,
    "winogrande": 61.01,
    "average": 36.81
  },
  "Writer/palmyra-20b-chat": {
    "arc": 43.52,
    "hellaswag": 72.83,
    "truthfulqa": 43.17,
    "mmlu": 35.18,
    "gsm8k": 3.94,
    "winogrande": 66.46,
    "average": 44.18
  },
  "Writer/palmyra-base": {
    "arc": 31.91,
    "hellaswag": 55.39,
    "truthfulqa": 37.57,
    "mmlu": 27.15,
    "gsm8k": 0.99,
    "winogrande": 58.09,
    "average": 35.18
  },
  "Writer/palmyra-large": {
    "arc": 44.97,
    "hellaswag": 71.85,
    "truthfulqa": 35.93,
    "mmlu": 28.54,
    "gsm8k": 3.41,
    "winogrande": 67.88,
    "average": 42.1
  },
  "Writer/palmyra-med-20b": {
    "arc": 46.76,
    "hellaswag": 73.54,
    "truthfulqa": 35.53,
    "mmlu": 44.36,
    "gsm8k": 2.65,
    "winogrande": 65.35,
    "average": 44.7
  },
  "Xilabs/calypso-3b-alpha-v2": {
    "arc": 41.55,
    "hellaswag": 71.48,
    "truthfulqa": 35.73,
    "mmlu": 25.82,
    "gsm8k": 0.68,
    "winogrande": 65.27,
    "average": 40.09
  },
  "Xwin-LM/Xwin-LM-13B-V0.1": {
    "arc": 62.54,
    "hellaswag": 82.8,
    "truthfulqa": 45.96,
    "mmlu": 56.53,
    "gsm8k": 9.63,
    "winogrande": 74.27,
    "average": 55.29
  },
  "Xwin-LM/Xwin-LM-70B-V0.1": {
    "arc": 70.22,
    "hellaswag": 87.25,
    "truthfulqa": 59.86,
    "mmlu": 69.77,
    "gsm8k": 27.22,
    "winogrande": 82.87,
    "average": 66.2
  },
  "Xwin-LM/Xwin-LM-7B-V0.1": {
    "arc": 56.57,
    "hellaswag": 79.4,
    "truthfulqa": 47.89,
    "mmlu": 49.98,
    "gsm8k": 5.31,
    "winogrande": 73.32,
    "average": 52.08
  },
  "Yehoon/yehoon_llama2": {
    "arc": 54.78,
    "hellaswag": 78.98,
    "truthfulqa": 49.17,
    "mmlu": 51.29,
    "gsm8k": 7.28,
    "winogrande": 74.74,
    "average": 52.71
  },
  "YeungNLP/firefly-bloom-2b6-v2": {
    "arc": 27.65,
    "hellaswag": 39.23,
    "truthfulqa": 42.27,
    "mmlu": 25.24,
    "gsm8k": 1.74,
    "winogrande": 54.78,
    "average": 31.82
  },
  "YeungNLP/firefly-bloom-7b1": {
    "arc": 40.44,
    "hellaswag": 61.2,
    "truthfulqa": 40.83,
    "mmlu": 26.83,
    "gsm8k": 0.68,
    "winogrande": 64.56,
    "average": 39.09
  },
  "YeungNLP/firefly-llama-13b": {
    "arc": 58.96,
    "hellaswag": 79.71,
    "truthfulqa": 49.59,
    "mmlu": 49.1,
    "gsm8k": 8.19,
    "winogrande": 75.61,
    "average": 53.53
  },
  "YeungNLP/firefly-llama-13b-v1.2": {
    "arc": 56.74,
    "hellaswag": 80.34,
    "truthfulqa": 51,
    "mmlu": 48.9,
    "gsm8k": 8.04,
    "winogrande": 75.93,
    "average": 53.49
  },
  "YeungNLP/firefly-llama-30b": {
    "arc": 64.25,
    "hellaswag": 83.64,
    "truthfulqa": 53.2,
    "mmlu": 58.23,
    "gsm8k": 15.85,
    "winogrande": 77.43,
    "average": 58.77
  },
  "YeungNLP/firefly-llama2-13b": {
    "arc": 59.13,
    "hellaswag": 81.99,
    "truthfulqa": 51.57,
    "mmlu": 55.49,
    "gsm8k": 11.22,
    "winogrande": 74.66,
    "average": 55.68
  },
  "YeungNLP/firefly-llama2-13b-chat": {
    "arc": 57.51,
    "hellaswag": 77.94,
    "truthfulqa": 48.18,
    "mmlu": 52.56,
    "gsm8k": 9.86,
    "winogrande": 74.74,
    "average": 53.47
  },
  "YeungNLP/firefly-llama2-13b-pretrain": {
    "arc": 53.92,
    "hellaswag": 79.1,
    "truthfulqa": 36.24,
    "mmlu": 51.25,
    "gsm8k": 8.57,
    "winogrande": 75.53,
    "average": 50.77
  },
  "YeungNLP/firefly-llama2-13b-v1.2": {
    "arc": 60.67,
    "hellaswag": 80.46,
    "truthfulqa": 51.03,
    "mmlu": 56.51,
    "gsm8k": 11.75,
    "winogrande": 74.82,
    "average": 55.87
  },
  "YeungNLP/firefly-llama2-7b-chat-temp": {
    "arc": 51.19,
    "hellaswag": 73.32,
    "truthfulqa": 46.78,
    "mmlu": 45.47
  },
  "YeungNLP/firefly-llama2-7b-pretrain": {
    "arc": 48.63,
    "hellaswag": 74.83,
    "truthfulqa": 39.08,
    "mmlu": 41.04,
    "gsm8k": 3.26,
    "winogrande": 70.24,
    "average": 46.18
  },
  "YeungNLP/firefly-ziya-13b": {
    "arc": 55.38,
    "hellaswag": 78.47,
    "truthfulqa": 49.29,
    "mmlu": 45.18,
    "gsm8k": 6.9,
    "winogrande": 74.82,
    "average": 51.67
  },
  "Yhyu13/chimera-inst-chat-13b-hf": {
    "arc": 55.38,
    "hellaswag": 78.93,
    "truthfulqa": 50.12,
    "mmlu": 50.6,
    "gsm8k": 8.19,
    "winogrande": 73.95,
    "average": 52.86
  },
  "Yhyu13/llama-30B-hf-openassitant": {
    "arc": 61.26,
    "hellaswag": 84.73,
    "truthfulqa": 42.27,
    "mmlu": 58.47,
    "gsm8k": 14.86,
    "winogrande": 80.03,
    "average": 56.94
  },
  "Yhyu13/oasst-rlhf-2-llama-30b-7k-steps-hf": {
    "arc": 61.35,
    "hellaswag": 83.8,
    "truthfulqa": 51.18,
    "mmlu": 57.89,
    "gsm8k": 31.46,
    "winogrande": 78.77,
    "average": 60.74
  },
  "Yukang/Llama-2-13b-chat-longlora-32k-sft": {
    "arc": 26.11,
    "hellaswag": 26.17,
    "truthfulqa": 49.07,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 64.09,
    "average": 31.43
  },
  "Yukang/Llama-2-13b-longlora-16k-ft": {
    "arc": 25.85,
    "hellaswag": 27.6,
    "truthfulqa": 48.89,
    "mmlu": 23.1,
    "gsm8k": 0,
    "winogrande": 49.57,
    "average": 29.17
  },
  "Yukang/Llama-2-13b-longlora-32k-ft": {
    "arc": 59.47,
    "hellaswag": 82.61,
    "truthfulqa": 37.44,
    "mmlu": 52.13,
    "gsm8k": 7.73,
    "winogrande": 75.53,
    "average": 52.48
  },
  "Yukang/Llama-2-7b-longlora-100k-ft": {
    "arc": 28.16,
    "hellaswag": 25.43,
    "truthfulqa": 49.06,
    "mmlu": 23.48,
    "gsm8k": 0,
    "winogrande": 48.38,
    "average": 29.09
  },
  "Yukang/Llama-2-7b-longlora-16k-ft": {
    "arc": 26.37,
    "hellaswag": 26.37,
    "truthfulqa": 47.76,
    "mmlu": 23.75,
    "gsm8k": 0,
    "winogrande": 48.62,
    "average": 28.81
  },
  "Yukang/Llama-2-7b-longlora-32k-ft": {
    "arc": 27.9,
    "hellaswag": 25.61,
    "truthfulqa": 49.57,
    "mmlu": 23.08,
    "gsm8k": 0,
    "winogrande": 49.01,
    "average": 29.19
  },
  "Yukang/LongAlpaca-13B": {
    "arc": 42.58,
    "hellaswag": 72.03,
    "truthfulqa": 36.85,
    "mmlu": 34.91,
    "gsm8k": 0,
    "winogrande": 64.09,
    "average": 41.74
  },
  "Yukang/LongAlpaca-7B": {
    "arc": 42.66,
    "hellaswag": 65.89,
    "truthfulqa": 40.16,
    "mmlu": 27.28,
    "gsm8k": 0,
    "winogrande": 60.14,
    "average": 39.35
  },
  "ZoidBB/unraveled-7b-a1": {
    "arc": 59.81,
    "hellaswag": 82.8,
    "truthfulqa": 42.23,
    "winogrande": 77.19,
    "gsm8k": 14.33,
    "mmlu": 63.39,
    "average": 56.62
  },
  "abacusai/Giraffe-beta-13b-32k": {
    "arc": 55.63,
    "hellaswag": 80.42,
    "truthfulqa": 42.58,
    "winogrande": 74.59,
    "gsm8k": 21.3,
    "mmlu": 53.61,
    "average": 54.69
  },
  "abhiramtirumala/DialoGPT-sarcastic-medium": {
    "arc": 23.29,
    "hellaswag": 25.93,
    "truthfulqa": 46.04,
    "mmlu": 23.76,
    "gsm8k": 0,
    "winogrande": 53.35,
    "average": 28.73
  },
  "abhishek/autotrain-llama-alpaca-peft-52508123785": {
    "arc": 52.22,
    "hellaswag": 76.92,
    "truthfulqa": 32.88,
    "mmlu": 37.6
  },
  "abhishek/ccy0-2g7e-wqsa-0": {
    "arc": 58.19,
    "hellaswag": 82.19,
    "truthfulqa": 49.99,
    "winogrande": 78.22,
    "gsm8k": 32.22,
    "mmlu": 59.59,
    "average": 60.07
  },
  "abhishek/llama2guanacotest": {
    "arc": 51.62,
    "hellaswag": 77.55,
    "truthfulqa": 43.88,
    "mmlu": 48.49,
    "gsm8k": 11.75,
    "winogrande": 73.16,
    "average": 51.08
  },
  "abhishek/zephyr-beta-math": {
    "arc": 56.66,
    "hellaswag": 81.26,
    "truthfulqa": 44.83,
    "winogrande": 75.53,
    "gsm8k": 56.41,
    "mmlu": 57.24,
    "average": 61.99
  },
  "acrastt/Bean-3B": {
    "arc": 40.36,
    "hellaswag": 72,
    "truthfulqa": 36.11,
    "mmlu": 26.43,
    "gsm8k": 0.53,
    "winogrande": 65.67,
    "average": 40.18
  },
  "acrastt/Griffin-3B": {
    "arc": 41.81,
    "hellaswag": 72.3,
    "truthfulqa": 38.33,
    "mmlu": 26.36,
    "gsm8k": 0.99,
    "winogrande": 67.01,
    "average": 41.13
  },
  "acrastt/Marx-3B": {
    "arc": 43.17,
    "hellaswag": 72.68,
    "truthfulqa": 39.09,
    "mmlu": 28.46,
    "gsm8k": 1.29,
    "winogrande": 65.59,
    "average": 41.71
  },
  "acrastt/Marx-3B-V2": {
    "arc": 44.03,
    "hellaswag": 72.92,
    "truthfulqa": 39.92,
    "mmlu": 27.84,
    "gsm8k": 1.21,
    "winogrande": 66.54,
    "average": 42.08
  },
  "acrastt/OmegLLaMA-3B": {
    "arc": 40.36,
    "hellaswag": 66.13,
    "truthfulqa": 33.31,
    "mmlu": 28,
    "gsm8k": 0.23,
    "winogrande": 61.64,
    "average": 38.28
  },
  "acrastt/Puma-3B": {
    "arc": 41.3,
    "hellaswag": 71.85,
    "truthfulqa": 38.34,
    "mmlu": 27.51,
    "gsm8k": 0.76,
    "winogrande": 66.38,
    "average": 41.02
  },
  "acrastt/RedPajama-INCITE-Chat-Instruct-3B-V1": {
    "arc": 42.58,
    "hellaswag": 67.48,
    "truthfulqa": 33.62,
    "mmlu": 25.99,
    "gsm8k": 0.91,
    "winogrande": 64.8,
    "average": 39.23
  },
  "adamo1139/Yi-34B-AEZAKMI-v1": {
    "arc": 64.33,
    "hellaswag": 84.31,
    "truthfulqa": 55.73,
    "winogrande": 80.82,
    "gsm8k": 52.92,
    "mmlu": 73.91,
    "average": 68.67
  },
  "adept/persimmon-8b-base": {
    "arc": 42.75,
    "hellaswag": 71.14,
    "truthfulqa": 37.85,
    "mmlu": 43.63
  },
  "adept/persimmon-8b-chat": {
    "arc": 44.97,
    "hellaswag": 73.3,
    "truthfulqa": 35.93,
    "mmlu": 44.98
  },
  "adonlee/LLaMA_2_13B_SFT_v0": {
    "arc": 62.03,
    "hellaswag": 83.8,
    "truthfulqa": 49.92,
    "mmlu": 58.39,
    "gsm8k": 12.43,
    "winogrande": 77.27,
    "average": 57.31
  },
  "adonlee/LLaMA_2_13B_SFT_v1": {
    "arc": 64.51,
    "hellaswag": 83.38,
    "truthfulqa": 53.2,
    "winogrande": 78.53,
    "gsm8k": 39.27,
    "mmlu": 58.6,
    "average": 62.92
  },
  "adonlee/LLaMA_2_13B_SFT_v1.5": {
    "gsm8k": 35.41
  },
  "adonlee/LLaMA_2_70B_LoRA": {
    "arc": 72.7,
    "hellaswag": 87.55,
    "truthfulqa": 64.52,
    "mmlu": 70.84
  },
  "ahnyeonchan/OpenOrca-AYT-13B": {
    "gsm8k": 0,
    "winogrande": 49.72
  },
  "ahxt/llama2_xs_460M_experimental": {
    "arc": 24.91,
    "hellaswag": 38.47,
    "truthfulqa": 41.59,
    "mmlu": 26.17,
    "gsm8k": 0,
    "winogrande": 49.88,
    "average": 30.17
  },
  "ai-business/Luban-13B": {
    "arc": 63.05,
    "hellaswag": 82.8,
    "truthfulqa": 55.53,
    "mmlu": 58.73,
    "gsm8k": 9.7,
    "winogrande": 76.56,
    "average": 57.73
  },
  "ai-forever/rugpt3large_based_on_gpt2": {
    "arc": 22.61,
    "hellaswag": 32.84,
    "truthfulqa": 43.39,
    "mmlu": 24.9,
    "gsm8k": 0.3,
    "winogrande": 53.12,
    "average": 29.53
  },
  "aiplanet/effi-13b": {
    "arc": 52.9,
    "hellaswag": 81.19,
    "truthfulqa": 44.95,
    "mmlu": 53.47
  },
  "aiplanet/effi-7b": {
    "arc": 55.12,
    "hellaswag": 78.07,
    "truthfulqa": 39.71,
    "mmlu": 35.91,
    "gsm8k": 3.18,
    "winogrande": 72.53,
    "average": 47.42
  },
  "aiplanet/panda-coder-13B": {
    "gsm8k": 0,
    "winogrande": 49.57
  },
  "aisquared/chopt-1_3b": {
    "arc": 31.48,
    "hellaswag": 56.63,
    "truthfulqa": 40.19,
    "mmlu": 25.35,
    "gsm8k": 0,
    "winogrande": 58.25,
    "average": 35.32
  },
  "aisquared/chopt-2_7b": {
    "arc": 36.01,
    "hellaswag": 63.38,
    "truthfulqa": 37.71,
    "mmlu": 25.44,
    "gsm8k": 0,
    "winogrande": 57.77,
    "average": 36.72
  },
  "aisquared/dlite-v1-124m": {
    "arc": 24.32,
    "hellaswag": 31.16,
    "truthfulqa": 36.38,
    "mmlu": 25.08,
    "gsm8k": 0,
    "winogrande": 50.2,
    "average": 27.86
  },
  "aisquared/dlite-v1-1_5b": {
    "arc": 31.66,
    "hellaswag": 49.69,
    "truthfulqa": 37.08,
    "mmlu": 25.62,
    "gsm8k": 0.08,
    "winogrande": 55.96,
    "average": 33.35
  },
  "aisquared/dlite-v1-355m": {
    "arc": 27.13,
    "hellaswag": 39.07,
    "truthfulqa": 37.13,
    "mmlu": 27.12,
    "gsm8k": 0,
    "winogrande": 52.8,
    "average": 30.54
  },
  "aisquared/dlite-v1-774m": {
    "arc": 28.07,
    "hellaswag": 44.35,
    "truthfulqa": 36.11,
    "mmlu": 25.91,
    "gsm8k": 0,
    "winogrande": 54.62,
    "average": 31.51
  },
  "aisquared/dlite-v2-124m": {
    "arc": 23.98,
    "hellaswag": 31.1,
    "truthfulqa": 38.98,
    "mmlu": 25.29,
    "gsm8k": 0,
    "winogrande": 50.43,
    "average": 28.3
  },
  "aisquared/dlite-v2-1_5b": {
    "arc": 32.59,
    "hellaswag": 53.98,
    "truthfulqa": 38.77,
    "mmlu": 24.93,
    "gsm8k": 0.23,
    "winogrande": 54.7,
    "average": 34.2
  },
  "aisquared/dlite-v2-355m": {
    "arc": 28.33,
    "hellaswag": 40.54,
    "truthfulqa": 38.76,
    "mmlu": 26.77,
    "gsm8k": 0,
    "winogrande": 52.8,
    "average": 31.2
  },
  "aisquared/dlite-v2-774m": {
    "arc": 30.12,
    "hellaswag": 47.68,
    "truthfulqa": 40,
    "mmlu": 25.37,
    "gsm8k": 0,
    "winogrande": 53.99,
    "average": 32.86
  },
  "ajibawa-2023/Python-Code-13B": {
    "arc": 58.79,
    "hellaswag": 81.66,
    "truthfulqa": 42.83,
    "winogrande": 74.03,
    "gsm8k": 9.55,
    "mmlu": 54.78,
    "average": 53.61
  },
  "ajibawa-2023/Python-Code-33B": {
    "arc": 56.31,
    "hellaswag": 81.01,
    "truthfulqa": 44.39,
    "winogrande": 75.22,
    "gsm8k": 19.18,
    "mmlu": 54.22,
    "average": 55.05
  },
  "ajibawa-2023/SlimOrca-13B": {
    "arc": 60.15,
    "hellaswag": 81.4,
    "truthfulqa": 49.37,
    "winogrande": 74.43,
    "gsm8k": 39.95,
    "mmlu": 57.04,
    "average": 60.39
  },
  "ajibawa-2023/Uncensored-Frank-13B": {
    "arc": 61.6,
    "hellaswag": 82.62,
    "truthfulqa": 48.34,
    "mmlu": 54.55,
    "gsm8k": 11.98,
    "winogrande": 74.74,
    "average": 55.64
  },
  "ajibawa-2023/Uncensored-Frank-33B": {
    "arc": 62.12,
    "hellaswag": 83.3,
    "truthfulqa": 54.03,
    "mmlu": 57.57,
    "gsm8k": 16.68,
    "winogrande": 76.56,
    "average": 58.38
  },
  "ajibawa-2023/Uncensored-Frank-7B": {
    "arc": 54.27,
    "hellaswag": 76.52,
    "truthfulqa": 43.86,
    "mmlu": 37.5,
    "gsm8k": 5,
    "winogrande": 70.24,
    "average": 47.9
  },
  "ajibawa-2023/Uncensored-Jordan-13B": {
    "arc": 57.42,
    "hellaswag": 82.7,
    "truthfulqa": 50.51,
    "winogrande": 76.16,
    "gsm8k": 15.09,
    "mmlu": 55.75,
    "average": 56.27
  },
  "ajibawa-2023/Uncensored-Jordan-7B": {
    "arc": 51.28,
    "hellaswag": 77.37,
    "truthfulqa": 47.5,
    "winogrande": 71.11,
    "gsm8k": 6.75,
    "mmlu": 45.69,
    "average": 49.95
  },
  "ajibawa-2023/carl-33b": {
    "arc": 64.59,
    "hellaswag": 85.27,
    "truthfulqa": 45.32,
    "mmlu": 58.38,
    "gsm8k": 6.37,
    "winogrande": 76.24,
    "average": 56.03
  },
  "ajibawa-2023/carl-7b": {
    "arc": 53.5,
    "hellaswag": 78.29,
    "truthfulqa": 40.29,
    "mmlu": 33.96,
    "gsm8k": 2.35,
    "winogrande": 68.59,
    "average": 46.16
  },
  "ajibawa-2023/scarlett-33b": {
    "arc": 67.75,
    "hellaswag": 85.48,
    "truthfulqa": 61.05,
    "mmlu": 58.98,
    "gsm8k": 2.81,
    "winogrande": 76.8,
    "average": 58.81
  },
  "ajibawa-2023/scarlett-7b": {
    "arc": 57.17,
    "hellaswag": 80.27,
    "truthfulqa": 48.52,
    "mmlu": 36.11,
    "gsm8k": 0.3,
    "winogrande": 72.14,
    "average": 49.09
  },
  "akjindal53244/Mistral-7B-v0.1-Open-Platypus": {
    "arc": 62.37,
    "hellaswag": 85.08,
    "truthfulqa": 47.33,
    "mmlu": 63.79,
    "gsm8k": 17.29,
    "winogrande": 77.66,
    "average": 58.92
  },
  "alibidaran/medical_transcription_generator": {
    "arc": 22.78,
    "hellaswag": 30.6,
    "truthfulqa": 46.5,
    "mmlu": 23.84,
    "gsm8k": 0,
    "winogrande": 50.43,
    "average": 29.03
  },
  "allenai/digital-socrates-13b": {
    "arc": 58.36,
    "hellaswag": 80.14,
    "truthfulqa": 44.47,
    "winogrande": 74.59,
    "gsm8k": 29.49,
    "mmlu": 57.01,
    "average": 57.34
  },
  "allenai/digital-socrates-7b": {
    "arc": 54.44,
    "hellaswag": 75.99,
    "truthfulqa": 44.88,
    "winogrande": 73.09,
    "gsm8k": 17.89,
    "mmlu": 51.41,
    "average": 52.95
  },
  "amazingvince/zephyr-smol_llama-100m-dpo-full": {
    "arc": 25,
    "hellaswag": 28.54,
    "truthfulqa": 45.75,
    "winogrande": 51.07,
    "gsm8k": 0.68,
    "mmlu": 25.18,
    "average": 29.37
  },
  "amazon/LightGPT": {
    "arc": 39.93,
    "hellaswag": 63.82,
    "truthfulqa": 36.69,
    "mmlu": 28.45,
    "gsm8k": 3.87,
    "winogrande": 64.48,
    "average": 39.54
  },
  "amazon/MistralLite": {
    "arc": 59.56,
    "hellaswag": 81.84,
    "truthfulqa": 37.87,
    "winogrande": 77.43,
    "gsm8k": 1.06,
    "mmlu": 50.93,
    "average": 51.45
  },
  "anas-awadalla/mpt-1b-redpajama-200b": {
    "arc": 25.77,
    "hellaswag": 26.08,
    "truthfulqa": 47.57,
    "mmlu": 24.5,
    "gsm8k": 0,
    "winogrande": 50.36,
    "average": 29.05
  },
  "anas-awadalla/mpt-7b": {
    "arc": 47.7,
    "hellaswag": 77.57,
    "truthfulqa": 33.44,
    "mmlu": 30.8,
    "gsm8k": 4.02,
    "winogrande": 72.14,
    "average": 44.28
  },
  "andreaskoepf/llama2-13b-megacode2_min100": {
    "arc": 60.58,
    "hellaswag": 81.26,
    "truthfulqa": 48.89,
    "mmlu": 57.92,
    "gsm8k": 15.92,
    "winogrande": 76.95,
    "average": 56.92
  },
  "anhnv125/llama-op-v4": {
    "arc": 61.52,
    "hellaswag": 79.21,
    "truthfulqa": 42.72,
    "mmlu": 57.01,
    "gsm8k": 9.63,
    "winogrande": 75.93,
    "average": 54.34
  },
  "anhnv125/pygmalion-6b-roleplay": {
    "arc": 40.53,
    "hellaswag": 67.47,
    "truthfulqa": 32.53,
    "mmlu": 25.73,
    "gsm8k": 1.14,
    "winogrande": 62.67,
    "average": 38.35
  },
  "anton-l/gpt-j-tiny-random": {
    "arc": 26.37,
    "hellaswag": 25.76,
    "truthfulqa": 47.44,
    "mmlu": 24.46,
    "gsm8k": 0,
    "winogrande": 49.49,
    "average": 28.92
  },
  "aqweteddy/Tulpar-tv_marcoroni-7b": {
    "arc": 41.64,
    "hellaswag": 67.11,
    "truthfulqa": 49.38,
    "mmlu": 32.72
  },
  "aqweteddy/llama_chat-tv_en_luban-tv_stable_platypus2": {
    "arc": 44.54,
    "hellaswag": 61.02,
    "truthfulqa": 51.88,
    "mmlu": 49.6
  },
  "argilla/notus-7b-v1": {
    "arc": 64.59,
    "hellaswag": 84.83,
    "truthfulqa": 54.35,
    "winogrande": 79.56,
    "gsm8k": 34.57,
    "mmlu": 63.04,
    "average": 63.49
  },
  "ariellee/SuperPlatty-30B": {
    "arc": 65.78,
    "hellaswag": 83.95,
    "truthfulqa": 53.52,
    "mmlu": 62.57,
    "gsm8k": 9.63,
    "winogrande": 80.35,
    "average": 59.3
  },
  "arver/llama7b-qlora": {
    "arc": 55.12,
    "hellaswag": 78.07,
    "truthfulqa": 39.71,
    "mmlu": 35.91,
    "gsm8k": 3.18,
    "winogrande": 72.53,
    "average": 47.42
  },
  "ashercn97/giraffe-7b": {
    "arc": 47.18,
    "hellaswag": 75.53,
    "truthfulqa": 38.48,
    "mmlu": 38.89,
    "gsm8k": 2.65,
    "winogrande": 68.98,
    "average": 45.29
  },
  "ashercn97/manatee-7b": {
    "arc": 54.52,
    "hellaswag": 78.95,
    "truthfulqa": 46.77,
    "mmlu": 49.26,
    "gsm8k": 7.05,
    "winogrande": 74.51,
    "average": 51.84
  },
  "augtoma/qCammel-13": {
    "arc": 60.84,
    "hellaswag": 83.66,
    "truthfulqa": 47.54,
    "mmlu": 56.73,
    "gsm8k": 11.37,
    "winogrande": 76.16,
    "average": 56.05
  },
  "augtoma/qCammel-70": {
    "arc": 68.34,
    "hellaswag": 87.87,
    "truthfulqa": 57.47,
    "mmlu": 70.18,
    "gsm8k": 29.72,
    "winogrande": 84.29,
    "average": 66.31
  },
  "augtoma/qCammel-70-x": {
    "arc": 68.34,
    "hellaswag": 87.87,
    "truthfulqa": 57.47,
    "mmlu": 70.18,
    "gsm8k": 29.72,
    "winogrande": 84.29,
    "average": 66.31
  },
  "augtoma/qCammel-70v1": {
    "arc": 68.34,
    "hellaswag": 87.87,
    "truthfulqa": 57.47,
    "mmlu": 70.18,
    "gsm8k": 29.72,
    "winogrande": 84.29,
    "average": 66.31
  },
  "augtoma/qCammel-70x": {
    "arc": 68.34,
    "hellaswag": 87.87,
    "truthfulqa": 57.47,
    "mmlu": 70.18,
    "gsm8k": 29.72,
    "winogrande": 84.29,
    "average": 66.31
  },
  "augtoma/qCammel70": {
    "arc": 68.34,
    "hellaswag": 87.87,
    "truthfulqa": 57.47,
    "mmlu": 70.18,
    "gsm8k": 29.72,
    "winogrande": 84.29,
    "average": 66.31
  },
  "ausboss/llama-13b-supercot": {
    "arc": 56.06,
    "hellaswag": 81.71,
    "truthfulqa": 48.55,
    "mmlu": 45.36,
    "gsm8k": 7.2,
    "winogrande": 75.77,
    "average": 52.44
  },
  "ausboss/llama-30b-supercot": {
    "arc": 64.85,
    "hellaswag": 85.08,
    "truthfulqa": 53.96,
    "mmlu": 56.56,
    "gsm8k": 11.9,
    "winogrande": 80.03,
    "average": 58.73
  },
  "ausboss/llama7b-wizardlm-unfiltered": {
    "arc": 52.99,
    "hellaswag": 77.89,
    "truthfulqa": 37.75,
    "mmlu": 36.41,
    "gsm8k": 4.32,
    "winogrande": 72.3,
    "average": 46.94
  },
  "baichuan-inc/Baichuan-7B": {
    "arc": 40.7,
    "hellaswag": 69.02,
    "truthfulqa": 36.23,
    "mmlu": 43.59,
    "gsm8k": 2.81,
    "winogrande": 66.77,
    "average": 43.19
  },
  "bavest/fin-llama-33b-merged": {
    "arc": 65.02,
    "hellaswag": 86.2,
    "truthfulqa": 49.75,
    "mmlu": 58.73,
    "gsm8k": 16.22,
    "winogrande": 80.03,
    "average": 59.32
  },
  "beaugogh/Llama2-13b-sharegpt4": {
    "arc": 61.77,
    "hellaswag": 84.53,
    "truthfulqa": 45.94,
    "mmlu": 55.21,
    "gsm8k": 8.79,
    "winogrande": 75.22,
    "average": 55.24
  },
  "beaugogh/Llama2-7b-openorca-mc-v1": {
    "arc": 55.63,
    "hellaswag": 80.17,
    "truthfulqa": 51.62,
    "mmlu": 48.44,
    "gsm8k": 4.09,
    "winogrande": 73.48,
    "average": 52.24
  },
  "beaugogh/Llama2-7b-openorca-mc-v2": {
    "arc": 55.55,
    "hellaswag": 81.26,
    "truthfulqa": 51.49,
    "mmlu": 48.3,
    "gsm8k": 5.38,
    "winogrande": 72.85,
    "average": 52.47
  },
  "beaugogh/Llama2-7b-openorca-mc-v2-dpo": {
    "arc": 54.78,
    "hellaswag": 81.48,
    "truthfulqa": 53.13,
    "mmlu": 47.2,
    "gsm8k": 4.47,
    "winogrande": 72.85,
    "average": 52.32
  },
  "beaugogh/Llama2-7b-sharegpt4": {
    "arc": 55.72,
    "hellaswag": 80.94,
    "truthfulqa": 48.34,
    "mmlu": 47.47,
    "gsm8k": 2.65,
    "winogrande": 71.19,
    "average": 51.05
  },
  "beaugogh/pythia-1.4b-deduped-sharegpt": {
    "arc": 34.3,
    "hellaswag": 54.49,
    "truthfulqa": 41.81,
    "mmlu": 24,
    "gsm8k": 0.83,
    "winogrande": 55.25,
    "average": 35.11
  },
  "beberik/Nyxene-11B": {
    "arc": 68.34,
    "hellaswag": 84.54,
    "truthfulqa": 57.5,
    "winogrande": 79.08,
    "gsm8k": 51.78,
    "mmlu": 65.09,
    "average": 67.72
  },
  "behnamsh/gpt2_platypus-camel_physics": {
    "arc": 22.78,
    "hellaswag": 31.24,
    "truthfulqa": 38.95,
    "mmlu": 25.87,
    "gsm8k": 0,
    "winogrande": 51.54,
    "average": 28.4
  },
  "beomi/KoAlpaca-KoRWKV-6B": {
    "arc": 23.46,
    "hellaswag": 31.65,
    "truthfulqa": 39.83,
    "mmlu": 24.89,
    "gsm8k": 0,
    "winogrande": 51.62,
    "average": 28.58
  },
  "beomi/KoAlpaca-Polyglot-5.8B": {
    "arc": 27.65,
    "hellaswag": 35.58,
    "truthfulqa": 39.74,
    "mmlu": 24.72,
    "gsm8k": 0.08,
    "winogrande": 49.01,
    "average": 29.46
  },
  "beomi/KoRWKV-6B": {
    "arc": 22.1,
    "hellaswag": 32.18,
    "truthfulqa": 39.05,
    "mmlu": 24.69,
    "gsm8k": 0,
    "winogrande": 51.14,
    "average": 28.19
  },
  "beomi/Yi-Ko-6B": {
    "arc": 48.89,
    "hellaswag": 74.48,
    "truthfulqa": 37.09,
    "winogrande": 72.93,
    "gsm8k": 12.51,
    "mmlu": 55.72,
    "average": 50.27
  },
  "beomi/llama-2-ko-7b": {
    "arc": 48.46,
    "hellaswag": 75.28,
    "truthfulqa": 34.49,
    "mmlu": 39.56,
    "gsm8k": 1.97,
    "winogrande": 72.14,
    "average": 45.32
  },
  "berkeley-nest/Starling-LM-7B-alpha": {
    "arc": 63.82,
    "hellaswag": 84.9,
    "truthfulqa": 46.39,
    "winogrande": 80.58,
    "gsm8k": 62.4,
    "mmlu": 64.67,
    "average": 67.13
  },
  "bertin-project/bertin-gpt-j-6B-alpaca": {
    "arc": 36.01,
    "hellaswag": 54.3,
    "truthfulqa": 43.38,
    "mmlu": 27.66,
    "gsm8k": 0,
    "winogrande": 55.8,
    "average": 36.19
  },
  "bhenrym14/airoboros-33b-gpt4-1.4.1-PI-8192-fp16": {
    "arc": 32,
    "hellaswag": 53.88,
    "truthfulqa": 38.59,
    "mmlu": 31.43,
    "gsm8k": 0,
    "winogrande": 56.83,
    "average": 35.46
  },
  "bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16": {
    "arc": 60.58,
    "hellaswag": 82.97,
    "truthfulqa": 46.1,
    "mmlu": 52.1,
    "gsm8k": 8.57,
    "winogrande": 73.72,
    "average": 54.01
  },
  "bhenrym14/airophin-13b-pntk-16k-fp16": {
    "arc": 61.18,
    "hellaswag": 82.86,
    "truthfulqa": 43.2,
    "mmlu": 55.19,
    "gsm8k": 8.04,
    "winogrande": 76.16,
    "average": 54.44
  },
  "bhenrym14/airophin-v2-13b-PI-8k-fp16": {
    "arc": 60.58,
    "hellaswag": 82.96,
    "truthfulqa": 40.14,
    "mmlu": 56.75,
    "gsm8k": 7.35,
    "winogrande": 76.64,
    "average": 54.07
  },
  "bhenrym14/mistral-7b-platypus-fp16": {
    "arc": 63.05,
    "hellaswag": 84.15,
    "truthfulqa": 45.07,
    "mmlu": 64.11,
    "gsm8k": 17.36,
    "winogrande": 78.53,
    "average": 58.71
  },
  "bhenrym14/platypus-yi-34b": {
    "arc": 68.43,
    "hellaswag": 85.21,
    "truthfulqa": 54.48,
    "winogrande": 84.06,
    "gsm8k": 61.03,
    "mmlu": 78.13,
    "average": 71.89
  },
  "bigcode/gpt_bigcode-santacoder": {
    "arc": 21.16,
    "hellaswag": 30.84,
    "truthfulqa": 45.64,
    "mmlu": 24.97,
    "gsm8k": 0.53,
    "winogrande": 47.83,
    "average": 28.5
  },
  "bigcode/santacoder": {
    "arc": 26.28,
    "hellaswag": 25.6,
    "truthfulqa": 51.24,
    "mmlu": 25.89,
    "gsm8k": 0,
    "winogrande": 48.07,
    "average": 29.51
  },
  "bigcode/starcoder": {
    "arc": 30.29,
    "hellaswag": 47.97,
    "truthfulqa": 41.28,
    "mmlu": 30
  },
  "bigcode/starcoderplus": {
    "arc": 48.72,
    "hellaswag": 77.3,
    "truthfulqa": 37.85,
    "mmlu": 43.72,
    "gsm8k": 8.04,
    "winogrande": 70.01,
    "average": 47.61
  },
  "bigcode/tiny_starcoder_py": {
    "arc": 20.99,
    "hellaswag": 28.77,
    "truthfulqa": 47.68,
    "mmlu": 26.79,
    "gsm8k": 0.99,
    "winogrande": 51.22,
    "average": 29.41
  },
  "bigscience/bloom": {
    "arc": 50.43,
    "hellaswag": 76.41,
    "truthfulqa": 39.76,
    "mmlu": 30.85,
    "gsm8k": 6.9,
    "winogrande": 72.06,
    "average": 46.07
  },
  "bigscience/bloom-1b1": {
    "arc": 28.33,
    "hellaswag": 42.78,
    "truthfulqa": 41.8,
    "mmlu": 26.7,
    "gsm8k": 0.23,
    "winogrande": 55.01,
    "average": 32.47
  },
  "bigscience/bloom-1b7": {
    "arc": 30.63,
    "hellaswag": 47.6,
    "truthfulqa": 41.31,
    "mmlu": 27.48,
    "gsm8k": 0.83,
    "winogrande": 56.04,
    "average": 33.98
  },
  "bigscience/bloom-3b": {
    "arc": 35.75,
    "hellaswag": 54.37,
    "truthfulqa": 40.57,
    "mmlu": 26.59,
    "gsm8k": 1.52,
    "winogrande": 57.62,
    "average": 36.07
  },
  "bigscience/bloom-560m": {
    "arc": 24.74,
    "hellaswag": 37.15,
    "truthfulqa": 42.44,
    "mmlu": 24.22,
    "gsm8k": 0.3,
    "winogrande": 51.93,
    "average": 30.13
  },
  "bigscience/bloom-7b1": {
    "arc": 41.13,
    "hellaswag": 62,
    "truthfulqa": 38.9,
    "mmlu": 26.25,
    "gsm8k": 1.36,
    "winogrande": 65.43,
    "average": 39.18
  },
  "bigscience/bloomz-3b": {
    "arc": 36.86,
    "hellaswag": 54.95,
    "truthfulqa": 40.34,
    "mmlu": 32.91,
    "gsm8k": 0,
    "winogrande": 57.14,
    "average": 37.03
  },
  "bigscience/bloomz-560m": {
    "arc": 23.55,
    "hellaswag": 36.31,
    "truthfulqa": 45.69,
    "mmlu": 25.1,
    "gsm8k": 0,
    "winogrande": 53.12,
    "average": 30.63
  },
  "bigscience/bloomz-7b1": {
    "arc": 42.49,
    "hellaswag": 63.01,
    "truthfulqa": 45.2,
    "mmlu": 37.85,
    "gsm8k": 0.08,
    "winogrande": 64.64,
    "average": 42.21
  },
  "bigscience/bloomz-7b1-mt": {
    "arc": 43.86,
    "hellaswag": 62.91,
    "truthfulqa": 45.65,
    "mmlu": 37.35,
    "gsm8k": 0,
    "winogrande": 63.06,
    "average": 42.14
  },
  "blueapple8259/TinyStories-Alpaca": {
    "arc": 23.98,
    "hellaswag": 24.92,
    "truthfulqa": 46.68,
    "winogrande": 51.85,
    "gsm8k": 0,
    "mmlu": 23.35,
    "average": 28.46
  },
  "bofenghuang/vigogne-13b-chat": {
    "arc": 58.62,
    "hellaswag": 80.85,
    "truthfulqa": 48.73,
    "mmlu": 47.76,
    "gsm8k": 8.34,
    "winogrande": 76.72,
    "average": 53.5
  },
  "bofenghuang/vigogne-13b-instruct": {
    "arc": 57.94,
    "hellaswag": 81.32,
    "truthfulqa": 50.23,
    "mmlu": 47.62,
    "gsm8k": 11.83,
    "winogrande": 77.11,
    "average": 54.34
  },
  "bofenghuang/vigogne-2-13b-instruct": {
    "arc": 61.18,
    "hellaswag": 83.25,
    "truthfulqa": 51.08,
    "mmlu": 55.92,
    "gsm8k": 2.05,
    "winogrande": 77.35,
    "average": 55.14
  },
  "bofenghuang/vigogne-2-7b-chat": {
    "arc": 55.63,
    "hellaswag": 78.71,
    "truthfulqa": 47.21,
    "mmlu": 50.98,
    "gsm8k": 7.73,
    "winogrande": 74.43,
    "average": 52.45
  },
  "bofenghuang/vigogne-2-7b-instruct": {
    "arc": 56.23,
    "hellaswag": 79.97,
    "truthfulqa": 49.51,
    "mmlu": 47.17,
    "gsm8k": 3.79,
    "winogrande": 75.45,
    "average": 52.02
  },
  "bofenghuang/vigogne-33b-instruct": {
    "arc": 63.05,
    "hellaswag": 85,
    "truthfulqa": 52.1,
    "mmlu": 58.32,
    "gsm8k": 11.14,
    "winogrande": 78.85,
    "average": 58.08
  },
  "bofenghuang/vigogne-7b-chat": {
    "arc": 52.47,
    "hellaswag": 78.35,
    "truthfulqa": 44.52,
    "mmlu": 39.51,
    "gsm8k": 7.58,
    "winogrande": 73.16,
    "average": 49.27
  },
  "bofenghuang/vigogne-7b-instruct": {
    "arc": 51.96,
    "hellaswag": 78.11,
    "truthfulqa": 42.47,
    "mmlu": 38.43,
    "gsm8k": 2.73,
    "winogrande": 72.85,
    "average": 47.76
  },
  "bofenghuang/vigostral-7b-chat": {
    "arc": 62.63,
    "hellaswag": 84.34,
    "truthfulqa": 49.24,
    "winogrande": 78.61,
    "gsm8k": 16.76,
    "mmlu": 63.53,
    "average": 59.19
  },
  "bongchoi/test-llama-2-7b": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.86
  },
  "bongchoi/test-llama2-70b": {
    "arc": 67.32,
    "hellaswag": 87.33,
    "truthfulqa": 44.92,
    "mmlu": 69.83
  },
  "bongchoi/test-llama2-7b": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.86,
    "gsm8k": 7.13,
    "winogrande": 74.03,
    "average": 49.73
  },
  "boomerchan/magpie-13b": {
    "arc": 63.31,
    "hellaswag": 84.25,
    "truthfulqa": 49.15,
    "mmlu": 58.15,
    "gsm8k": 14.48,
    "winogrande": 76.48,
    "average": 57.64
  },
  "breadlicker45/dough-base-001": {
    "arc": 23.89,
    "hellaswag": 24.76,
    "truthfulqa": 53.4,
    "mmlu": 23.13,
    "gsm8k": 0,
    "winogrande": 51.07,
    "average": 29.38
  },
  "breadlicker45/dough-instruct-base-001": {
    "arc": 23.89,
    "hellaswag": 24.76,
    "truthfulqa": 53.4,
    "mmlu": 23.13,
    "gsm8k": 0,
    "winogrande": 51.07,
    "average": 29.38
  },
  "brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties": {
    "arc": 64.93,
    "hellaswag": 85.92,
    "truthfulqa": 55.84,
    "winogrande": 83.03,
    "gsm8k": 61.94,
    "mmlu": 76.18,
    "average": 71.31
  },
  "brucethemoose/Capybara-Tess-Yi-34B-200K": {
    "arc": 66.13,
    "hellaswag": 86.24,
    "truthfulqa": 56.37,
    "winogrande": 82.4,
    "gsm8k": 57.39,
    "mmlu": 74.89,
    "average": 70.57
  },
  "bsp-albz/llama2-13b-platypus-ckpt-1000": {
    "arc": 28.16,
    "hellaswag": 26.55,
    "truthfulqa": 48.79,
    "mmlu": 23.17,
    "gsm8k": 0,
    "winogrande": 49.01,
    "average": 29.28
  },
  "budecosystem/boomer-1b": {
    "arc": 22.78,
    "hellaswag": 31.58,
    "truthfulqa": 39.17,
    "mmlu": 25.66,
    "gsm8k": 0.91,
    "winogrande": 50.51,
    "average": 28.44
  },
  "budecosystem/genz-13b-v2": {
    "arc": 55.97,
    "hellaswag": 79.98,
    "truthfulqa": 48.09,
    "mmlu": 54.3,
    "gsm8k": 12.28,
    "winogrande": 74.59,
    "average": 54.2
  },
  "budecosystem/genz-70b": {
    "arc": 71.42,
    "hellaswag": 87.99,
    "truthfulqa": 62.66,
    "mmlu": 70.78,
    "gsm8k": 33.74,
    "winogrande": 83.5,
    "average": 68.35
  },
  "caisarl76/Mistral-7B-OpenOrca-Guanaco-accu16": {
    "arc": 59.73,
    "hellaswag": 83.08,
    "truthfulqa": 50.81,
    "mmlu": 61.29,
    "gsm8k": 16,
    "winogrande": 76.56,
    "average": 57.91
  },
  "caisarl76/Mistral-7B-guanaco1k-ep2": {
    "arc": 60.07,
    "hellaswag": 82.76,
    "truthfulqa": 54.4,
    "mmlu": 61.5,
    "gsm8k": 11.98,
    "winogrande": 78.06,
    "average": 58.13
  },
  "caisarl76/mistral-guanaco1k-ep2": {
    "arc": 60.07,
    "hellaswag": 82.76,
    "truthfulqa": 54.4,
    "mmlu": 61.5,
    "gsm8k": 11.98,
    "winogrande": 78.06,
    "average": 58.13
  },
  "camel-ai/CAMEL-13B-Combined-Data": {
    "arc": 55.63,
    "hellaswag": 79.25,
    "truthfulqa": 47.42,
    "mmlu": 49.74,
    "gsm8k": 7.13,
    "winogrande": 75.45,
    "average": 52.44
  },
  "camel-ai/CAMEL-13B-Role-Playing-Data": {
    "arc": 54.95,
    "hellaswag": 79.25,
    "truthfulqa": 46.35,
    "mmlu": 46.61,
    "gsm8k": 7.35,
    "winogrande": 74.03,
    "average": 51.42
  },
  "camel-ai/CAMEL-33B-Combined-Data": {
    "arc": 62.97,
    "hellaswag": 83.83,
    "truthfulqa": 50.21,
    "mmlu": 58.98,
    "gsm8k": 14.1,
    "winogrande": 78.3,
    "average": 58.07
  },
  "ceadar-ie/FinanceConnect-13B": {},
  "cerebras/Cerebras-GPT-1.3B": {
    "arc": 26.28,
    "hellaswag": 38.54,
    "truthfulqa": 42.7,
    "mmlu": 26.59,
    "gsm8k": 0.23,
    "winogrande": 53.43,
    "average": 31.3
  },
  "cerebras/Cerebras-GPT-111M": {
    "arc": 20.22,
    "hellaswag": 26.73,
    "truthfulqa": 46.31,
    "mmlu": 25.51,
    "gsm8k": 0,
    "winogrande": 47.75,
    "average": 27.75
  },
  "cerebras/Cerebras-GPT-13B": {
    "arc": 38.14,
    "hellaswag": 60.01,
    "truthfulqa": 39.19,
    "mmlu": 25.92,
    "gsm8k": 1.29,
    "winogrande": 59.83,
    "average": 37.4
  },
  "cerebras/Cerebras-GPT-2.7B": {
    "arc": 29.1,
    "hellaswag": 49.29,
    "truthfulqa": 41.37,
    "mmlu": 25.17,
    "gsm8k": 0.45,
    "winogrande": 54.14,
    "average": 33.25
  },
  "cerebras/Cerebras-GPT-256M": {
    "arc": 22.01,
    "hellaswag": 28.99,
    "truthfulqa": 45.98,
    "mmlu": 26.83,
    "gsm8k": 0,
    "winogrande": 52.49,
    "average": 29.38
  },
  "cerebras/Cerebras-GPT-590M": {
    "arc": 23.72,
    "hellaswag": 32.4,
    "truthfulqa": 44.15,
    "mmlu": 25.97,
    "gsm8k": 0.45,
    "winogrande": 48.15,
    "average": 29.14
  },
  "cerebras/Cerebras-GPT-6.7B": {
    "arc": 35.07,
    "hellaswag": 59.36,
    "truthfulqa": 38.02,
    "mmlu": 25.93,
    "gsm8k": 0.53,
    "winogrande": 58.72,
    "average": 36.27
  },
  "chansung/gpt4-alpaca-lora-13b-decapoda-1024": {
    "arc": 59.39,
    "hellaswag": 81.87,
    "truthfulqa": 52.59,
    "mmlu": 47.75,
    "gsm8k": 8.11,
    "winogrande": 77.35,
    "average": 54.51
  },
  "chaoyi-wu/MedLLaMA_13B": {
    "arc": 54.27,
    "hellaswag": 78.53,
    "truthfulqa": 40.54,
    "mmlu": 46.4
  },
  "chargoddard/Chronorctypus-Limarobormes-13b": {
    "arc": 59.9,
    "hellaswag": 82.75,
    "truthfulqa": 51.9,
    "mmlu": 58.45,
    "gsm8k": 3.87,
    "winogrande": 74.43,
    "average": 55.22
  },
  "chargoddard/MelangeA-70b": {
    "arc": 71.25,
    "hellaswag": 87.3,
    "truthfulqa": 60.61,
    "mmlu": 70.56,
    "gsm8k": 5.69,
    "winogrande": 81.53,
    "average": 62.82
  },
  "chargoddard/MelangeB-70b": {
    "arc": 71.67,
    "hellaswag": 87.5,
    "truthfulqa": 59.36,
    "mmlu": 70.03,
    "gsm8k": 30.63,
    "winogrande": 83.5,
    "average": 67.12
  },
  "chargoddard/MelangeC-70b": {
    "arc": 71.67,
    "hellaswag": 87.6,
    "truthfulqa": 58.13,
    "mmlu": 70.37,
    "gsm8k": 0,
    "winogrande": 83.98,
    "average": 61.96
  },
  "chargoddard/Yi-34B-Llama": {
    "arc": 64.59,
    "hellaswag": 85.63,
    "truthfulqa": 55.6,
    "winogrande": 82.79,
    "gsm8k": 60.8,
    "mmlu": 76.31,
    "average": 70.95
  },
  "chargoddard/duplicitous-mammal-13b": {
    "arc": 61.69,
    "hellaswag": 83.79,
    "truthfulqa": 52.27,
    "mmlu": 57.5,
    "gsm8k": 9.1,
    "winogrande": 75.06,
    "average": 56.57
  },
  "chargoddard/duplicitous-slurpbeast-13b": {
    "arc": 62.12,
    "hellaswag": 83.92,
    "truthfulqa": 52.33,
    "mmlu": 57.53,
    "gsm8k": 8.79,
    "winogrande": 75.06,
    "average": 56.63
  },
  "chargoddard/llama-2-16b-nastychat": {
    "arc": 57.42,
    "hellaswag": 80.59,
    "truthfulqa": 53.45,
    "mmlu": 55.99,
    "gsm8k": 8.11,
    "winogrande": 74.66,
    "average": 55.04
  },
  "chargoddard/llama-2-26b-trenchcoat-stack": {
    "arc": 55.03,
    "hellaswag": 79.9,
    "truthfulqa": 40.48,
    "mmlu": 53.73,
    "gsm8k": 2.88,
    "winogrande": 74.74,
    "average": 51.13
  },
  "chargoddard/llama-2-34b-uncode": {
    "arc": 39.51,
    "hellaswag": 33.9,
    "truthfulqa": 40.94,
    "mmlu": 38.49,
    "gsm8k": 20.77,
    "winogrande": 74.35,
    "average": 41.33
  },
  "chargoddard/llama-polyglot-13b": {
    "arc": 59.81,
    "hellaswag": 81.27,
    "truthfulqa": 48.71,
    "winogrande": 76.72,
    "gsm8k": 22.59,
    "mmlu": 55.04,
    "average": 57.36
  },
  "chargoddard/llama2-22b": {
    "arc": 58.53,
    "hellaswag": 82.55,
    "truthfulqa": 39.84,
    "mmlu": 54.68,
    "gsm8k": 9.93,
    "winogrande": 76.32,
    "average": 53.64
  },
  "chargoddard/llama2-22b-blocktriangular": {
    "arc": 58.53,
    "hellaswag": 82.59,
    "truthfulqa": 39.3,
    "mmlu": 54.64,
    "gsm8k": 11.22,
    "winogrande": 75.93,
    "average": 53.7
  },
  "chargoddard/loyal-piano-m7": {
    "arc": 66.72,
    "hellaswag": 85.03,
    "truthfulqa": 60.03,
    "winogrande": 79.08,
    "gsm8k": 56.71,
    "mmlu": 64.43,
    "average": 68.67
  },
  "chargoddard/loyal-piano-m7-cdpo": {
    "arc": 67.06,
    "hellaswag": 85.42,
    "truthfulqa": 61.54,
    "winogrande": 79.08,
    "gsm8k": 56.33,
    "mmlu": 64.54,
    "average": 69
  },
  "chargoddard/platypus-2-22b-relora": {
    "arc": 57.68,
    "hellaswag": 82.44,
    "truthfulqa": 43.61,
    "mmlu": 55.33,
    "gsm8k": 6.6,
    "winogrande": 77.35,
    "average": 53.84
  },
  "chargoddard/platypus2-22b-relora": {
    "arc": 57.68,
    "hellaswag": 82.44,
    "truthfulqa": 43.61,
    "mmlu": 55.33,
    "gsm8k": 6.29,
    "winogrande": 77.11,
    "average": 53.74
  },
  "chargoddard/storytime-13b": {
    "arc": 62.03,
    "hellaswag": 83.96,
    "truthfulqa": 52.5,
    "mmlu": 57.48,
    "gsm8k": 8.34,
    "winogrande": 75.53,
    "average": 56.64
  },
  "chargoddard/ypotryll-22b-epoch2-qlora": {
    "arc": 59.22,
    "hellaswag": 80.66,
    "truthfulqa": 40.42,
    "mmlu": 54.52,
    "gsm8k": 5.38,
    "winogrande": 76.32,
    "average": 52.75
  },
  "chavinlo/alpaca-native": {
    "arc": 52.05,
    "hellaswag": 77,
    "truthfulqa": 37.6,
    "mmlu": 41.45,
    "gsm8k": 1.44,
    "winogrande": 69.46,
    "average": 46.5
  },
  "chavinlo/gpt4-x-alpaca": {
    "arc": 52.82,
    "hellaswag": 79.59,
    "truthfulqa": 48.88,
    "mmlu": 48.19,
    "gsm8k": 2.81,
    "winogrande": 70.17,
    "average": 50.41
  },
  "chickencaesar/llama2-platypus-llama2-chat-13B-hf": {
    "arc": 62.97,
    "hellaswag": 82.75,
    "truthfulqa": 42.93,
    "mmlu": 56.86,
    "gsm8k": 2.81,
    "winogrande": 76.32,
    "average": 54.11
  },
  "chinoll/Yi-6b-200k-dpo": {
    "arc": 43.09,
    "hellaswag": 74.53,
    "truthfulqa": 45.51,
    "winogrande": 73.09,
    "gsm8k": 11.37,
    "mmlu": 64,
    "average": 51.93
  },
  "chinoll/Yi-7b-dpo": {
    "arc": 43.09,
    "hellaswag": 74.53,
    "truthfulqa": 45.51,
    "winogrande": 73.09,
    "gsm8k": 11.37,
    "mmlu": 64,
    "average": 51.93
  },
  "circulus/Llama-2-13b-orca-v1": {
    "arc": 62.2,
    "hellaswag": 82.32,
    "truthfulqa": 49.6,
    "mmlu": 57.67,
    "gsm8k": 12.89,
    "winogrande": 76.8,
    "average": 56.91
  },
  "circulus/Llama-2-7b-orca-v1": {
    "arc": 56.31,
    "hellaswag": 79.14,
    "truthfulqa": 50.19,
    "mmlu": 52.71,
    "gsm8k": 7.81,
    "winogrande": 75.22,
    "average": 53.56
  },
  "clibrain/Llama-2-13b-ft-instruct-es": {
    "arc": 59.39,
    "hellaswag": 81.51,
    "truthfulqa": 37.81,
    "mmlu": 54.31,
    "gsm8k": 8.57,
    "winogrande": 75.77,
    "average": 52.89
  },
  "clibrain/Llama-2-7b-ft-instruct-es": {
    "arc": 53.67,
    "hellaswag": 77.83,
    "truthfulqa": 38.82,
    "mmlu": 46.58,
    "gsm8k": 5.69,
    "winogrande": 75.22,
    "average": 49.63
  },
  "clibrain/Llama-2-ft-instruct-es": {
    "gsm8k": 0,
    "winogrande": 49.57
  },
  "cmarkea/bloomz-3b-sft-chat": {
    "arc": 36.86,
    "hellaswag": 54.34,
    "truthfulqa": 39.69,
    "mmlu": 31.49,
    "gsm8k": 0.38,
    "winogrande": 58.88,
    "average": 36.94
  },
  "cmarkea/bloomz-560m-sft-chat": {
    "arc": 27.47,
    "hellaswag": 37.05,
    "truthfulqa": 42.35,
    "mmlu": 23.93,
    "gsm8k": 0,
    "winogrande": 53.51,
    "average": 30.72
  },
  "cmarkea/bloomz-7b1-mt-sft-chat": {
    "arc": 44.03,
    "hellaswag": 62.6,
    "truthfulqa": 44.34,
    "mmlu": 38.64,
    "gsm8k": 0.53,
    "winogrande": 63.3,
    "average": 42.24
  },
  "codellama/CodeLlama-13b-Instruct-hf": {
    "arc": 44.54,
    "hellaswag": 64.93,
    "truthfulqa": 45.88,
    "mmlu": 38.89,
    "gsm8k": 12.66,
    "winogrande": 68.03,
    "average": 45.82
  },
  "codellama/CodeLlama-13b-Python-hf": {
    "arc": 32.59,
    "hellaswag": 43.94,
    "truthfulqa": 44.59,
    "mmlu": 27.23,
    "gsm8k": 8.64,
    "winogrande": 65.04,
    "average": 37.01
  },
  "codellama/CodeLlama-13b-hf": {
    "arc": 40.87,
    "hellaswag": 63.35,
    "truthfulqa": 43.79,
    "mmlu": 32.81,
    "gsm8k": 12.13,
    "winogrande": 67.17,
    "average": 43.35
  },
  "codellama/CodeLlama-34b-Instruct-hf": {
    "arc": 40.78,
    "hellaswag": 35.66,
    "truthfulqa": 44.29,
    "mmlu": 39.72,
    "gsm8k": 31.01,
    "winogrande": 74.51,
    "average": 44.33
  },
  "codellama/CodeLlama-34b-Python-hf": {
    "arc": 40.19,
    "hellaswag": 36.82,
    "truthfulqa": 44.28,
    "mmlu": 34.79,
    "gsm8k": 14.33,
    "winogrande": 71.19,
    "average": 40.27
  },
  "codellama/CodeLlama-34b-hf": {
    "arc": 37.54,
    "hellaswag": 31.84,
    "truthfulqa": 38.89,
    "mmlu": 37.2,
    "gsm8k": 14.25,
    "winogrande": 73.01,
    "average": 38.79
  },
  "codellama/CodeLlama-7b-Instruct-hf": {
    "arc": 38.31,
    "hellaswag": 59.32,
    "truthfulqa": 41.45,
    "mmlu": 36.48,
    "gsm8k": 7.96,
    "winogrande": 64.56,
    "average": 41.35
  },
  "codellama/CodeLlama-7b-Python-hf": {
    "arc": 31.31,
    "hellaswag": 52.86,
    "truthfulqa": 42.21,
    "mmlu": 27.32,
    "gsm8k": 5.16,
    "winogrande": 64.01,
    "average": 37.15
  },
  "codellama/CodeLlama-7b-hf": {
    "arc": 39.93,
    "hellaswag": 60.8,
    "truthfulqa": 37.82,
    "mmlu": 31.12,
    "gsm8k": 5.16,
    "winogrande": 64.01,
    "average": 39.81
  },
  "codeparrot/codeparrot": {
    "arc": 21.67,
    "hellaswag": 28.34,
    "truthfulqa": 50.87,
    "mmlu": 25.55,
    "gsm8k": 0.23,
    "winogrande": 50.2,
    "average": 29.48
  },
  "concedo/OPT-19M-ChatSalad": {
    "arc": 24.4,
    "hellaswag": 25.15,
    "truthfulqa": 51.36,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 49.72,
    "average": 28.96
  },
  "concedo/Pythia-70M-ChatSalad": {
    "arc": 20.99,
    "hellaswag": 27.28,
    "truthfulqa": 49.74,
    "mmlu": 24.78,
    "gsm8k": 0,
    "winogrande": 52.41,
    "average": 29.2
  },
  "concedo/Vicuzard-30B-Uncensored": {
    "arc": 62.97,
    "hellaswag": 83.68,
    "truthfulqa": 52.27,
    "mmlu": 58.16,
    "gsm8k": 15.39,
    "winogrande": 77.11,
    "average": 58.26
  },
  "conceptofmind/Hermes-LLongMA-2-7b-8k": {
    "arc": 49.74,
    "hellaswag": 72.88,
    "truthfulqa": 38.84,
    "mmlu": 28.51
  },
  "conceptofmind/LLongMA-2-13b-16k": {
    "arc": 54.27,
    "hellaswag": 79.63,
    "truthfulqa": 37.71,
    "mmlu": 50.97,
    "gsm8k": 5.46,
    "winogrande": 72.61,
    "average": 50.11
  },
  "conceptofmind/LLongMA-2-7b-16k": {
    "arc": 52.22,
    "hellaswag": 76.21,
    "truthfulqa": 39.06,
    "mmlu": 38.46
  },
  "conceptofmind/Open-LLongMA-3b": {
    "arc": 39.76,
    "hellaswag": 65.46,
    "truthfulqa": 34.51,
    "mmlu": 24.95
  },
  "crumb/gpt2023": {
    "arc": 21.93,
    "hellaswag": 31.11,
    "truthfulqa": 40.71,
    "mmlu": 25.05,
    "gsm8k": 0.3,
    "winogrande": 50.12,
    "average": 28.2
  },
  "csitfun/llama-7b-logicot": {
    "arc": 47.01,
    "hellaswag": 72.56,
    "truthfulqa": 43.63,
    "mmlu": 38.93,
    "gsm8k": 0,
    "winogrande": 67.56,
    "average": 44.95
  },
  "cyberagent/open-calm-7b": {
    "arc": 20.48,
    "hellaswag": 30.65,
    "truthfulqa": 44.15,
    "mmlu": 25.22,
    "gsm8k": 0.23,
    "winogrande": 48.54,
    "average": 28.21
  },
  "cyberagent/open-calm-large": {
    "arc": 20.73,
    "hellaswag": 29.56,
    "truthfulqa": 46.52,
    "mmlu": 25.23,
    "gsm8k": 0.08,
    "winogrande": 51.14,
    "average": 28.88
  },
  "danielhanchen/open_llama_3b_600bt_preview": {
    "arc": 36.86,
    "hellaswag": 59.96,
    "truthfulqa": 32.81,
    "mmlu": 25.97,
    "gsm8k": 0.61,
    "winogrande": 63.69,
    "average": 36.65
  },
  "danielpark/gorani-100k-llama2-13b-instruct": {
    "arc": 28.07,
    "hellaswag": 26.3,
    "truthfulqa": 48.96,
    "mmlu": 25.17,
    "gsm8k": 0,
    "winogrande": 49.64,
    "average": 29.69
  },
  "databricks/dolly-v2-12b": {
    "arc": 42.41,
    "hellaswag": 72.53,
    "truthfulqa": 33.83,
    "mmlu": 25.92,
    "gsm8k": 1.21,
    "winogrande": 60.85,
    "average": 39.46
  },
  "databricks/dolly-v2-3b": {
    "arc": 39.59,
    "hellaswag": 65.04,
    "truthfulqa": 33.77,
    "mmlu": 25.05,
    "gsm8k": 1.06,
    "winogrande": 59.43,
    "average": 37.32
  },
  "databricks/dolly-v2-7b": {
    "arc": 44.54,
    "hellaswag": 69.64,
    "truthfulqa": 34.88,
    "mmlu": 25.18,
    "gsm8k": 1.14,
    "winogrande": 60.06,
    "average": 39.24
  },
  "davzoku/cria-llama2-7b-v1.3": {
    "arc": 52.73,
    "hellaswag": 78.58,
    "truthfulqa": 45.58,
    "mmlu": 48.3,
    "gsm8k": 8.49,
    "winogrande": 71.9,
    "average": 50.93
  },
  "davzoku/cria-llama2-7b-v1.3_peft": {
    "arc": 51.45,
    "hellaswag": 77.35,
    "truthfulqa": 45.52,
    "mmlu": 46.47,
    "gsm8k": 6.75,
    "winogrande": 70.8,
    "average": 49.72
  },
  "ddobokki/Llama-2-70b-orca-200k": {
    "arc": 64.85,
    "hellaswag": 85.25,
    "truthfulqa": 56.18,
    "mmlu": 66.89
  },
  "deepnight-research/zsc-text": {
    "arc": 26.71,
    "hellaswag": 25.76,
    "truthfulqa": 48.35,
    "mmlu": 23.12
  },
  "deepse/CodeUp-Llama-2-13b-chat-hf": {
    "arc": 59.04,
    "hellaswag": 81.93,
    "truthfulqa": 44.12,
    "mmlu": 54.63,
    "gsm8k": 15.24,
    "winogrande": 74.51,
    "average": 54.91
  },
  "deepseek-ai/deepseek-coder-1.3b-instruct": {
    "arc": 28.58,
    "hellaswag": 39.87,
    "truthfulqa": 44.02,
    "winogrande": 52.41,
    "gsm8k": 1.06,
    "mmlu": 28.47,
    "average": 32.4
  },
  "deepseek-ai/deepseek-llm-67b-chat": {
    "arc": 67.75,
    "hellaswag": 86.82,
    "truthfulqa": 55.85,
    "winogrande": 84.21,
    "gsm8k": 63.68,
    "mmlu": 72.42,
    "average": 71.79
  },
  "dfurman/Llama-2-13B-Instruct-v0.2": {
    "arc": 60.58,
    "hellaswag": 81.96,
    "truthfulqa": 45.71,
    "winogrande": 77.82,
    "gsm8k": 9.33,
    "mmlu": 55.46,
    "average": 55.14
  },
  "dfurman/falcon-40b-openassistant-peft": {
    "arc": 62.63,
    "hellaswag": 85.59,
    "truthfulqa": 51.02,
    "mmlu": 57.77,
    "gsm8k": 13.34,
    "winogrande": 81.45,
    "average": 58.63
  },
  "dfurman/llama-2-13b-dolphin-peft": {
    "gsm8k": 0,
    "winogrande": 49.57
  },
  "dfurman/llama-2-13b-guanaco-peft": {
    "arc": 59.98,
    "hellaswag": 82.43,
    "truthfulqa": 42.59,
    "mmlu": 55.76
  },
  "dfurman/llama-2-70b-dolphin-peft": {
    "arc": 69.62,
    "hellaswag": 86.82,
    "truthfulqa": 57.43,
    "mmlu": 69.18,
    "gsm8k": 27.37,
    "winogrande": 83.9,
    "average": 65.72
  },
  "dfurman/llama-2-7b-instruct-peft": {
    "arc": 51.19,
    "hellaswag": 78.92,
    "truthfulqa": 48.5,
    "mmlu": 46.63,
    "gsm8k": 5.99,
    "winogrande": 74.43,
    "average": 50.94
  },
  "dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16": {
    "arc": 60.41,
    "hellaswag": 82.58,
    "truthfulqa": 43.61,
    "mmlu": 55.86,
    "gsm8k": 8.49,
    "winogrande": 76.72,
    "average": 54.61
  },
  "dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged": {
    "arc": 59.13,
    "hellaswag": 82.13,
    "truthfulqa": 44.23,
    "mmlu": 54.98,
    "gsm8k": 8.11,
    "winogrande": 76.4,
    "average": 54.16
  },
  "dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16": {
    "arc": 59.04,
    "hellaswag": 82.33,
    "truthfulqa": 35.75,
    "mmlu": 55.36,
    "gsm8k": 10.01,
    "winogrande": 76.32,
    "average": 53.14
  },
  "dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged": {
    "arc": 58.45,
    "hellaswag": 81.97,
    "truthfulqa": 35.85,
    "mmlu": 55.02,
    "gsm8k": 10.69,
    "winogrande": 75.69,
    "average": 52.95
  },
  "dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16": {
    "arc": 59.98,
    "hellaswag": 82.43,
    "truthfulqa": 39.9,
    "mmlu": 55.41,
    "gsm8k": 10.54,
    "winogrande": 76.56,
    "average": 54.14
  },
  "dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged": {
    "arc": 58.96,
    "hellaswag": 81.94,
    "truthfulqa": 40.26,
    "mmlu": 55,
    "gsm8k": 8.72,
    "winogrande": 76.56,
    "average": 53.57
  },
  "dhmeltzer/Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged": {
    "arc": 53.67,
    "hellaswag": 78.21,
    "truthfulqa": 46.13,
    "mmlu": 45.9,
    "gsm8k": 4.7,
    "winogrande": 73.8,
    "average": 50.4
  },
  "dhmeltzer/Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged": {
    "arc": 53.67,
    "hellaswag": 78.09,
    "truthfulqa": 41.72,
    "mmlu": 45.63,
    "gsm8k": 5.61,
    "winogrande": 73.56,
    "average": 49.71
  },
  "dhmeltzer/llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16": {
    "arc": 54.1,
    "hellaswag": 78.74,
    "truthfulqa": 43.4,
    "mmlu": 45.44,
    "gsm8k": 4.55,
    "winogrande": 73.64,
    "average": 49.98
  },
  "dhmeltzer/llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged": {
    "arc": 53.41,
    "hellaswag": 77.9,
    "truthfulqa": 40.81,
    "mmlu": 43.56,
    "gsm8k": 5.08,
    "winogrande": 74.59,
    "average": 49.23
  },
  "dhmeltzer/llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged": {
    "arc": 54.35,
    "hellaswag": 78.06,
    "truthfulqa": 37.11,
    "mmlu": 45.35,
    "gsm8k": 4.62,
    "winogrande": 73.4,
    "average": 48.82
  },
  "dhmeltzer/llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged": {
    "arc": 53.75,
    "hellaswag": 78.76,
    "truthfulqa": 43.31,
    "mmlu": 46.02,
    "gsm8k": 4.7,
    "winogrande": 73.48,
    "average": 50
  },
  "digitous/13B-Chimera": {
    "arc": 57.59,
    "hellaswag": 81.5,
    "truthfulqa": 52.59,
    "mmlu": 49.86,
    "gsm8k": 10.69,
    "winogrande": 77.27,
    "average": 54.92
  },
  "digitous/13B-HyperMantis": {
    "arc": 58.53,
    "hellaswag": 82.2,
    "truthfulqa": 47.5,
    "mmlu": 50.61,
    "gsm8k": 10.39,
    "winogrande": 76.24,
    "average": 54.25
  },
  "digitous/Adventien-GPTJ": {
    "arc": 42.49,
    "hellaswag": 69.21,
    "truthfulqa": 36.95,
    "mmlu": 25.4,
    "gsm8k": 1.59,
    "winogrande": 60.22,
    "average": 39.31
  },
  "digitous/Alpacino13b": {
    "arc": 58.53,
    "hellaswag": 81.31,
    "truthfulqa": 41.66,
    "mmlu": 47.92,
    "gsm8k": 7.96,
    "winogrande": 76.95,
    "average": 52.39
  },
  "digitous/Alpacino30b": {
    "arc": 62.71,
    "hellaswag": 85.04,
    "truthfulqa": 44.23,
    "mmlu": 58.48,
    "gsm8k": 15.77,
    "winogrande": 79.79,
    "average": 57.67
  },
  "digitous/GPT-R": {
    "arc": 41.21,
    "hellaswag": 66.89,
    "truthfulqa": 34.22,
    "mmlu": 36.5,
    "gsm8k": 1.59,
    "winogrande": 64.4,
    "average": 40.8
  },
  "digitous/Janin-GPTJ": {
    "arc": 40.87,
    "hellaswag": 67.29,
    "truthfulqa": 36.25,
    "mmlu": 27.4,
    "gsm8k": 1.97,
    "winogrande": 64.25,
    "average": 39.67
  },
  "digitous/Janin-R": {
    "arc": 40.44,
    "hellaswag": 67.36,
    "truthfulqa": 34.49,
    "mmlu": 31.24,
    "gsm8k": 2.27,
    "winogrande": 65.35,
    "average": 40.19
  },
  "digitous/Javalion-GPTJ": {
    "arc": 41.89,
    "hellaswag": 68.69,
    "truthfulqa": 35.44,
    "mmlu": 26.85,
    "gsm8k": 1.67,
    "winogrande": 65.27,
    "average": 39.97
  },
  "digitous/Javalion-R": {
    "arc": 41.72,
    "hellaswag": 68.02,
    "truthfulqa": 34.44,
    "mmlu": 30.81,
    "gsm8k": 2.65,
    "winogrande": 65.43,
    "average": 40.51
  },
  "digitous/Javelin-GPTJ": {
    "arc": 42.66,
    "hellaswag": 70.45,
    "truthfulqa": 36.08,
    "mmlu": 26.2,
    "gsm8k": 1.82,
    "winogrande": 64.17,
    "average": 40.23
  },
  "digitous/Javelin-R": {
    "arc": 41.64,
    "hellaswag": 69.01,
    "truthfulqa": 34.5,
    "mmlu": 30.7,
    "gsm8k": 1.67,
    "winogrande": 64.8,
    "average": 40.39
  },
  "digitous/Skegma-GPTJ": {
    "arc": 43.77,
    "hellaswag": 69.22,
    "truthfulqa": 34.67,
    "mmlu": 25.37,
    "gsm8k": 1.52,
    "winogrande": 64.64,
    "average": 39.87
  },
  "doas/test2": {
    "arc": 29.61,
    "hellaswag": 26.65,
    "truthfulqa": 48.49,
    "mmlu": 24.34,
    "gsm8k": 0,
    "winogrande": 50.12,
    "average": 29.87
  },
  "doas/test5": {
    "arc": 28.41,
    "hellaswag": 26.63,
    "truthfulqa": 47.34,
    "mmlu": 25.36,
    "gsm8k": 0,
    "winogrande": 52.64,
    "average": 30.06
  },
  "dotvignesh/perry-7b": {
    "arc": 51.79,
    "hellaswag": 76.43,
    "truthfulqa": 40.08,
    "mmlu": 46.18,
    "gsm8k": 10.31,
    "winogrande": 72.53,
    "average": 49.55
  },
  "dpv/finetuned-gpt2-tiny": {
    "arc": 21.84,
    "hellaswag": 31.6,
    "truthfulqa": 40.67,
    "mmlu": 25.86,
    "gsm8k": 0.3,
    "winogrande": 50.12,
    "average": 28.4
  },
  "dsvv-cair/alpaca-cleaned-llama-30b-bf16": {
    "arc": 61.77,
    "hellaswag": 85.06,
    "truthfulqa": 51.49,
    "mmlu": 57.52,
    "gsm8k": 7.73,
    "winogrande": 77.35,
    "average": 56.82
  },
  "duliadotio/dulia-13b-8k-alpha": {
    "arc": 60.67,
    "hellaswag": 82,
    "truthfulqa": 42.59,
    "mmlu": 56.87,
    "gsm8k": 10.69,
    "winogrande": 77.19,
    "average": 55
  },
  "dvruette/gpt-neox-20b-full-precision": {
    "arc": 48.81,
    "hellaswag": 74.44,
    "truthfulqa": 36.89,
    "mmlu": 26.16,
    "gsm8k": 2.65,
    "winogrande": 68.27,
    "average": 42.87
  },
  "dvruette/llama-13b-pretrained": {
    "arc": 56.31,
    "hellaswag": 79.32,
    "truthfulqa": 48.42,
    "mmlu": 47.03,
    "gsm8k": 16.07,
    "winogrande": 76.95,
    "average": 54.02
  },
  "dvruette/llama-13b-pretrained-dropout": {
    "arc": 56.4,
    "hellaswag": 79.34,
    "truthfulqa": 48.6,
    "mmlu": 46.59,
    "gsm8k": 11.83,
    "winogrande": 75.22,
    "average": 53
  },
  "dvruette/llama-13b-pretrained-sft-do2": {
    "arc": 58.96,
    "hellaswag": 80.32,
    "truthfulqa": 47.41,
    "mmlu": 47.25,
    "gsm8k": 9.25,
    "winogrande": 75.53,
    "average": 53.12
  },
  "dvruette/llama-13b-pretrained-sft-epoch-1": {
    "arc": 57.25,
    "hellaswag": 79.99,
    "truthfulqa": 44.45,
    "mmlu": 45.52,
    "gsm8k": 13.87,
    "winogrande": 77.58,
    "average": 53.11
  },
  "dvruette/oasst-gpt-neox-20b-1000-steps": {
    "arc": 48.55,
    "hellaswag": 74.61,
    "truthfulqa": 35.63,
    "mmlu": 26.39,
    "gsm8k": 3.11,
    "winogrande": 66.77,
    "average": 42.51
  },
  "dvruette/oasst-gpt-neox-20b-3000-steps": {
    "arc": 46.42,
    "hellaswag": 72.08,
    "truthfulqa": 35.53,
    "mmlu": 26.16,
    "gsm8k": 2.88,
    "winogrande": 68.75,
    "average": 41.97
  },
  "dvruette/oasst-llama-13b-1000-steps": {
    "arc": 58.11,
    "hellaswag": 81.52,
    "truthfulqa": 35.99,
    "mmlu": 48.65,
    "gsm8k": 11.3,
    "winogrande": 77.51,
    "average": 52.18
  },
  "dvruette/oasst-llama-13b-2-epochs": {
    "arc": 57.94,
    "hellaswag": 82.4,
    "truthfulqa": 47.27,
    "mmlu": 48.56,
    "gsm8k": 8.26,
    "winogrande": 76.87,
    "average": 53.55
  },
  "dvruette/oasst-pythia-12b-6000-steps": {
    "arc": 45.39,
    "hellaswag": 69.68,
    "truthfulqa": 39.85,
    "mmlu": 25.97,
    "gsm8k": 0.53,
    "winogrande": 63.22,
    "average": 40.77
  },
  "dvruette/oasst-pythia-12b-flash-attn-5000-steps": {
    "arc": 44.97,
    "hellaswag": 69.75,
    "truthfulqa": 38.89,
    "mmlu": 26.64,
    "gsm8k": 0.99,
    "winogrande": 63.14,
    "average": 40.73
  },
  "dvruette/oasst-pythia-12b-pretrained-sft": {
    "arc": 45.31,
    "hellaswag": 67.67,
    "truthfulqa": 38.16,
    "mmlu": 27.81,
    "gsm8k": 4.02,
    "winogrande": 65.9,
    "average": 41.48
  },
  "dvruette/oasst-pythia-12b-reference": {
    "arc": 43,
    "hellaswag": 67.91,
    "truthfulqa": 36.57,
    "mmlu": 28.33,
    "gsm8k": 1.21,
    "winogrande": 64.96,
    "average": 40.33
  },
  "dvruette/oasst-pythia-6.9b-4000-steps": {
    "arc": 41.64,
    "hellaswag": 64.24,
    "truthfulqa": 40.43,
    "mmlu": 26.26,
    "gsm8k": 0.53,
    "winogrande": 61.8,
    "average": 39.15
  },
  "eachadea/vicuna-13b": {
    "arc": 51.71,
    "hellaswag": 79.94,
    "truthfulqa": 52.68,
    "mmlu": 50.84,
    "gsm8k": 7.58,
    "winogrande": 71.03,
    "average": 52.3
  },
  "eachadea/vicuna-13b-1.1": {
    "arc": 52.73,
    "hellaswag": 80.13,
    "truthfulqa": 52.08,
    "mmlu": 51.94,
    "gsm8k": 8.64,
    "winogrande": 74.19,
    "average": 53.29
  },
  "eachadea/vicuna-7b-1.1": {
    "arc": 53.67,
    "hellaswag": 77.46,
    "truthfulqa": 48.94,
    "mmlu": 45.63,
    "gsm8k": 5.53,
    "winogrande": 70.96,
    "average": 50.37
  },
  "edor/Hermes-Platypus2-mini-7B": {
    "arc": 53.75,
    "hellaswag": 79.24,
    "truthfulqa": 49.28,
    "mmlu": 47.08
  },
  "edor/Platypus2-mini-7B": {
    "arc": 53.33,
    "hellaswag": 78.81,
    "truthfulqa": 42,
    "mmlu": 45.58,
    "gsm8k": 6.22,
    "winogrande": 75.14,
    "average": 50.18
  },
  "edor/Stable-Platypus2-mini-7B": {
    "arc": 54.86,
    "hellaswag": 78.95,
    "truthfulqa": 51.06,
    "mmlu": 51.78
  },
  "ehartford/CodeLlama-34b-Instruct-hf": {
    "arc": 40.78,
    "hellaswag": 35.68,
    "truthfulqa": 44.29,
    "mmlu": 39.75
  },
  "ehartford/CodeLlama-34b-Python-hf": {
    "arc": 38.05,
    "hellaswag": 34.79,
    "truthfulqa": 43.57,
    "mmlu": 32.96,
    "gsm8k": 0,
    "winogrande": 66.14,
    "average": 35.92
  },
  "ehartford/Samantha-1.1-70b": {
    "arc": 68.77,
    "hellaswag": 87.46,
    "truthfulqa": 64.85,
    "mmlu": 68.6,
    "gsm8k": 31.61,
    "winogrande": 83.27,
    "average": 67.43
  },
  "ehartford/Samantha-1.11-13b": {
    "arc": 60.84,
    "hellaswag": 82.99,
    "truthfulqa": 47.72,
    "mmlu": 55.96,
    "gsm8k": 12.28,
    "winogrande": 76.01,
    "average": 55.97
  },
  "ehartford/Samantha-1.11-70b": {
    "arc": 70.05,
    "hellaswag": 87.55,
    "truthfulqa": 65.02,
    "mmlu": 67.82,
    "gsm8k": 29.95,
    "winogrande": 83.27,
    "average": 67.28
  },
  "ehartford/Samantha-1.11-7b": {
    "arc": 55.03,
    "hellaswag": 79.12,
    "truthfulqa": 50.37,
    "mmlu": 40.51,
    "gsm8k": 7.2,
    "winogrande": 74.19,
    "average": 51.07
  },
  "ehartford/Samantha-1.11-CodeLlama-34b": {
    "arc": 56.57,
    "hellaswag": 75.47,
    "truthfulqa": 50.46,
    "mmlu": 53.51,
    "gsm8k": 19.33,
    "winogrande": 73.48,
    "average": 54.8
  },
  "ehartford/Wizard-Vicuna-13B-Uncensored": {
    "arc": 58.96,
    "hellaswag": 81.95,
    "truthfulqa": 51.69,
    "mmlu": 47.92,
    "gsm8k": 8.64,
    "winogrande": 75.69,
    "average": 54.14
  },
  "ehartford/Wizard-Vicuna-30B-Uncensored": {
    "arc": 62.12,
    "hellaswag": 83.45,
    "truthfulqa": 50.81,
    "mmlu": 58.24,
    "gsm8k": 14.25,
    "winogrande": 78.45,
    "average": 57.89
  },
  "ehartford/Wizard-Vicuna-7B-Uncensored": {
    "arc": 53.41,
    "hellaswag": 78.85,
    "truthfulqa": 43.48,
    "mmlu": 37.09,
    "gsm8k": 4.55,
    "winogrande": 72.22,
    "average": 48.27
  },
  "ehartford/WizardLM-1.0-Uncensored-CodeLlama-34b": {
    "arc": 56.4,
    "hellaswag": 75.45,
    "truthfulqa": 43.06,
    "mmlu": 54.51,
    "gsm8k": 19.64,
    "winogrande": 72.45,
    "average": 53.59
  },
  "ehartford/WizardLM-1.0-Uncensored-Llama2-13b": {
    "arc": 55.72,
    "hellaswag": 80.34,
    "truthfulqa": 51.44,
    "mmlu": 55.4,
    "gsm8k": 13.27,
    "winogrande": 74.11,
    "average": 55.05
  },
  "ehartford/WizardLM-13B-Uncensored": {
    "arc": 50.94,
    "hellaswag": 76.64,
    "truthfulqa": 46.73,
    "mmlu": 43.96,
    "gsm8k": 2.05,
    "winogrande": 70.56,
    "average": 48.48
  },
  "ehartford/WizardLM-30B-Uncensored": {
    "arc": 60.24,
    "hellaswag": 82.93,
    "truthfulqa": 51.57,
    "mmlu": 56.8,
    "gsm8k": 12.89,
    "winogrande": 74.35,
    "average": 56.46
  },
  "ehartford/WizardLM-33B-V1.0-Uncensored": {
    "arc": 63.65,
    "hellaswag": 83.84,
    "truthfulqa": 56.8,
    "mmlu": 59.36,
    "gsm8k": 18.65,
    "winogrande": 77.66,
    "average": 59.99
  },
  "ehartford/WizardLM-7B-Uncensored": {
    "arc": 47.87,
    "hellaswag": 73.08,
    "truthfulqa": 41.49,
    "mmlu": 35.42,
    "gsm8k": 3.26,
    "winogrande": 68.43,
    "average": 44.93
  },
  "ehartford/based-30b": {
    "arc": 63.91,
    "hellaswag": 85.67,
    "truthfulqa": 35.7,
    "mmlu": 58.28,
    "gsm8k": 0.3,
    "winogrande": 80.11,
    "average": 54
  },
  "ehartford/dolphin-2.0-mistral-7b": {
    "arc": 59.22,
    "hellaswag": 80.26,
    "truthfulqa": 61.09,
    "mmlu": 56.9,
    "gsm8k": 18.65,
    "winogrande": 75.37,
    "average": 58.58
  },
  "ehartford/dolphin-2.1-mistral-7b": {
    "arc": 64.42,
    "hellaswag": 84.92,
    "truthfulqa": 55.56,
    "mmlu": 63.32,
    "gsm8k": 20.77,
    "winogrande": 77.74,
    "average": 61.12
  },
  "ehartford/dolphin-2.2.1-mistral-7b": {
    "arc": 63.31,
    "hellaswag": 83.76,
    "truthfulqa": 53.11,
    "winogrande": 78.14,
    "gsm8k": 48.07,
    "mmlu": 63.17,
    "average": 64.93
  },
  "ehartford/dolphin-llama-13b": {
    "arc": 55.55,
    "hellaswag": 77.11,
    "truthfulqa": 52.23,
    "mmlu": 52.16,
    "gsm8k": 14.4,
    "winogrande": 69.93,
    "average": 53.56
  },
  "ehartford/dolphin-llama2-7b": {
    "arc": 46.59,
    "hellaswag": 67.52,
    "truthfulqa": 49.72,
    "mmlu": 48.37,
    "gsm8k": 5.69,
    "winogrande": 63.77,
    "average": 46.94
  },
  "ehartford/minotaur-llama2-13b-qlora": {
    "arc": 60.07,
    "hellaswag": 82.42,
    "truthfulqa": 45.57,
    "mmlu": 55.87,
    "gsm8k": 12.05,
    "winogrande": 76.24,
    "average": 55.37
  },
  "ehartford/samantha-1.1-llama-33b": {
    "arc": 67.83,
    "hellaswag": 85.55,
    "truthfulqa": 61.19,
    "mmlu": 58.79,
    "gsm8k": 4.02,
    "winogrande": 76.48,
    "average": 58.98
  },
  "ehartford/samantha-1.2-mistral-7b": {
    "arc": 64.08,
    "hellaswag": 85.08,
    "truthfulqa": 50.4,
    "mmlu": 63.91,
    "gsm8k": 16.98,
    "winogrande": 78.53,
    "average": 59.83
  },
  "ehartford/samantha-mistral-7b": {
    "arc": 63.4,
    "hellaswag": 84.1,
    "truthfulqa": 46.08,
    "mmlu": 61.36,
    "gsm8k": 16,
    "winogrande": 76.8,
    "average": 57.96
  },
  "ehartford/samantha-mistral-instruct-7b": {
    "arc": 53.5,
    "hellaswag": 75.14,
    "truthfulqa": 58.81,
    "mmlu": 51.72,
    "gsm8k": 10.84,
    "winogrande": 70.4,
    "average": 53.4
  },
  "elinas/chronos-13b-v2": {
    "arc": 58.7,
    "hellaswag": 82.52,
    "truthfulqa": 50.55,
    "mmlu": 53.39,
    "gsm8k": 11.3,
    "winogrande": 75.06,
    "average": 55.25
  },
  "elinas/chronos-33b": {
    "arc": 62.2,
    "hellaswag": 83.48,
    "truthfulqa": 46.67,
    "mmlu": 55.87,
    "gsm8k": 13.04,
    "winogrande": 78.3,
    "average": 56.59
  },
  "elinas/chronos-70b-v2": {
    "arc": 68.09,
    "hellaswag": 86.5,
    "truthfulqa": 53.7,
    "mmlu": 68.28,
    "gsm8k": 28.66,
    "winogrande": 81.22,
    "average": 64.41
  },
  "elinas/chronos007-70b": {
    "arc": 70.14,
    "hellaswag": 87.52,
    "truthfulqa": 57.65,
    "mmlu": 69.33,
    "gsm8k": 42.61,
    "winogrande": 82.24,
    "average": 68.25
  },
  "elliotthwang/Elliott-Chinese-LLaMa-GPTQ": {
    "arc": 51.02,
    "hellaswag": 75.23,
    "truthfulqa": 45.09,
    "mmlu": 49.58,
    "gsm8k": 17.21,
    "winogrande": 72.61,
    "average": 51.79
  },
  "elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V1.0": {
    "arc": 50.68,
    "hellaswag": 75.36,
    "truthfulqa": 44.7,
    "mmlu": 49.33,
    "gsm8k": 17.36,
    "winogrande": 72.38,
    "average": 51.64
  },
  "elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V2.0": {
    "arc": 50.77,
    "hellaswag": 75.36,
    "truthfulqa": 44.7,
    "mmlu": 49.41,
    "gsm8k": 16,
    "winogrande": 72.61,
    "average": 51.47
  },
  "elliotthwang/elliott_Llama-2-7b-hf": {
    "arc": 53.16,
    "hellaswag": 78.33,
    "truthfulqa": 42.11,
    "mmlu": 47.09,
    "gsm8k": 6.9,
    "winogrande": 73.64,
    "average": 50.21
  },
  "elyza/ELYZA-japanese-Llama-2-7b": {
    "arc": 52.22,
    "hellaswag": 76.42,
    "truthfulqa": 37.92,
    "mmlu": 44.6,
    "gsm8k": 8.34,
    "winogrande": 72.69,
    "average": 48.7
  },
  "elyza/ELYZA-japanese-Llama-2-7b-fast": {
    "arc": 51.88,
    "hellaswag": 75.46,
    "truthfulqa": 36.45,
    "mmlu": 44.34,
    "gsm8k": 6.29,
    "winogrande": 71.59,
    "average": 47.67
  },
  "elyza/ELYZA-japanese-Llama-2-7b-fast-instruct": {
    "arc": 53.75,
    "hellaswag": 77.55,
    "truthfulqa": 38.84,
    "mmlu": 46.85,
    "gsm8k": 6.29,
    "winogrande": 71.59,
    "average": 49.15
  },
  "elyza/ELYZA-japanese-Llama-2-7b-instruct": {
    "arc": 53.16,
    "hellaswag": 78.25,
    "truthfulqa": 39.08,
    "mmlu": 47.07,
    "gsm8k": 7.88,
    "winogrande": 73.24,
    "average": 49.78
  },
  "ericzzz/falcon-rw-1b-instruct-openorca": {
    "arc": 34.56,
    "hellaswag": 60.93,
    "truthfulqa": 37.42,
    "winogrande": 60.69,
    "gsm8k": 3.41,
    "mmlu": 28.77,
    "average": 37.63
  },
  "ethzanalytics/pythia-31m": {
    "arc": 21.84,
    "hellaswag": 27,
    "truthfulqa": 49.1,
    "mmlu": 24.97,
    "gsm8k": 0.23,
    "winogrande": 49.72,
    "average": 28.81
  },
  "euclaise/Ferret-7B": {
    "arc": 62.29,
    "hellaswag": 81.31,
    "truthfulqa": 40.01,
    "winogrande": 77.66,
    "gsm8k": 2.05,
    "mmlu": 60.27,
    "average": 53.93
  },
  "euclaise/Ferret_7B": {
    "arc": 62.29,
    "hellaswag": 81.33,
    "truthfulqa": 39.94,
    "winogrande": 77.51,
    "gsm8k": 2.05,
    "mmlu": 60.09,
    "average": 53.87
  },
  "euclaise/falcon_1b_stage1": {
    "arc": 35.15,
    "hellaswag": 62.4,
    "truthfulqa": 40,
    "mmlu": 24.47,
    "gsm8k": 0,
    "winogrande": 61.48,
    "average": 37.25
  },
  "euclaise/falcon_1b_stage2": {
    "arc": 33.11,
    "hellaswag": 63.19,
    "truthfulqa": 38.4,
    "mmlu": 24.22,
    "gsm8k": 0,
    "winogrande": 62.35,
    "average": 36.88
  },
  "euclaise/falcon_1b_stage3": {
    "arc": 33.11,
    "hellaswag": 54.08,
    "truthfulqa": 37.92,
    "mmlu": 25.11,
    "gsm8k": 0,
    "winogrande": 59.51,
    "average": 34.96
  },
  "euclaise/falcon_1b_stage3_2": {
    "arc": 34.56,
    "hellaswag": 58.37,
    "truthfulqa": 39.89,
    "mmlu": 23.87,
    "gsm8k": 0,
    "winogrande": 60.46,
    "average": 36.19
  },
  "euclaise/gpt-neox-122m-minipile-digits": {
    "arc": 20.73,
    "hellaswag": 27.03,
    "truthfulqa": 49.19,
    "mmlu": 25.31,
    "gsm8k": 0,
    "winogrande": 52.33,
    "average": 29.1
  },
  "ewof/koishi-instruct-3b": {
    "arc": 40.96,
    "hellaswag": 64.54,
    "truthfulqa": 31.65,
    "mmlu": 26.58,
    "gsm8k": 1.14,
    "winogrande": 64.09,
    "average": 38.16
  },
  "facebook/galactica-1.3b": {
    "arc": 34.13,
    "hellaswag": 40.91,
    "truthfulqa": 41.4,
    "mmlu": 27.09
  },
  "facebook/galactica-30b": {
    "arc": 47.35,
    "hellaswag": 61.21,
    "truthfulqa": 38.01,
    "mmlu": 47.56
  },
  "facebook/opt-1.3b": {
    "arc": 29.52,
    "hellaswag": 54.53,
    "truthfulqa": 38.71,
    "mmlu": 24.96,
    "gsm8k": 0.15,
    "winogrande": 59.75,
    "average": 34.6
  },
  "facebook/opt-125m": {
    "arc": 22.87,
    "hellaswag": 31.47,
    "truthfulqa": 42.87,
    "mmlu": 26.02,
    "gsm8k": 0.08,
    "winogrande": 51.62,
    "average": 29.16
  },
  "facebook/opt-13b": {
    "arc": 39.93,
    "hellaswag": 71.2,
    "truthfulqa": 34.1,
    "mmlu": 24.9,
    "gsm8k": 1.74,
    "winogrande": 68.51,
    "average": 40.06
  },
  "facebook/opt-2.7b": {
    "arc": 33.96,
    "hellaswag": 61.43,
    "truthfulqa": 37.43,
    "mmlu": 25.43,
    "gsm8k": 0.23,
    "winogrande": 61.96,
    "average": 36.74
  },
  "facebook/opt-30b": {
    "arc": 43.26,
    "hellaswag": 74.07,
    "truthfulqa": 35.16,
    "mmlu": 26.66,
    "gsm8k": 2.2,
    "winogrande": 70.64,
    "average": 42
  },
  "facebook/opt-350m": {
    "arc": 23.55,
    "hellaswag": 36.73,
    "truthfulqa": 40.83,
    "mmlu": 26.02,
    "gsm8k": 0.3,
    "winogrande": 52.64,
    "average": 30.01
  },
  "facebook/opt-6.7b": {
    "arc": 39.16,
    "hellaswag": 68.66,
    "truthfulqa": 35.12,
    "mmlu": 24.57,
    "gsm8k": 0.99,
    "winogrande": 65.98,
    "average": 39.08
  },
  "facebook/opt-66b": {
    "gsm8k": 1.67,
    "winogrande": 70.01,
    "arc": 46.33,
    "hellaswag": 76.25,
    "truthfulqa": 35.43,
    "mmlu": 26.99,
    "average": 42.78
  },
  "facebook/opt-iml-max-1.3b": {
    "arc": 30.72,
    "hellaswag": 53.81,
    "truthfulqa": 38.34,
    "mmlu": 27.61,
    "gsm8k": 0.53,
    "winogrande": 60.22,
    "average": 35.21
  },
  "facebook/opt-iml-max-30b": {
    "arc": 43.86,
    "hellaswag": 72.39,
    "truthfulqa": 38.16,
    "mmlu": 41.09,
    "gsm8k": 2.5,
    "winogrande": 73.72,
    "average": 45.29
  },
  "facebook/xglm-1.7B": {
    "arc": 25.85,
    "hellaswag": 45.68,
    "truthfulqa": 37.21,
    "mmlu": 25.1,
    "gsm8k": 0.76,
    "winogrande": 53.91,
    "average": 31.42
  },
  "facebook/xglm-4.5B": {
    "arc": 31.48,
    "hellaswag": 57.95,
    "truthfulqa": 35.84,
    "mmlu": 25.43,
    "gsm8k": 0.23,
    "winogrande": 54.93,
    "average": 34.31
  },
  "facebook/xglm-564M": {
    "arc": 24.57,
    "hellaswag": 34.64,
    "truthfulqa": 40.43,
    "mmlu": 25.18,
    "gsm8k": 0.23,
    "winogrande": 52.25,
    "average": 29.55
  },
  "facebook/xglm-7.5B": {
    "arc": 34.13,
    "hellaswag": 60.77,
    "truthfulqa": 36.66,
    "mmlu": 27.79,
    "gsm8k": 0.23,
    "winogrande": 58.72,
    "average": 36.38
  },
  "fangloveskari/ORCA_LLaMA_70B_QLoRA": {
    "arc": 72.27,
    "hellaswag": 87.74,
    "truthfulqa": 63.37,
    "mmlu": 70.23,
    "gsm8k": 28.35,
    "winogrande": 83.66,
    "average": 67.6
  },
  "fangloveskari/Platypus_QLoRA_LLaMA_70b": {
    "arc": 72.1,
    "hellaswag": 87.46,
    "truthfulqa": 61.18,
    "mmlu": 71.02,
    "gsm8k": 30.78,
    "winogrande": 82.87,
    "average": 67.57
  },
  "fblgit/juanako-7b-UNA": {
    "arc": 68.17,
    "hellaswag": 85.34,
    "truthfulqa": 65.13,
    "winogrande": 78.85,
    "gsm8k": 44.81,
    "mmlu": 62.47,
    "average": 67.46
  },
  "fblgit/una-cybertron-7b-v1-fp16": {
    "arc": 68.43,
    "hellaswag": 85.42,
    "truthfulqa": 63.28,
    "winogrande": 81.37,
    "gsm8k": 55.12,
    "mmlu": 63.34,
    "average": 69.49
  },
  "fblgit/una-cybertron-7b-v2-bf16": {
    "arc": 68.26,
    "hellaswag": 85.85,
    "truthfulqa": 64.63,
    "winogrande": 80.98,
    "gsm8k": 55.04,
    "mmlu": 63.23,
    "average": 69.67
  },
  "feidfoe/Metamath-reproduce-7b": {
    "arc": 47.18,
    "hellaswag": 73.65,
    "truthfulqa": 41.58,
    "winogrande": 71.35,
    "gsm8k": 58.15,
    "mmlu": 42.94,
    "average": 55.81
  },
  "fireballoon/baichuan-vicuna-chinese-7b": {
    "arc": 43.52,
    "hellaswag": 71.12,
    "truthfulqa": 42.45,
    "mmlu": 46.87,
    "gsm8k": 5.53,
    "winogrande": 66.85,
    "average": 46.06
  },
  "formulae/Dorflan": {
    "arc": 54.44,
    "hellaswag": 75.78,
    "truthfulqa": 51.17,
    "mmlu": 51.36,
    "gsm8k": 0.38,
    "winogrande": 72.61,
    "average": 50.96
  },
  "frank098/Wizard-Vicuna-13B-juniper": {
    "arc": 55.89,
    "hellaswag": 79.75,
    "truthfulqa": 54.72,
    "mmlu": 44.99,
    "gsm8k": 7.28,
    "winogrande": 72.69,
    "average": 52.55
  },
  "frank098/WizardLM_13B_juniper": {
    "arc": 55.38,
    "hellaswag": 77.2,
    "truthfulqa": 51.5,
    "mmlu": 45.46,
    "gsm8k": 8.04,
    "winogrande": 71.11,
    "average": 51.45
  },
  "frank098/orca_mini_3b_juniper": {
    "arc": 40.87,
    "hellaswag": 61.73,
    "truthfulqa": 43.19,
    "mmlu": 26.37,
    "gsm8k": 0.53,
    "winogrande": 60.3,
    "average": 38.83
  },
  "gaodrew/OpenOrca-Platypus2-13B-thera-1250": {
    "arc": 59.22,
    "hellaswag": 81.02,
    "truthfulqa": 48.43,
    "mmlu": 57.04,
    "gsm8k": 8.57,
    "winogrande": 73.09,
    "average": 54.56
  },
  "gaodrew/gaodrew-gorgonzola-13b": {
    "arc": 53.84,
    "hellaswag": 78.86,
    "truthfulqa": 42.58,
    "mmlu": 71.54,
    "gsm8k": 10.01,
    "winogrande": 75.3,
    "average": 55.36
  },
  "gaodrew/gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps": {
    "arc": 61.52,
    "hellaswag": 84.06,
    "truthfulqa": 51.05,
    "mmlu": 60.23,
    "gsm8k": 17.66,
    "winogrande": 80.82,
    "average": 59.22
  },
  "garage-bAInd/Camel-Platypus2-13B": {
    "arc": 60.75,
    "hellaswag": 83.61,
    "truthfulqa": 49.6,
    "mmlu": 56.51,
    "gsm8k": 0.08,
    "winogrande": 75.37,
    "average": 54.32
  },
  "garage-bAInd/Camel-Platypus2-70B": {
    "arc": 71.08,
    "hellaswag": 87.6,
    "truthfulqa": 58.09,
    "mmlu": 70.04,
    "gsm8k": 23.96,
    "winogrande": 82.95,
    "average": 65.62
  },
  "garage-bAInd/Platypus-30B": {
    "arc": 64.59,
    "hellaswag": 84.26,
    "truthfulqa": 45.35,
    "mmlu": 64.23,
    "gsm8k": 14.4,
    "winogrande": 81.37,
    "average": 59.03
  },
  "garage-bAInd/Platypus2-13B": {
    "arc": 61.26,
    "hellaswag": 82.56,
    "truthfulqa": 44.86,
    "mmlu": 56.7,
    "gsm8k": 7.05,
    "winogrande": 76.87,
    "average": 54.88
  },
  "garage-bAInd/Platypus2-70B": {
    "arc": 70.65,
    "hellaswag": 87.15,
    "truthfulqa": 52.37,
    "mmlu": 70.08,
    "gsm8k": 33.06,
    "winogrande": 84.37,
    "average": 66.28
  },
  "garage-bAInd/Platypus2-70B-instruct": {
    "arc": 71.84,
    "hellaswag": 87.94,
    "truthfulqa": 62.26,
    "mmlu": 70.48,
    "gsm8k": 40.56,
    "winogrande": 82.72,
    "average": 69.3
  },
  "garage-bAInd/Platypus2-7B": {
    "arc": 55.2,
    "hellaswag": 78.84,
    "truthfulqa": 40.64,
    "mmlu": 49.83,
    "gsm8k": 1.82,
    "winogrande": 73.48,
    "average": 49.97
  },
  "garage-bAInd/Stable-Platypus2-13B": {
    "arc": 62.71,
    "hellaswag": 82.29,
    "truthfulqa": 52.52,
    "mmlu": 58.3,
    "gsm8k": 1.82,
    "winogrande": 76.87,
    "average": 55.75
  },
  "georgesung/llama2_7b_chat_uncensored": {
    "arc": 53.58,
    "hellaswag": 78.66,
    "truthfulqa": 41.34,
    "mmlu": 44.49,
    "gsm8k": 5.84,
    "winogrande": 74.11,
    "average": 49.67
  },
  "glaiveai/glaive-coder-7b": {
    "arc": 42.66,
    "hellaswag": 64.69,
    "truthfulqa": 39.88,
    "mmlu": 37.15,
    "gsm8k": 5.23,
    "winogrande": 59.75,
    "average": 41.56
  },
  "golaxy/gogpt-3b-bloom": {
    "arc": 31.91,
    "hellaswag": 50.32,
    "truthfulqa": 41.79,
    "mmlu": 25.2,
    "gsm8k": 0.15,
    "winogrande": 54.38,
    "average": 33.96
  },
  "golaxy/gogpt-560m": {
    "arc": 26.37,
    "hellaswag": 31.86,
    "truthfulqa": 43.12,
    "mmlu": 25.29,
    "gsm8k": 0,
    "winogrande": 50.75,
    "average": 29.57
  },
  "golaxy/gogpt-7b": {
    "arc": 48.81,
    "hellaswag": 73.79,
    "truthfulqa": 41,
    "mmlu": 43.03,
    "gsm8k": 1.9,
    "winogrande": 69.77,
    "average": 46.38
  },
  "golaxy/gogpt-7b-bloom": {
    "arc": 44.62,
    "hellaswag": 62.56,
    "truthfulqa": 40.61,
    "mmlu": 33.81,
    "gsm8k": 0,
    "winogrande": 62.9,
    "average": 40.75
  },
  "golaxy/gogpt2-13b": {
    "arc": 48.38,
    "hellaswag": 71.78,
    "truthfulqa": 44.73,
    "mmlu": 44.5,
    "gsm8k": 2.05,
    "winogrande": 67.88,
    "average": 46.55
  },
  "golaxy/gogpt2-13b-chat": {
    "arc": 48.38,
    "hellaswag": 71.78,
    "truthfulqa": 44.73,
    "mmlu": 44.5
  },
  "golaxy/gogpt2-7b": {
    "arc": 46.76,
    "hellaswag": 71.53,
    "truthfulqa": 47.85,
    "mmlu": 42.85,
    "gsm8k": 2.27,
    "winogrande": 68.67,
    "average": 46.66
  },
  "golaxy/goims": {
    "arc": 49.49,
    "hellaswag": 72.67,
    "truthfulqa": 44.8,
    "mmlu": 43.85,
    "gsm8k": 6.29,
    "winogrande": 69.69,
    "average": 47.8
  },
  "golaxy/gowizardlm": {
    "arc": 49.74,
    "hellaswag": 71.9,
    "truthfulqa": 47.66,
    "mmlu": 42.96,
    "gsm8k": 3.94,
    "winogrande": 69.61,
    "average": 47.64
  },
  "gradientputri/MegaMix-A1-13B": {
    "arc": 61.6,
    "hellaswag": 83.49,
    "truthfulqa": 47.48,
    "mmlu": 58.26,
    "gsm8k": 24.11,
    "winogrande": 76.16,
    "average": 58.52
  },
  "gradientputri/MegaMix-S1-13B": {
    "arc": 62.46,
    "hellaswag": 83.65,
    "truthfulqa": 44.52,
    "mmlu": 57.88,
    "gsm8k": 18.35,
    "winogrande": 75.85,
    "average": 57.12
  },
  "gradientputri/MegaMix-T1-13B": {
    "arc": 61.35,
    "hellaswag": 83.44,
    "truthfulqa": 48.19,
    "mmlu": 58.49,
    "gsm8k": 24.11,
    "winogrande": 76.09,
    "average": 58.61
  },
  "grantprice/Cerebras-GPT-590M-finetuned-DND": {
    "arc": 24.74,
    "hellaswag": 27.84,
    "truthfulqa": 48.26,
    "mmlu": 23.12
  },
  "grimpep/L2-MythoMax22b-instruct-Falseblock": {
    "arc": 60.49,
    "hellaswag": 82.06,
    "truthfulqa": 55.77,
    "mmlu": 52.9
  },
  "grimpep/MythoMax-L2-33b": {
    "arc": 57.25,
    "hellaswag": 79.12,
    "truthfulqa": 52.48,
    "mmlu": 50.85
  },
  "grimpep/llama2-22B-GPLATTY": {
    "arc": 58.96,
    "hellaswag": 82.01,
    "truthfulqa": 46.93,
    "mmlu": 54.55
  },
  "grimpep/llama2-22b-wizard_vicuna": {
    "arc": 58.96,
    "hellaswag": 82.01,
    "truthfulqa": 46.93,
    "mmlu": 54.55
  },
  "grimpep/llama2-28B-Airo03": {
    "arc": 58.45,
    "hellaswag": 81.39,
    "truthfulqa": 47.09,
    "mmlu": 53.31
  },
  "guardrail/llama-2-7b-guanaco-instruct-sharded": {
    "arc": 53.75,
    "hellaswag": 78.69,
    "truthfulqa": 43.93,
    "mmlu": 46.65,
    "gsm8k": 7.81,
    "winogrande": 72.61,
    "average": 50.57
  },
  "gywy/llama2-13b-chinese-v1": {
    "arc": 59.81,
    "hellaswag": 75.72,
    "truthfulqa": 45.72,
    "mmlu": 54.18
  },
  "gywy/llama2-13b-chinese-v2": {
    "arc": 53.92,
    "hellaswag": 74.64,
    "truthfulqa": 45.43,
    "mmlu": 49.74,
    "gsm8k": 2.2,
    "winogrande": 71.59,
    "average": 49.59
  },
  "h2oai/h2ogpt-gm-oasst1-en-1024-12b": {
    "arc": 43.09,
    "hellaswag": 69.75,
    "truthfulqa": 38,
    "mmlu": 25.87,
    "gsm8k": 1.06,
    "winogrande": 66.14,
    "average": 40.65
  },
  "h2oai/h2ogpt-gm-oasst1-en-1024-20b": {
    "arc": 48.04,
    "hellaswag": 72.76,
    "truthfulqa": 39.92,
    "mmlu": 25.96,
    "gsm8k": 2.5,
    "winogrande": 66.3,
    "average": 42.58
  },
  "h2oai/h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt": {
    "arc": 41.3,
    "hellaswag": 62.44,
    "truthfulqa": 42,
    "mmlu": 27.55,
    "gsm8k": 1.52,
    "winogrande": 64.56,
    "average": 39.9
  },
  "h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt": {
    "arc": 34.04,
    "hellaswag": 50.51,
    "truthfulqa": 41.8,
    "mmlu": 24.66,
    "gsm8k": 0,
    "winogrande": 54.93,
    "average": 34.32
  },
  "h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2": {
    "arc": 36.43,
    "hellaswag": 61.41,
    "truthfulqa": 37.59,
    "mmlu": 25.01,
    "gsm8k": 0.23,
    "winogrande": 64.64,
    "average": 37.55
  },
  "h2oai/h2ogpt-gm-oasst1-multilang-1024-20b": {
    "arc": 47.44,
    "hellaswag": 72.58,
    "truthfulqa": 34.39,
    "mmlu": 26.37,
    "gsm8k": 2.2,
    "winogrande": 68.43,
    "average": 41.9
  },
  "h2oai/h2ogpt-oasst1-512-12b": {
    "arc": 42.32,
    "hellaswag": 70.24,
    "truthfulqa": 36.41,
    "mmlu": 26.01,
    "gsm8k": 1.67,
    "winogrande": 66.22,
    "average": 40.48
  },
  "h2oai/h2ogpt-oasst1-512-20b": {
    "arc": 46.93,
    "hellaswag": 72.77,
    "truthfulqa": 37.5,
    "mmlu": 26.25,
    "gsm8k": 3.18,
    "winogrande": 68.03,
    "average": 42.44
  },
  "h2oai/h2ogpt-oig-oasst1-256-6_9b": {
    "arc": 39.93,
    "hellaswag": 65.42,
    "truthfulqa": 35,
    "mmlu": 26.39,
    "gsm8k": 1.59,
    "winogrande": 63.38,
    "average": 38.62
  },
  "h2oai/h2ogpt-oig-oasst1-512-6_9b": {
    "arc": 40.44,
    "hellaswag": 65.58,
    "truthfulqa": 36.68,
    "mmlu": 24.9,
    "gsm8k": 0.99,
    "winogrande": 62.51,
    "average": 38.52
  },
  "h2oai/h2ogpt-research-oasst1-llama-65b": {
    "arc": 64.76,
    "hellaswag": 85.94,
    "truthfulqa": 48.85,
    "mmlu": 63.57
  },
  "h2oai/h2ogpt-research-oig-oasst1-512-30b": {
    "arc": 58.96,
    "hellaswag": 82.61,
    "truthfulqa": 48.47,
    "mmlu": 50.74
  },
  "habanoz/TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1": {
    "arc": 30.55,
    "hellaswag": 53.7,
    "truthfulqa": 35.85,
    "winogrande": 58.09,
    "gsm8k": 0,
    "mmlu": 26.07,
    "average": 34.04
  },
  "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1": {
    "arc": 30.72,
    "hellaswag": 54.32,
    "truthfulqa": 41.67,
    "winogrande": 57.62,
    "gsm8k": 0.76,
    "mmlu": 24.78,
    "average": 34.98
  },
  "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1": {
    "arc": 31.48,
    "hellaswag": 54.4,
    "truthfulqa": 42.34,
    "winogrande": 57.54,
    "gsm8k": 1.44,
    "mmlu": 25.47,
    "average": 35.45
  },
  "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1": {
    "arc": 31.4,
    "hellaswag": 54.24,
    "truthfulqa": 42.47,
    "winogrande": 57.7,
    "gsm8k": 1.36,
    "mmlu": 25.36,
    "average": 35.42
  },
  "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1": {
    "arc": 31.14,
    "hellaswag": 54.31,
    "truthfulqa": 41.72,
    "winogrande": 57.77,
    "gsm8k": 1.29,
    "mmlu": 25.42,
    "average": 35.28
  },
  "habanoz/TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1": {
    "arc": 31.06,
    "hellaswag": 55.02,
    "truthfulqa": 35.08,
    "winogrande": 58.01,
    "gsm8k": 1.59,
    "mmlu": 26.41,
    "average": 34.53
  },
  "habanoz/tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1": {
    "arc": 32.85,
    "hellaswag": 58.16,
    "truthfulqa": 38.35,
    "winogrande": 57.7,
    "gsm8k": 0.45,
    "mmlu": 25.96,
    "average": 35.58
  },
  "hakurei/instruct-12b": {
    "arc": 42.58,
    "hellaswag": 66.76,
    "truthfulqa": 31.96,
    "mmlu": 26.79,
    "gsm8k": 0.23,
    "winogrande": 63.46,
    "average": 38.63
  },
  "hakurei/lotus-12B": {
    "arc": 30.72,
    "hellaswag": 52.71,
    "truthfulqa": 40.12,
    "mmlu": 24.55
  },
  "hakurei/mommygpt-3B": {
    "arc": 41.89,
    "hellaswag": 71.69,
    "truthfulqa": 37.9,
    "winogrande": 65.82,
    "gsm8k": 2.12,
    "mmlu": 28.74,
    "average": 41.36
  },
  "haonan-li/bactrian-x-llama-13b-merged": {
    "arc": 56.4,
    "hellaswag": 79.33,
    "truthfulqa": 48.38,
    "mmlu": 48.4,
    "gsm8k": 5.53,
    "winogrande": 73.95,
    "average": 52
  },
  "haoranxu/ALMA-13B-Pretrain": {
    "arc": 56.91,
    "hellaswag": 80.15,
    "truthfulqa": 37.44,
    "mmlu": 50.31,
    "gsm8k": 8.87,
    "winogrande": 76.4,
    "average": 51.68
  },
  "harborwater/open-llama-3b-claude-30k": {
    "arc": 41.72,
    "hellaswag": 72.64,
    "truthfulqa": 38.46,
    "winogrande": 66.54,
    "gsm8k": 2.2,
    "mmlu": 24.03,
    "average": 40.93
  },
  "harborwater/open-llama-3b-everything-v2": {
    "arc": 42.83,
    "hellaswag": 73.28,
    "truthfulqa": 37.26,
    "mmlu": 26.87,
    "gsm8k": 1.59,
    "winogrande": 66.61,
    "average": 41.41
  },
  "harborwater/open-llama-3b-everythingLM-2048": {
    "arc": 42.75,
    "hellaswag": 71.72,
    "truthfulqa": 34.26,
    "mmlu": 27.16,
    "gsm8k": 1.52,
    "winogrande": 66.3,
    "average": 40.62
  },
  "harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k": {
    "arc": 41.81,
    "hellaswag": 73.01,
    "truthfulqa": 38.99,
    "mmlu": 26.36,
    "gsm8k": 1.9,
    "winogrande": 66.69,
    "average": 41.46
  },
  "harborwater/wizard-orca-3b": {
    "arc": 41.72,
    "hellaswag": 71.78,
    "truthfulqa": 40.04,
    "mmlu": 24.49,
    "gsm8k": 1.06,
    "winogrande": 66.93,
    "average": 41
  },
  "health360/Healix-3B": {
    "arc": 37.71,
    "hellaswag": 65.94,
    "truthfulqa": 37.4,
    "mmlu": 26.02,
    "gsm8k": 0.76,
    "winogrande": 65.75,
    "average": 38.93
  },
  "health360/Healix-410M": {
    "arc": 25.09,
    "hellaswag": 32.02,
    "truthfulqa": 44.42,
    "mmlu": 24.94,
    "gsm8k": 0,
    "winogrande": 54.14,
    "average": 30.1
  },
  "heegyu/LIMA-13b-hf": {
    "arc": 57.42,
    "hellaswag": 81.68,
    "truthfulqa": 41.76,
    "mmlu": 48.72,
    "gsm8k": 8.87,
    "winogrande": 77.19,
    "average": 52.61
  },
  "heegyu/LIMA2-13b-hf": {
    "arc": 60.24,
    "hellaswag": 83.69,
    "truthfulqa": 41.81,
    "mmlu": 53.17,
    "gsm8k": 5.76,
    "winogrande": 73.24,
    "average": 52.99
  },
  "heegyu/LIMA2-7b-hf": {
    "arc": 53.24,
    "hellaswag": 80.6,
    "truthfulqa": 44.74,
    "mmlu": 43.22,
    "gsm8k": 3.87,
    "winogrande": 69.93,
    "average": 49.27
  },
  "heegyu/RedTulu-Uncensored-3B-0719": {
    "arc": 40.02,
    "hellaswag": 62.55,
    "truthfulqa": 37.59,
    "mmlu": 30.37,
    "gsm8k": 2.27,
    "winogrande": 62.35,
    "average": 39.19
  },
  "heegyu/WizardVicuna-3B-0719": {
    "arc": 40.7,
    "hellaswag": 65.45,
    "truthfulqa": 40.71,
    "mmlu": 25.44,
    "gsm8k": 0.76,
    "winogrande": 63.85,
    "average": 39.49
  },
  "heegyu/WizardVicuna-Uncensored-3B-0719": {
    "arc": 41.38,
    "hellaswag": 66.19,
    "truthfulqa": 39.35,
    "mmlu": 26.53,
    "gsm8k": 1.14,
    "winogrande": 63.77,
    "average": 39.73
  },
  "heegyu/WizardVicuna-open-llama-3b-v2": {
    "arc": 37.71,
    "hellaswag": 66.6,
    "truthfulqa": 36.8,
    "mmlu": 27.23,
    "gsm8k": 0.99,
    "winogrande": 63.3,
    "average": 38.77
  },
  "heegyu/WizardVicuna2-13b-hf": {
    "arc": 55.38,
    "hellaswag": 79.14,
    "truthfulqa": 42.43,
    "mmlu": 48.46,
    "gsm8k": 7.43,
    "winogrande": 73.48,
    "average": 51.05
  },
  "hiyouga/Baichuan2-7B-Base-LLaMAfied": {
    "arc": 49.57,
    "hellaswag": 73.45,
    "truthfulqa": 37.54,
    "mmlu": 54.86,
    "gsm8k": 7.81,
    "winogrande": 70.72,
    "average": 48.99
  },
  "hiyouga/Baichuan2-7B-Chat-LLaMAfied": {
    "arc": 52.47,
    "hellaswag": 74.04,
    "truthfulqa": 48.04,
    "mmlu": 53.88,
    "gsm8k": 10.92,
    "winogrande": 69.14,
    "average": 51.42
  },
  "hoskinson-center/proofGPT-v0.1": {
    "arc": 22.87,
    "hellaswag": 28.66,
    "truthfulqa": 51.64,
    "mmlu": 25.96,
    "gsm8k": 0.08,
    "winogrande": 50.43,
    "average": 29.94
  },
  "hoskinson-center/proofGPT-v0.1-6.7B": {
    "arc": 23.29,
    "hellaswag": 28.45,
    "truthfulqa": 50.87,
    "mmlu": 24.57,
    "gsm8k": 0,
    "winogrande": 51.14,
    "average": 29.72
  },
  "hpcai-tech/Colossal-LLaMA-2-7b-base": {
    "arc": 53.5,
    "hellaswag": 70.5,
    "truthfulqa": 50.19,
    "mmlu": 54.4,
    "gsm8k": 9.7,
    "winogrande": 70.01,
    "average": 51.38
  },
  "huashiyiqike/testmodel": {
    "arc": 19.71,
    "hellaswag": 26.68,
    "truthfulqa": 43.72,
    "mmlu": 25.28,
    "gsm8k": 0,
    "winogrande": 50.2,
    "average": 27.6
  },
  "huggingface/llama-13b": {
    "arc": 56.23,
    "hellaswag": 80.93,
    "truthfulqa": 39.48,
    "mmlu": 47.67,
    "gsm8k": 7.58,
    "winogrande": 76.24,
    "average": 51.36
  },
  "huggingface/llama-30b": {
    "arc": 61.26,
    "hellaswag": 84.73,
    "truthfulqa": 42.27,
    "mmlu": 58.47,
    "gsm8k": 14.86,
    "winogrande": 80.03,
    "average": 56.94
  },
  "huggingface/llama-65b": {
    "arc": 63.48,
    "hellaswag": 86.09,
    "truthfulqa": 43.43,
    "mmlu": 63.93,
    "gsm8k": 27.67,
    "winogrande": 82.56,
    "average": 61.19
  },
  "huggingface/llama-7b": {
    "arc": 51.02,
    "hellaswag": 77.82,
    "truthfulqa": 34.33,
    "mmlu": 35.71,
    "gsm8k": 3.56,
    "winogrande": 71.43,
    "average": 45.65
  },
  "huggingtweets/bladeecity-jerma985": {
    "arc": 22.87,
    "hellaswag": 30.53,
    "truthfulqa": 44.99,
    "mmlu": 26.56,
    "gsm8k": 0,
    "winogrande": 52.01,
    "average": 29.49
  },
  "huggingtweets/gladosystem": {
    "arc": 24.4,
    "hellaswag": 29.71,
    "truthfulqa": 41.78,
    "mmlu": 23.18,
    "gsm8k": 0,
    "winogrande": 50.67,
    "average": 28.29
  },
  "huggingtweets/jerma985": {
    "arc": 21.67,
    "hellaswag": 30.91,
    "truthfulqa": 44.01,
    "mmlu": 26.57,
    "gsm8k": 0,
    "winogrande": 50.67,
    "average": 28.97
  },
  "huggyllama/llama-13b": {
    "arc": 56.14,
    "hellaswag": 80.92,
    "truthfulqa": 39.48,
    "mmlu": 47.61,
    "gsm8k": 7.58,
    "winogrande": 76.24,
    "average": 51.33
  },
  "huggyllama/llama-30b": {
    "arc": 61.43,
    "hellaswag": 84.73,
    "truthfulqa": 42.27,
    "mmlu": 58.45,
    "gsm8k": 14.86,
    "winogrande": 80.03,
    "average": 56.96
  },
  "huggyllama/llama-65b": {
    "arc": 63.48,
    "hellaswag": 86.09,
    "truthfulqa": 43.43,
    "mmlu": 63.93,
    "gsm8k": 37.23,
    "winogrande": 82.56,
    "average": 62.79
  },
  "huggyllama/llama-7b": {
    "arc": 50.94,
    "hellaswag": 77.81,
    "truthfulqa": 34.33,
    "winogrande": 71.43,
    "gsm8k": 8.04,
    "mmlu": 35.69,
    "average": 46.37
  },
  "hyunseoki/ko-en-llama2-13b": {
    "arc": 58.19,
    "hellaswag": 81.89,
    "truthfulqa": 39.96,
    "mmlu": 52.02,
    "gsm8k": 0.76,
    "winogrande": 74.82,
    "average": 51.27
  },
  "hyunseoki/ko-ref-llama2-13b": {
    "arc": 48.38,
    "hellaswag": 73.56,
    "truthfulqa": 35.82,
    "mmlu": 34.83,
    "gsm8k": 0,
    "winogrande": 69.14,
    "average": 43.62
  },
  "hyunseoki/ko-ref-llama2-7b": {
    "arc": 42.66,
    "hellaswag": 66.58,
    "truthfulqa": 38.62,
    "mmlu": 30.41,
    "gsm8k": 0,
    "winogrande": 66.22,
    "average": 40.75
  },
  "iGenius-AI-Team/LLAMA-13B-test-finetuning": {
    "arc": 58.02,
    "hellaswag": 82.36,
    "truthfulqa": 44.14,
    "winogrande": 76.72,
    "gsm8k": 22.52,
    "mmlu": 54.27,
    "average": 56.34
  },
  "ibranze/araproje-llama2-7b-hf": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.8,
    "gsm8k": 7.13,
    "winogrande": 74.03,
    "average": 49.73
  },
  "ikala/bloom-zh-3b-chat": {
    "arc": 38.82,
    "hellaswag": 54.71,
    "truthfulqa": 41.25,
    "mmlu": 31.62,
    "gsm8k": 0.45,
    "winogrande": 58.64,
    "average": 37.58
  },
  "illuin/test-custom-llama": {
    "arc": 52.3,
    "hellaswag": 77.49,
    "truthfulqa": 33.81,
    "mmlu": 36.61,
    "gsm8k": 4.02,
    "winogrande": 72.06,
    "average": 46.05
  },
  "internlm/internlm-20b": {
    "arc": 60.49,
    "hellaswag": 82.13,
    "truthfulqa": 52.61,
    "mmlu": 61.85,
    "gsm8k": 23.5,
    "winogrande": 76.72,
    "average": 59.55
  },
  "internlm/internlm-20b-chat": {
    "arc": 55.38,
    "hellaswag": 78.58,
    "truthfulqa": 43.22,
    "mmlu": 58.53,
    "gsm8k": 18.73,
    "winogrande": 78.77,
    "average": 55.54
  },
  "itsliupeng/llama2_7b_code": {
    "arc": 52.13,
    "hellaswag": 75.71,
    "truthfulqa": 38.76,
    "mmlu": 48.05,
    "gsm8k": 8.11,
    "winogrande": 71.51,
    "average": 49.04
  },
  "itsliupeng/llama2_7b_mmlu": {
    "arc": 56.14,
    "hellaswag": 79.13,
    "truthfulqa": 40.95,
    "mmlu": 60.04,
    "gsm8k": 7.88,
    "winogrande": 74.43,
    "average": 53.09
  },
  "itsliupeng/llama2_7b_zh": {
    "arc": 52.05,
    "hellaswag": 74.88,
    "truthfulqa": 42.86,
    "winogrande": 71.74,
    "gsm8k": 6.44,
    "mmlu": 60.69,
    "average": 51.44
  },
  "jarradh/llama2_70b_chat_uncensored": {
    "arc": 68.43,
    "hellaswag": 86.77,
    "truthfulqa": 52.5,
    "mmlu": 68.76,
    "gsm8k": 30.25,
    "winogrande": 82.56,
    "average": 64.88
  },
  "jaspercatapang/Echidna-30B": {
    "arc": 28.5,
    "hellaswag": 25.5,
    "truthfulqa": 48.14,
    "mmlu": 24.89
  },
  "jb723/cross_lingual_epoch2": {
    "arc": 39.25,
    "hellaswag": 47.92,
    "truthfulqa": 47.9,
    "winogrande": 62.12,
    "gsm8k": 0,
    "mmlu": 36.66,
    "average": 38.98
  },
  "jb723/llama2-ko-7B-model": {
    "arc": 56.31,
    "hellaswag": 79.51,
    "truthfulqa": 40.98,
    "mmlu": 45.71,
    "gsm8k": 2.58,
    "winogrande": 72.06,
    "average": 49.53
  },
  "jebcarter/psyonic-cetacean-20B": {
    "arc": 63.57,
    "hellaswag": 86.2,
    "truthfulqa": 57.55,
    "winogrande": 78.14,
    "gsm8k": 14.71,
    "mmlu": 59.66,
    "average": 59.97
  },
  "jerryjalapeno/nart-100k-7b": {
    "arc": 54.1,
    "hellaswag": 78.47,
    "truthfulqa": 36.74,
    "mmlu": 34.98,
    "gsm8k": 3.56,
    "winogrande": 70.48,
    "average": 46.39
  },
  "jjaaaww/posi_13b": {
    "arc": 59.64,
    "hellaswag": 82.52,
    "truthfulqa": 42.14,
    "mmlu": 56.56,
    "gsm8k": 1.59,
    "winogrande": 76.24,
    "average": 53.12
  },
  "jlevin/guanaco-13b-llama-2": {
    "arc": 55.38,
    "hellaswag": 81.87,
    "truthfulqa": 46.88,
    "mmlu": 47.19,
    "gsm8k": 5.76,
    "winogrande": 74.35,
    "average": 51.9
  },
  "jlevin/guanaco-unchained-llama-2-7b": {
    "arc": 47.35,
    "hellaswag": 72.16,
    "truthfulqa": 41.49,
    "mmlu": 41.76,
    "gsm8k": 3.41,
    "winogrande": 64.48,
    "average": 45.11
  },
  "joehuangx/spatial-vicuna-7b-v1.5-LoRA": {
    "arc": 50.77,
    "hellaswag": 74.63,
    "truthfulqa": 49.36,
    "mmlu": 48.13,
    "gsm8k": 6.9,
    "winogrande": 72.38,
    "average": 50.36
  },
  "jondurbin/airoboros-13b": {
    "arc": 58.28,
    "hellaswag": 81.05,
    "truthfulqa": 51.57,
    "mmlu": 50.03,
    "gsm8k": 6.97,
    "winogrande": 76.24,
    "average": 54.02
  },
  "jondurbin/airoboros-13b-gpt4": {
    "arc": 59.39,
    "hellaswag": 83.29,
    "truthfulqa": 47.65,
    "mmlu": 47.89,
    "gsm8k": 7.88,
    "winogrande": 75.77,
    "average": 53.65
  },
  "jondurbin/airoboros-13b-gpt4-1.1": {
    "arc": 59.04,
    "hellaswag": 83.05,
    "truthfulqa": 46.62,
    "mmlu": 49.41,
    "gsm8k": 8.19,
    "winogrande": 75.77,
    "average": 53.68
  },
  "jondurbin/airoboros-13b-gpt4-1.2": {
    "arc": 58.36,
    "hellaswag": 81.61,
    "truthfulqa": 47.54,
    "mmlu": 48.84,
    "gsm8k": 3.87,
    "winogrande": 73.64,
    "average": 52.31
  },
  "jondurbin/airoboros-13b-gpt4-1.3": {
    "arc": 58.53,
    "hellaswag": 81.6,
    "truthfulqa": 45.29,
    "mmlu": 46.96,
    "gsm8k": 2.35,
    "winogrande": 75.85,
    "average": 51.76
  },
  "jondurbin/airoboros-13b-gpt4-1.4": {
    "arc": 59.64,
    "hellaswag": 83.22,
    "truthfulqa": 48.82,
    "mmlu": 47.56,
    "gsm8k": 7.73,
    "winogrande": 76.24,
    "average": 53.87
  },
  "jondurbin/airoboros-13b-gpt4-1.4-fp16": {
    "arc": 59.64,
    "hellaswag": 83.22,
    "truthfulqa": 48.82,
    "mmlu": 47.56,
    "gsm8k": 7.73,
    "winogrande": 76.24,
    "average": 53.87
  },
  "jondurbin/airoboros-33b-2.1": {
    "arc": 63.65,
    "hellaswag": 84.97,
    "truthfulqa": 52.17,
    "mmlu": 57.37,
    "gsm8k": 6.6,
    "winogrande": 78.22,
    "average": 57.16
  },
  "jondurbin/airoboros-33b-gpt4": {
    "arc": 63.74,
    "hellaswag": 84.87,
    "truthfulqa": 47.06,
    "mmlu": 58.54,
    "gsm8k": 12.66,
    "winogrande": 77.03,
    "average": 57.32
  },
  "jondurbin/airoboros-33b-gpt4-1.2": {
    "arc": 64.42,
    "hellaswag": 84.93,
    "truthfulqa": 49.18,
    "mmlu": 60.35,
    "gsm8k": 9.78,
    "winogrande": 77.51,
    "average": 57.7
  },
  "jondurbin/airoboros-33b-gpt4-1.3": {
    "arc": 63.82,
    "hellaswag": 85.09,
    "truthfulqa": 45.33,
    "mmlu": 58.94,
    "gsm8k": 13.04,
    "winogrande": 78.69,
    "average": 57.49
  },
  "jondurbin/airoboros-33b-gpt4-1.4": {
    "arc": 64.42,
    "hellaswag": 85.13,
    "truthfulqa": 50.47,
    "mmlu": 59.53,
    "gsm8k": 11.75,
    "winogrande": 77.9,
    "average": 58.2
  },
  "jondurbin/airoboros-33b-gpt4-2.0": {
    "arc": 63.82,
    "hellaswag": 85.65,
    "truthfulqa": 45.57,
    "mmlu": 58.44,
    "gsm8k": 10.69,
    "winogrande": 77.9,
    "average": 57.01
  },
  "jondurbin/airoboros-33b-gpt4-m2.0": {
    "arc": 63.4,
    "hellaswag": 85.19,
    "truthfulqa": 48.15,
    "mmlu": 57.46,
    "gsm8k": 9.63,
    "winogrande": 78.37,
    "average": 57.03
  },
  "jondurbin/airoboros-65b-gpt4-1.2": {
    "arc": 65.87,
    "hellaswag": 86.08,
    "truthfulqa": 52.72,
    "mmlu": 63.37,
    "gsm8k": 26.54,
    "winogrande": 79.56,
    "average": 62.36
  },
  "jondurbin/airoboros-65b-gpt4-1.3": {
    "arc": 66.13,
    "hellaswag": 85.99,
    "truthfulqa": 51.32,
    "mmlu": 63.89,
    "gsm8k": 13.65,
    "winogrande": 79.95,
    "average": 60.15
  },
  "jondurbin/airoboros-65b-gpt4-1.4": {
    "arc": 65.78,
    "hellaswag": 85.83,
    "truthfulqa": 52.45,
    "mmlu": 62.27,
    "gsm8k": 18.04,
    "winogrande": 79.64,
    "average": 60.67
  },
  "jondurbin/airoboros-65b-gpt4-1.4-peft": {
    "arc": 65.78,
    "hellaswag": 85.83,
    "truthfulqa": 52.45,
    "mmlu": 62.27,
    "gsm8k": 18.04,
    "winogrande": 79.64,
    "average": 60.67
  },
  "jondurbin/airoboros-65b-gpt4-2.0": {
    "arc": 66.64,
    "hellaswag": 86.66,
    "truthfulqa": 49.11,
    "mmlu": 63.18,
    "gsm8k": 20.55,
    "winogrande": 80.27,
    "average": 61.07
  },
  "jondurbin/airoboros-65b-gpt4-m2.0": {
    "arc": 65.02,
    "hellaswag": 86.35,
    "truthfulqa": 46.66,
    "mmlu": 64.37,
    "gsm8k": 22.14,
    "winogrande": 80.19,
    "average": 60.79
  },
  "jondurbin/airoboros-7b": {
    "arc": 53.07,
    "hellaswag": 77.65,
    "truthfulqa": 43.39,
    "mmlu": 37.23,
    "gsm8k": 2.12,
    "winogrande": 70.96,
    "average": 47.4
  },
  "jondurbin/airoboros-7b-gpt4": {
    "arc": 53.07,
    "hellaswag": 78.69,
    "truthfulqa": 40.72,
    "mmlu": 38.9,
    "gsm8k": 1.74,
    "winogrande": 73.09,
    "average": 47.7
  },
  "jondurbin/airoboros-7b-gpt4-1.1": {
    "arc": 54.61,
    "hellaswag": 80.15,
    "truthfulqa": 41.22,
    "mmlu": 39.25,
    "gsm8k": 3.11,
    "winogrande": 73.09,
    "average": 48.57
  },
  "jondurbin/airoboros-7b-gpt4-1.2": {
    "arc": 52.13,
    "hellaswag": 78.14,
    "truthfulqa": 41.79,
    "mmlu": 38.64,
    "gsm8k": 2.12,
    "winogrande": 71.67,
    "average": 47.42
  },
  "jondurbin/airoboros-7b-gpt4-1.3": {
    "arc": 52.47,
    "hellaswag": 77.98,
    "truthfulqa": 35.73,
    "mmlu": 41.97,
    "gsm8k": 0.99,
    "winogrande": 72.3,
    "average": 46.91
  },
  "jondurbin/airoboros-7b-gpt4-1.4": {
    "arc": 53.92,
    "hellaswag": 80.33,
    "truthfulqa": 41.05,
    "mmlu": 38.61,
    "gsm8k": 3.71,
    "winogrande": 72.77,
    "average": 48.4
  },
  "jondurbin/airoboros-7b-gpt4-1.4.1-qlora": {
    "arc": 52.73,
    "hellaswag": 77.89,
    "truthfulqa": 36.07,
    "mmlu": 38.77,
    "gsm8k": 2.27,
    "winogrande": 70.32,
    "average": 46.34
  },
  "jondurbin/airoboros-c34b-2.1": {
    "arc": 54.69,
    "hellaswag": 76.45,
    "truthfulqa": 46.15,
    "mmlu": 55.08,
    "gsm8k": 8.34,
    "winogrande": 68.43,
    "average": 51.52
  },
  "jondurbin/airoboros-c34b-2.2.1": {
    "arc": 54.69,
    "hellaswag": 76.84,
    "truthfulqa": 51.36,
    "mmlu": 55.43,
    "gsm8k": 20.02,
    "winogrande": 72.53,
    "average": 55.15
  },
  "jondurbin/airoboros-gpt-3.5-turbo-100k-7b": {
    "arc": 53.07,
    "hellaswag": 76.16,
    "truthfulqa": 45.07,
    "mmlu": 33.63,
    "gsm8k": 3.56,
    "winogrande": 70.8,
    "average": 47.05
  },
  "jondurbin/airoboros-l2-13b-2.1": {
    "arc": 55.12,
    "hellaswag": 80.24,
    "truthfulqa": 44.62,
    "mmlu": 50.89,
    "gsm8k": 3.56,
    "winogrande": 75.06,
    "average": 51.58
  },
  "jondurbin/airoboros-l2-13b-2.2.1": {
    "arc": 60.92,
    "hellaswag": 83.77,
    "truthfulqa": 49.42,
    "mmlu": 56.47,
    "gsm8k": 11.6,
    "winogrande": 76.01,
    "average": 56.37
  },
  "jondurbin/airoboros-l2-13b-3.0": {
    "arc": 59.81,
    "hellaswag": 83.71,
    "truthfulqa": 47.79,
    "mmlu": 54.86,
    "gsm8k": 8.95,
    "winogrande": 76.16,
    "average": 55.21
  },
  "jondurbin/airoboros-l2-13b-gpt4-1.4.1": {
    "arc": 59.13,
    "hellaswag": 82.78,
    "truthfulqa": 40.27,
    "mmlu": 55.62,
    "gsm8k": 6.97,
    "winogrande": 73.32,
    "average": 53.02
  },
  "jondurbin/airoboros-l2-13b-gpt4-2.0": {
    "arc": 59.04,
    "hellaswag": 82.82,
    "truthfulqa": 36.47,
    "mmlu": 54.71,
    "gsm8k": 7.73,
    "winogrande": 74.19,
    "average": 52.49
  },
  "jondurbin/airoboros-l2-13b-gpt4-m2.0": {
    "arc": 59.22,
    "hellaswag": 81.02,
    "truthfulqa": 39.7,
    "mmlu": 53.73,
    "gsm8k": 8.64,
    "winogrande": 73.64,
    "average": 52.66
  },
  "jondurbin/airoboros-l2-70b-2.1": {
    "arc": 70.65,
    "hellaswag": 86.81,
    "truthfulqa": 56,
    "mmlu": 69.17,
    "gsm8k": 21,
    "winogrande": 81.45,
    "average": 64.18
  },
  "jondurbin/airoboros-l2-70b-2.2.1": {
    "arc": 69.71,
    "hellaswag": 87.95,
    "truthfulqa": 59.49,
    "mmlu": 69.79,
    "gsm8k": 44.88,
    "winogrande": 82.95,
    "average": 69.13
  },
  "jondurbin/airoboros-l2-70b-gpt4-1.4.1": {
    "arc": 70.39,
    "hellaswag": 87.82,
    "truthfulqa": 55.2,
    "mmlu": 70.31,
    "gsm8k": 22.52,
    "winogrande": 83.58,
    "average": 64.97
  },
  "jondurbin/airoboros-l2-70b-gpt4-2.0": {
    "arc": 68.52,
    "hellaswag": 87.89,
    "truthfulqa": 49.79,
    "mmlu": 70.41,
    "gsm8k": 24.72,
    "winogrande": 83.5,
    "average": 64.14
  },
  "jondurbin/airoboros-l2-70b-gpt4-m2.0": {
    "arc": 70.05,
    "hellaswag": 87.79,
    "truthfulqa": 49.75,
    "mmlu": 70.46,
    "gsm8k": 25.4,
    "winogrande": 83.58,
    "average": 64.51
  },
  "jondurbin/airoboros-l2-7b-2.1": {
    "arc": 54.44,
    "hellaswag": 78.68,
    "truthfulqa": 43.95,
    "mmlu": 44.45,
    "gsm8k": 2.2,
    "winogrande": 74.11,
    "average": 49.64
  },
  "jondurbin/airoboros-l2-7b-2.2.1": {
    "arc": 55.03,
    "hellaswag": 80.06,
    "truthfulqa": 44.65,
    "mmlu": 47.64,
    "gsm8k": 6.14,
    "winogrande": 73.8,
    "average": 51.22
  },
  "jondurbin/airoboros-l2-7b-gpt4-1.4.1": {
    "arc": 55.12,
    "hellaswag": 79.6,
    "truthfulqa": 40.29,
    "mmlu": 45.17,
    "gsm8k": 2.81,
    "winogrande": 74.27,
    "average": 49.54
  },
  "jondurbin/airoboros-l2-7b-gpt4-2.0": {
    "arc": 52.9,
    "hellaswag": 78.53,
    "truthfulqa": 39.45,
    "mmlu": 45.09,
    "gsm8k": 3.18,
    "winogrande": 71.11,
    "average": 48.38
  },
  "jondurbin/airoboros-l2-7b-gpt4-m2.0": {
    "arc": 50.51,
    "hellaswag": 76.87,
    "truthfulqa": 41.34,
    "mmlu": 45.35,
    "gsm8k": 4.09,
    "winogrande": 69.53,
    "average": 47.95
  },
  "jondurbin/airoboros-m-7b-3.1.2": {
    "arc": 61.86,
    "hellaswag": 83.51,
    "truthfulqa": 53.75,
    "winogrande": 77.58,
    "gsm8k": 13.87,
    "mmlu": 61.91,
    "average": 58.75
  },
  "jondurbin/airocoder-34b-2.1": {
    "arc": 54.18,
    "hellaswag": 73.84,
    "truthfulqa": 40.7,
    "mmlu": 50.67,
    "gsm8k": 8.34,
    "winogrande": 69.93,
    "average": 49.61
  },
  "jondurbin/spicyboros-7b-2.2": {
    "arc": 56.57,
    "hellaswag": 80.09,
    "truthfulqa": 47.22,
    "mmlu": 48.47,
    "gsm8k": 4.85,
    "winogrande": 74.51,
    "average": 51.95
  },
  "jordiclive/Llama-2-70b-oasst-1-200": {
    "arc": 67.66,
    "hellaswag": 87.24,
    "truthfulqa": 51.28,
    "mmlu": 69.95,
    "gsm8k": 32.75,
    "winogrande": 84.14,
    "average": 65.5
  },
  "jordiclive/gpt4all-alpaca-oa-codealpaca-lora-13b": {
    "arc": 56.14,
    "hellaswag": 80.93,
    "truthfulqa": 39.48,
    "mmlu": 47.66,
    "gsm8k": 7.58,
    "winogrande": 76.16,
    "average": 51.33
  },
  "jphme/Llama-2-13b-chat-german": {
    "arc": 57.85,
    "hellaswag": 81.66,
    "truthfulqa": 46.32,
    "mmlu": 54.45,
    "gsm8k": 13.65,
    "winogrande": 76.48,
    "average": 55.07
  },
  "jphme/em_german_leo_mistral": {
    "arc": 52.82,
    "hellaswag": 78.03,
    "truthfulqa": 50.19,
    "mmlu": 50.03,
    "gsm8k": 5.61,
    "winogrande": 73.48,
    "average": 51.69
  },
  "jphme/orca_mini_v2_ger_7b": {
    "arc": 49.83,
    "hellaswag": 75.5,
    "truthfulqa": 45.74,
    "mmlu": 39.1,
    "gsm8k": 4.17,
    "winogrande": 71.59,
    "average": 47.65
  },
  "jslin09/bloom-560m-finetuned-fraud": {
    "gsm8k": 0,
    "winogrande": 48.38
  },
  "julianweng/Llama-2-7b-chat-orcah": {
    "arc": 45.39,
    "hellaswag": 76.62,
    "truthfulqa": 45.23,
    "mmlu": 48.11,
    "gsm8k": 3.79,
    "winogrande": 70.96,
    "average": 48.35
  },
  "junelee/wizard-vicuna-13b": {
    "arc": 54.69,
    "hellaswag": 79.18,
    "truthfulqa": 49.62,
    "mmlu": 48.88,
    "gsm8k": 9.17,
    "winogrande": 74.82,
    "average": 52.73
  },
  "jxhong/CAlign-alpaca-7b": {
    "arc": 50.94,
    "hellaswag": 74.55,
    "truthfulqa": 46.89,
    "mmlu": 38.56,
    "gsm8k": 1.36,
    "winogrande": 72.06,
    "average": 47.39
  },
  "jzjiao/opt-1.3b-rlhf": {
    "arc": 28.92,
    "hellaswag": 52.77,
    "truthfulqa": 37.44,
    "mmlu": 25.39,
    "gsm8k": 0.45,
    "winogrande": 58.96,
    "average": 33.99
  },
  "kaist-ai/prometheus-13b-v1.0": {
    "arc": 53.24,
    "hellaswag": 80.75,
    "truthfulqa": 45.66,
    "winogrande": 73.72,
    "gsm8k": 31.69,
    "mmlu": 51.49,
    "average": 56.09
  },
  "kajdun/iubaris-13b-v3": {
    "arc": 59.13,
    "hellaswag": 81.78,
    "truthfulqa": 48.61,
    "mmlu": 54.42
  },
  "kajdun/viwaai-30b_v4": {
    "arc": 63.48,
    "hellaswag": 84.19,
    "truthfulqa": 53.25,
    "mmlu": 57.47
  },
  "kashif/stack-llama-2": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.8,
    "gsm8k": 10.01,
    "winogrande": 74.03,
    "average": 50.21
  },
  "kevinpro/Vicuna-13B-CoT": {
    "arc": 52.73,
    "hellaswag": 80.13,
    "truthfulqa": 52.08,
    "mmlu": 51.94,
    "gsm8k": 8.64,
    "winogrande": 74.19,
    "average": 53.29
  },
  "keyfan/vicuna-chinese-replication-v1.1": {
    "arc": 42.83,
    "hellaswag": 71.47,
    "truthfulqa": 47.24,
    "mmlu": 47.47,
    "gsm8k": 9.48,
    "winogrande": 67.4,
    "average": 47.65
  },
  "kfkas/Llama-2-ko-7b-Chat": {
    "arc": 40.44,
    "hellaswag": 67.12,
    "truthfulqa": 35.45,
    "mmlu": 30.19,
    "gsm8k": 1.29,
    "winogrande": 66.85,
    "average": 40.22
  },
  "khoantap/wizard-limarp": {
    "arc": 58.62,
    "hellaswag": 81.87,
    "truthfulqa": 48.28,
    "mmlu": 54.96
  },
  "kingbri/airolima-chronos-grad-l2-13B": {
    "arc": 59.56,
    "hellaswag": 83.5,
    "truthfulqa": 44.67,
    "mmlu": 55.78,
    "gsm8k": 13.65,
    "winogrande": 75.85,
    "average": 55.5
  },
  "kingbri/chronolima-airo-grad-l2-13B": {
    "arc": 59.56,
    "hellaswag": 83.47,
    "truthfulqa": 44.58,
    "mmlu": 55.8,
    "gsm8k": 13.95,
    "winogrande": 75.61,
    "average": 55.5
  },
  "kittn/mistral-7B-v0.1-hf": {
    "gsm8k": 18.12,
    "winogrande": 78.37
  },
  "klosax/open_llama_13b_600bt_preview": {
    "arc": 44.28,
    "hellaswag": 72.43,
    "truthfulqa": 34.66,
    "mmlu": 31.47,
    "gsm8k": 1.97,
    "winogrande": 68.43,
    "average": 42.21
  },
  "klosax/open_llama_3b_350bt_preview": {
    "arc": 36.52,
    "hellaswag": 60.86,
    "truthfulqa": 35.03,
    "mmlu": 26.78
  },
  "klosax/open_llama_7b_400bt_preview": {
    "arc": 39.51,
    "hellaswag": 65.88,
    "truthfulqa": 36.04,
    "mmlu": 27.64
  },
  "klosax/openllama-3b-350bt": {
    "arc": 36.52,
    "hellaswag": 60.86,
    "truthfulqa": 35.03,
    "mmlu": 26.78
  },
  "klosax/pythia-160m-deduped-step92k-193bt": {
    "arc": 24.23,
    "hellaswag": 32.33,
    "truthfulqa": 43.49,
    "mmlu": 24.54,
    "gsm8k": 0.38,
    "winogrande": 50.83,
    "average": 29.3
  },
  "klosax/pythia-70m-deduped-step44k-92bt": {
    "arc": 22.1,
    "hellaswag": 28.21,
    "truthfulqa": 46.12,
    "mmlu": 26.03,
    "gsm8k": 0,
    "winogrande": 51.54,
    "average": 29
  },
  "klyang/MentaLLaMA-chat-7B": {
    "arc": 52.82,
    "hellaswag": 76.1,
    "truthfulqa": 44.02,
    "winogrande": 70.4,
    "gsm8k": 16.15,
    "mmlu": 47.51,
    "average": 51.17
  },
  "krevas/LDCC-Instruct-Llama-2-ko-13B": {
    "arc": 56.74,
    "hellaswag": 81.57,
    "truthfulqa": 38,
    "mmlu": 51.2
  },
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v2": {
    "arc": 56.4,
    "hellaswag": 81.82,
    "truthfulqa": 39.78,
    "mmlu": 45.57
  },
  "kyujinpy/PlatYi-34B-LoRA": {
    "arc": 67.15,
    "hellaswag": 85.37,
    "truthfulqa": 53.32,
    "winogrande": 83.66,
    "gsm8k": 40.64,
    "mmlu": 78.46,
    "average": 68.1
  },
  "kyujinpy/PlatYi-34B-Q": {
    "arc": 66.89,
    "hellaswag": 85.14,
    "truthfulqa": 53.03,
    "winogrande": 82.48,
    "gsm8k": 53.98,
    "mmlu": 77.66,
    "average": 69.86
  },
  "l3utterfly/llama2-3b-distilled-layla-v1": {
    "arc": 30.46,
    "hellaswag": 46.05,
    "truthfulqa": 42.14,
    "winogrande": 57.38,
    "gsm8k": 0.23,
    "mmlu": 23.91,
    "average": 33.36
  },
  "l3utterfly/llama2-7b-layla": {
    "arc": 54.18,
    "hellaswag": 79.34,
    "truthfulqa": 46.5,
    "mmlu": 49.7,
    "gsm8k": 8.49,
    "winogrande": 74.11,
    "average": 52.05
  },
  "l3utterfly/mistral-7b-v0.1-layla-v1": {
    "arc": 60.15,
    "hellaswag": 83.25,
    "truthfulqa": 48.9,
    "winogrande": 75.93,
    "gsm8k": 16.83,
    "mmlu": 60.31,
    "average": 57.56
  },
  "l3utterfly/mistral-7b-v0.1-layla-v2": {
    "arc": 27.05,
    "hellaswag": 25.87,
    "truthfulqa": 49.04,
    "winogrande": 48.93,
    "gsm8k": 0,
    "mmlu": 25.38,
    "average": 29.38
  },
  "l3utterfly/open-llama-3b-v2-layla": {
    "arc": 38.23,
    "hellaswag": 66.43,
    "truthfulqa": 44.4,
    "mmlu": 28.56,
    "gsm8k": 1.06,
    "winogrande": 62.83,
    "average": 40.25
  },
  "layoric/llama-2-13b-code-alpaca": {
    "arc": 60.84,
    "hellaswag": 82.14,
    "truthfulqa": 38.27,
    "mmlu": 55.93,
    "gsm8k": 11.9,
    "winogrande": 76.4,
    "average": 54.25
  },
  "lgaalves/gpt-2-xl_camel-ai-physics": {
    "arc": 29.52,
    "hellaswag": 50.62,
    "truthfulqa": 39.12,
    "mmlu": 26.79,
    "gsm8k": 0.15,
    "winogrande": 57.54,
    "average": 33.96
  },
  "lgaalves/gpt2-dolly": {
    "arc": 22.7,
    "hellaswag": 30.15,
    "truthfulqa": 44.97,
    "mmlu": 25.81,
    "gsm8k": 0.15,
    "winogrande": 51.46,
    "average": 29.21
  },
  "lgaalves/gpt2-xl_lima": {
    "arc": 31.14,
    "hellaswag": 51.28,
    "truthfulqa": 38.74,
    "winogrande": 57.22,
    "gsm8k": 0.91,
    "mmlu": 25.43,
    "average": 34.12
  },
  "lgaalves/gpt2_camel_physics-platypus": {
    "arc": 23.04,
    "hellaswag": 31.32,
    "truthfulqa": 39.56,
    "mmlu": 26.91,
    "gsm8k": 0,
    "winogrande": 49.64,
    "average": 28.41
  },
  "lgaalves/gpt2_guanaco-dolly-platypus": {
    "arc": 23.55,
    "hellaswag": 31.03,
    "truthfulqa": 40.02,
    "mmlu": 26.4,
    "gsm8k": 0,
    "winogrande": 50.12,
    "average": 28.52
  },
  "lgaalves/gpt2_open-platypus": {
    "arc": 22.18,
    "hellaswag": 31.29,
    "truthfulqa": 40.35,
    "mmlu": 26.19,
    "gsm8k": 0.15,
    "winogrande": 51.3,
    "average": 28.58
  },
  "lgaalves/gpt2_platypus-camel_physics": {
    "arc": 23.04,
    "hellaswag": 31.32,
    "truthfulqa": 39.56,
    "mmlu": 26.91,
    "gsm8k": 0,
    "winogrande": 49.64,
    "average": 28.41
  },
  "lgaalves/gpt2_platypus-dolly-guanaco": {
    "arc": 23.21,
    "hellaswag": 31.04,
    "truthfulqa": 40.31,
    "mmlu": 26.16,
    "gsm8k": 0,
    "winogrande": 50.36,
    "average": 28.51
  },
  "lgaalves/llama-2-13b-chat-platypus": {
    "arc": 53.84,
    "hellaswag": 80.67,
    "truthfulqa": 46.23,
    "mmlu": 54.44,
    "gsm8k": 12.36,
    "winogrande": 76.01,
    "average": 53.92
  },
  "lgaalves/llama-2-13b-hf-platypus": {
    "arc": 58.87,
    "hellaswag": 82.14,
    "truthfulqa": 42.84,
    "mmlu": 54.98,
    "gsm8k": 9.4,
    "winogrande": 77.11,
    "average": 54.22
  },
  "lgaalves/llama-2-7b-hf_open-platypus": {
    "arc": 51.45,
    "hellaswag": 78.63,
    "truthfulqa": 43.71,
    "mmlu": 43.6,
    "gsm8k": 6.6,
    "winogrande": 74.43,
    "average": 49.74
  },
  "lgaalves/mistral-7b-platypus1k": {
    "arc": 61.6,
    "hellaswag": 82.93,
    "truthfulqa": 46.96,
    "mmlu": 63.16,
    "gsm8k": 16.38,
    "winogrande": 78.14,
    "average": 58.2
  },
  "lgaalves/mistral-7b_open_platypus": {
    "arc": 55.8,
    "hellaswag": 82.13,
    "truthfulqa": 48.87,
    "winogrande": 78.61,
    "gsm8k": 12.59,
    "mmlu": 59.76,
    "average": 56.29
  },
  "lgaalves/tinyllama-1.1b-chat-v0.3_platypus": {
    "arc": 30.29,
    "hellaswag": 55.12,
    "truthfulqa": 39.15,
    "mmlu": 26.13,
    "gsm8k": 0.53,
    "winogrande": 55.8,
    "average": 34.5
  },
  "lilloukas/GPlatty-30B": {
    "arc": 65.78,
    "hellaswag": 84.79,
    "truthfulqa": 52.45,
    "mmlu": 63.49,
    "gsm8k": 13.87,
    "winogrande": 80.98,
    "average": 60.23
  },
  "lilloukas/Platypus-30B": {
    "arc": 64.59,
    "hellaswag": 84.24,
    "truthfulqa": 45.35,
    "mmlu": 64.19,
    "gsm8k": 14.4,
    "winogrande": 81.37,
    "average": 59.02
  },
  "liuxiang886/llama2-70B-qlora-gpt4": {
    "arc": 70.31,
    "hellaswag": 86.39,
    "truthfulqa": 54.02,
    "mmlu": 69.29,
    "gsm8k": 28.89,
    "winogrande": 82.87,
    "average": 65.3
  },
  "lizhuang144/llama_mirror_13b_v1.0": {
    "arc": 57.59,
    "hellaswag": 80.53,
    "truthfulqa": 44.54,
    "mmlu": 48,
    "gsm8k": 7.43,
    "winogrande": 76.64,
    "average": 52.46
  },
  "lizhuang144/starcoder_mirror": {
    "arc": 31.31,
    "hellaswag": 45.82,
    "truthfulqa": 43.38,
    "mmlu": 29.29,
    "gsm8k": 5.53,
    "winogrande": 57.22,
    "average": 35.42
  },
  "lizpreciatior/lzlv_70b_fp16_hf": {
    "arc": 70.14,
    "hellaswag": 87.54,
    "truthfulqa": 60.49,
    "mmlu": 70.23,
    "gsm8k": 30.93,
    "winogrande": 83.43,
    "average": 67.13
  },
  "llama-anon/instruct-13b": {
    "arc": 56.14,
    "hellaswag": 80.27,
    "truthfulqa": 36.97,
    "mmlu": 47.89,
    "gsm8k": 2.27,
    "winogrande": 73.56,
    "average": 49.52
  },
  "llm-agents/tora-13b-v1.0": {
    "arc": 58.96,
    "hellaswag": 82.31,
    "truthfulqa": 40.25,
    "mmlu": 54.73,
    "gsm8k": 9.86,
    "winogrande": 75.61,
    "average": 53.62
  },
  "llm-agents/tora-70b-v1.0": {
    "arc": 67.75,
    "hellaswag": 85.83,
    "truthfulqa": 51.79,
    "mmlu": 69.22,
    "gsm8k": 23.81,
    "winogrande": 81.93,
    "average": 63.39
  },
  "llm-agents/tora-7b-v1.0": {
    "arc": 52.47,
    "hellaswag": 78.68,
    "truthfulqa": 37.9,
    "mmlu": 45.9,
    "gsm8k": 2.5,
    "winogrande": 73.56,
    "average": 48.5
  },
  "llm-agents/tora-code-13b-v1.0": {
    "arc": 44.45,
    "hellaswag": 69.29,
    "truthfulqa": 34.98,
    "mmlu": 36.67,
    "gsm8k": 8.19,
    "winogrande": 62.59,
    "average": 42.69
  },
  "llm-agents/tora-code-34b-v1.0": {
    "arc": 50.43,
    "hellaswag": 75.54,
    "truthfulqa": 39.66,
    "mmlu": 46.78,
    "gsm8k": 13.12,
    "winogrande": 68.19,
    "average": 48.95
  },
  "llm-agents/tora-code-7b-v1.0": {
    "arc": 40.7,
    "hellaswag": 65.86,
    "truthfulqa": 34.84,
    "mmlu": 33.34,
    "gsm8k": 4.93,
    "winogrande": 61.56,
    "average": 40.21
  },
  "llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0": {
    "arc": 26.88,
    "hellaswag": 44.78,
    "truthfulqa": 45.19,
    "winogrande": 50.67,
    "gsm8k": 0,
    "mmlu": 23.12,
    "average": 31.77
  },
  "llm-jp/llm-jp-13b-instruct-full-jaster-v1.0": {
    "arc": 27.22,
    "hellaswag": 44.7,
    "truthfulqa": 44.69,
    "winogrande": 50.04,
    "gsm8k": 0,
    "mmlu": 23.12,
    "average": 31.63
  },
  "lloorree/jfdslijsijdgis": {
    "arc": 69.62,
    "hellaswag": 86.95,
    "truthfulqa": 58.2,
    "mmlu": 69.17
  },
  "lloorree/kssht-castor-70b": {
    "arc": 69.54,
    "hellaswag": 87.53,
    "truthfulqa": 56.31,
    "mmlu": 70.38
  },
  "lloorree/kssht-dahj-70b": {
    "arc": 70.82,
    "hellaswag": 87.3,
    "truthfulqa": 58.92,
    "mmlu": 70.43
  },
  "lloorree/kssht-euripedes-70b": {
    "arc": 69.8,
    "hellaswag": 87.59,
    "truthfulqa": 55.51,
    "mmlu": 70.43
  },
  "lmsys/longchat-13b-16k": {
    "arc": 53.58,
    "hellaswag": 77.67,
    "truthfulqa": 47.07,
    "mmlu": 45.24,
    "gsm8k": 4.17,
    "winogrande": 70.09,
    "average": 49.64
  },
  "lmsys/longchat-7b-v1.5-32k": {
    "arc": 51.71,
    "hellaswag": 74.97,
    "truthfulqa": 44.42,
    "mmlu": 43.16,
    "gsm8k": 4.78,
    "winogrande": 68.67,
    "average": 47.95
  },
  "lmsys/vicuna-13b-delta-v1.1": {
    "arc": 52.73,
    "hellaswag": 80.14,
    "truthfulqa": 52.08,
    "mmlu": 51.9,
    "gsm8k": 8.64,
    "winogrande": 74.19,
    "average": 53.28
  },
  "lmsys/vicuna-13b-v1.1": {
    "arc": 52.73,
    "hellaswag": 80.14,
    "truthfulqa": 52.08,
    "mmlu": 51.9,
    "gsm8k": 8.64,
    "winogrande": 74.19,
    "average": 53.28
  },
  "lmsys/vicuna-13b-v1.3": {
    "arc": 54.61,
    "hellaswag": 80.41,
    "truthfulqa": 52.14,
    "mmlu": 52.88,
    "gsm8k": 10.77,
    "winogrande": 74.82,
    "average": 54.27
  },
  "lmsys/vicuna-13b-v1.5": {
    "arc": 57.08,
    "hellaswag": 81.24,
    "truthfulqa": 51.51,
    "mmlu": 56.67,
    "gsm8k": 11.3,
    "winogrande": 74.66,
    "average": 55.41
  },
  "lmsys/vicuna-13b-v1.5-16k": {
    "arc": 55.72,
    "hellaswag": 80.61,
    "truthfulqa": 51.79,
    "mmlu": 55.45,
    "gsm8k": 13.12,
    "winogrande": 72.38,
    "average": 54.85
  },
  "lmsys/vicuna-33b-v1.3": {
    "arc": 61.6,
    "hellaswag": 83.06,
    "truthfulqa": 56.09,
    "mmlu": 59.21,
    "gsm8k": 13.72,
    "winogrande": 77.03,
    "average": 58.45
  },
  "lmsys/vicuna-7b-delta-v1.1": {
    "arc": 53.67,
    "hellaswag": 77.5,
    "truthfulqa": 48.95,
    "mmlu": 45.61,
    "gsm8k": 5.53,
    "winogrande": 70.96,
    "average": 50.37
  },
  "lmsys/vicuna-7b-v1.3": {
    "arc": 50.43,
    "hellaswag": 76.92,
    "truthfulqa": 47.01,
    "mmlu": 48.14,
    "gsm8k": 5.69,
    "winogrande": 70.48,
    "average": 49.78
  },
  "lmsys/vicuna-7b-v1.5": {
    "arc": 53.24,
    "hellaswag": 77.39,
    "truthfulqa": 50.33,
    "mmlu": 50.82,
    "gsm8k": 8.19,
    "winogrande": 72.14,
    "average": 52.02
  },
  "lmsys/vicuna-7b-v1.5-16k": {
    "arc": 54.69,
    "hellaswag": 77.32,
    "truthfulqa": 50.41,
    "mmlu": 49.51,
    "gsm8k": 6.37,
    "winogrande": 71.03,
    "average": 51.56
  },
  "lu-vae/llama2-13B-sharegpt4-orca-openplatypus-8w": {
    "arc": 62.8,
    "hellaswag": 84.04,
    "truthfulqa": 45.66,
    "mmlu": 55.13,
    "gsm8k": 11.75,
    "winogrande": 75.14,
    "average": 55.75
  },
  "lu-vae/llama2-13b-sharegpt4-test": {
    "arc": 58.02,
    "hellaswag": 82.65,
    "truthfulqa": 48.27,
    "mmlu": 55.99,
    "gsm8k": 13.12,
    "winogrande": 76.09,
    "average": 55.69
  },
  "luffycodes/higgs-llama-vicuna-ep25-70b": {
    "arc": 62.29,
    "hellaswag": 86.07,
    "truthfulqa": 53.75,
    "mmlu": 64.25,
    "gsm8k": 34.57,
    "winogrande": 80.66,
    "average": 63.6
  },
  "luffycodes/llama-shishya-7b-ep3-v1": {
    "arc": 48.04,
    "hellaswag": 76.63,
    "truthfulqa": 30.9,
    "winogrande": 69.46,
    "gsm8k": 0,
    "mmlu": 46.12,
    "average": 45.19
  },
  "luffycodes/llama-shishya-7b-ep3-v2": {
    "arc": 47.35,
    "hellaswag": 75.88,
    "truthfulqa": 30.16,
    "winogrande": 68.75,
    "gsm8k": 0,
    "mmlu": 43.84,
    "average": 44.33
  },
  "luffycodes/mcq-hal-vicuna-13b-v1.5": {
    "arc": 56.06,
    "hellaswag": 80.7,
    "truthfulqa": 45.13,
    "mmlu": 52.9,
    "gsm8k": 8.87,
    "winogrande": 72.77,
    "average": 52.74
  },
  "luffycodes/mcq-vicuna-13b-v1.5": {
    "arc": 56.66,
    "hellaswag": 81.09,
    "truthfulqa": 43.99,
    "mmlu": 53.3,
    "gsm8k": 8.04,
    "winogrande": 73.01,
    "average": 52.68
  },
  "luffycodes/nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple": {
    "arc": 59.13,
    "hellaswag": 80.64,
    "truthfulqa": 51.29,
    "mmlu": 56.12,
    "gsm8k": 10.54,
    "winogrande": 74.66,
    "average": 55.4
  },
  "luffycodes/vicuna-shishya-7b-ep3-v1": {
    "arc": 45.9,
    "hellaswag": 76.36,
    "truthfulqa": 40.32,
    "winogrande": 71.74,
    "gsm8k": 0,
    "mmlu": 50.04,
    "average": 47.39
  },
  "lvkaokao/llama2-7b-hf-chat-lora": {
    "arc": 55.72,
    "hellaswag": 78.75,
    "truthfulqa": 43.11,
    "mmlu": 47.99,
    "gsm8k": 10.77,
    "winogrande": 75.85,
    "average": 52.03
  },
  "lvkaokao/llama2-7b-hf-chat-lora-v2": {
    "arc": 55.03,
    "hellaswag": 78.81,
    "truthfulqa": 44.05,
    "mmlu": 51.35,
    "gsm8k": 10.84,
    "winogrande": 74.9,
    "average": 52.5
  },
  "lvkaokao/llama2-7b-hf-chat-lora-v3": {
    "arc": 57.25,
    "hellaswag": 78.62,
    "truthfulqa": 50.62,
    "mmlu": 50.57,
    "gsm8k": 1.52,
    "winogrande": 76.32,
    "average": 52.48
  },
  "lvkaokao/llama2-7b-hf-instruction-lora": {
    "arc": 55.38,
    "hellaswag": 78.57,
    "truthfulqa": 41.83,
    "mmlu": 49.39,
    "gsm8k": 9.86,
    "winogrande": 74.19,
    "average": 51.54
  },
  "lvkaokao/mistral-7b-finetuned-orca-dpo-v2": {
    "arc": 66.21,
    "hellaswag": 83.64,
    "truthfulqa": 59.65,
    "winogrande": 78.14,
    "gsm8k": 19.56,
    "mmlu": 62.37,
    "average": 61.6
  },
  "lxe/Cerebras-GPT-2.7B-Alpaca-SP": {
    "arc": 30.8,
    "hellaswag": 48.88,
    "truthfulqa": 40.24,
    "mmlu": 25.12,
    "gsm8k": 0.53,
    "winogrande": 55.41,
    "average": 33.5
  },
  "lyogavin/Anima-7B-100K": {
    "arc": 46.59,
    "hellaswag": 72.28,
    "truthfulqa": 37.84,
    "mmlu": 33.4,
    "gsm8k": 0.68,
    "winogrande": 67.09,
    "average": 42.98
  },
  "malhajar/Platypus2-70B-instruct-4bit-gptq": {
    "arc": 29.01,
    "hellaswag": 25.95,
    "truthfulqa": 49.56,
    "mmlu": 23.53
  },
  "marcchew/LaMini-40k-Platypus2-7B": {
    "arc": 28.5,
    "hellaswag": 26.32,
    "truthfulqa": 47.39,
    "mmlu": 27.04,
    "gsm8k": 0,
    "winogrande": 50.2,
    "average": 29.91
  },
  "marcchew/Marcoroni-7B-LaMini-40K": {
    "arc": 27.65,
    "hellaswag": 26.23,
    "truthfulqa": 47.4,
    "mmlu": 26.92,
    "gsm8k": 0,
    "winogrande": 50.51,
    "average": 29.78
  },
  "marcchew/Marcoroni-7B-LaMini-80K": {
    "arc": 28.75,
    "hellaswag": 26.13,
    "truthfulqa": 49.71,
    "mmlu": 24.46,
    "gsm8k": 0,
    "winogrande": 51.46,
    "average": 30.09
  },
  "marcchew/Platypus-2-7B-LaMini-14K": {
    "arc": 29.52,
    "hellaswag": 26.15,
    "truthfulqa": 48.29,
    "mmlu": 23.13,
    "gsm8k": 0,
    "winogrande": 50.75,
    "average": 29.64
  },
  "marcchew/test1": {
    "arc": 27.65,
    "hellaswag": 26.17,
    "truthfulqa": 48.33,
    "mmlu": 24.55,
    "gsm8k": 0,
    "winogrande": 50.2,
    "average": 29.48
  },
  "matsuo-lab/weblab-10b": {
    "arc": 39.51,
    "hellaswag": 65.76,
    "truthfulqa": 36.02,
    "mmlu": 26.29,
    "gsm8k": 1.44,
    "winogrande": 62.51,
    "average": 38.59
  },
  "matsuo-lab/weblab-10b-instruction-sft": {
    "arc": 40.1,
    "hellaswag": 65.3,
    "truthfulqa": 36.79,
    "mmlu": 26.66,
    "gsm8k": 1.82,
    "winogrande": 64.09,
    "average": 39.13
  },
  "maximuslee07/llama-2-7b-rockwell-final": {
    "arc": 52.73,
    "hellaswag": 79.1,
    "truthfulqa": 47.21,
    "mmlu": 47.88,
    "gsm8k": 7.96,
    "winogrande": 68.43,
    "average": 50.55
  },
  "maywell/Mini_Synatra_SFT": {
    "arc": 62.46,
    "hellaswag": 83.44,
    "truthfulqa": 53.67,
    "winogrande": 74.66,
    "gsm8k": 44.88,
    "mmlu": 61.2,
    "average": 63.39
  },
  "maywell/PiVoT-0.1-Evil-a": {
    "arc": 59.64,
    "hellaswag": 81.48,
    "truthfulqa": 39.23,
    "winogrande": 75.3,
    "gsm8k": 40.41,
    "mmlu": 58.94,
    "average": 59.17
  },
  "maywell/PiVoT-0.1-early": {
    "arc": 62.46,
    "hellaswag": 82.97,
    "truthfulqa": 62.89,
    "winogrande": 73.72,
    "gsm8k": 44.43,
    "mmlu": 61.02,
    "average": 64.58
  },
  "maywell/Synatra-11B-Testbench": {
    "arc": 57.34,
    "hellaswag": 78.66,
    "truthfulqa": 51.97,
    "winogrande": 75.77,
    "gsm8k": 17.74,
    "mmlu": 55.56,
    "average": 56.17
  },
  "maywell/Synatra-7B-v0.3-RP": {
    "arc": 62.2,
    "hellaswag": 82.29,
    "truthfulqa": 52.64,
    "winogrande": 76.48,
    "gsm8k": 21.15,
    "mmlu": 60.8,
    "average": 59.26
  },
  "maywell/Synatra-7B-v0.3-dpo": {
    "arc": 62.8,
    "hellaswag": 82.58,
    "truthfulqa": 56.46,
    "winogrande": 76.24,
    "gsm8k": 23.73,
    "mmlu": 61.46,
    "average": 60.54
  },
  "maywell/Synatra-RP-Orca-2-7b-v0.1": {
    "arc": 57.68,
    "hellaswag": 77.37,
    "truthfulqa": 52.52,
    "winogrande": 74.59,
    "gsm8k": 39.65,
    "mmlu": 56.1,
    "average": 59.65
  },
  "maywell/Synatra-V0.1-7B": {
    "arc": 55.29,
    "hellaswag": 76.63,
    "truthfulqa": 55.76,
    "mmlu": 55.29,
    "gsm8k": 19.41,
    "winogrande": 72.77,
    "average": 55.86
  },
  "maywell/Synatra-V0.1-7B-Instruct": {
    "arc": 55.29,
    "hellaswag": 76.63,
    "truthfulqa": 55.76,
    "mmlu": 55.29,
    "gsm8k": 19.41,
    "winogrande": 72.77,
    "average": 55.86
  },
  "maywell/koOpenChat-sft": {
    "arc": 59.81,
    "hellaswag": 78.73,
    "truthfulqa": 51.24,
    "winogrande": 76.4,
    "gsm8k": 24.18,
    "mmlu": 61.32,
    "average": 58.61
  },
  "medalpaca/medalpaca-7b": {
    "arc": 54.1,
    "hellaswag": 80.42,
    "truthfulqa": 40.46,
    "mmlu": 41.47,
    "gsm8k": 3.03,
    "winogrande": 71.19,
    "average": 48.45
  },
  "mergedlm/zephyrnotus-11b-alpha": {
    "arc": 61.35,
    "hellaswag": 82.8,
    "truthfulqa": 57.22,
    "winogrande": 76.4,
    "gsm8k": 17.13,
    "mmlu": 60.67,
    "average": 59.26
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "arc": 59.04,
    "hellaswag": 81.94,
    "truthfulqa": 44.12,
    "mmlu": 54.64,
    "gsm8k": 15.24,
    "winogrande": 74.51,
    "average": 54.92
  },
  "meta-llama/Llama-2-13b-hf": {
    "arc": 58.11,
    "hellaswag": 80.97,
    "truthfulqa": 34.17,
    "mmlu": 54.34,
    "winogrande": 76.64,
    "gsm8k": 22.82,
    "average": 54.51
  },
  "meta-llama/Llama-2-70b-chat-hf": {
    "arc": 64.59,
    "hellaswag": 85.88,
    "truthfulqa": 52.8,
    "mmlu": 63.91,
    "gsm8k": 26.69,
    "winogrande": 80.51,
    "average": 62.4
  },
  "meta-llama/Llama-2-70b-hf": {
    "arc": 67.32,
    "hellaswag": 87.33,
    "truthfulqa": 44.92,
    "mmlu": 69.83,
    "gsm8k": 54.06,
    "winogrande": 83.74,
    "average": 67.87
  },
  "meta-llama/Llama-2-7b-chat-hf": {
    "arc": 52.9,
    "hellaswag": 78.55,
    "truthfulqa": 45.57,
    "mmlu": 48.32,
    "gsm8k": 7.35,
    "winogrande": 71.74,
    "average": 50.74
  },
  "meta-llama/Llama-2-7b-hf": {
    "arc": 53.07,
    "hellaswag": 77.74,
    "truthfulqa": 38.98,
    "mmlu": 43.8,
    "winogrande": 74.03,
    "gsm8k": 14.48,
    "average": 50.35
  },
  "meta-math/MetaMath-13B-V1.0": {
    "arc": 49.49,
    "hellaswag": 76.48,
    "truthfulqa": 41.58,
    "mmlu": 47.74,
    "gsm8k": 28.51,
    "winogrande": 72.45,
    "average": 52.71
  },
  "meta-math/MetaMath-70B-V1.0": {
    "arc": 68,
    "hellaswag": 86.85,
    "truthfulqa": 50.98,
    "mmlu": 69.31,
    "gsm8k": 44.66,
    "winogrande": 82.32,
    "average": 67.02
  },
  "meta-math/MetaMath-Mistral-7B": {
    "arc": 60.67,
    "hellaswag": 82.58,
    "truthfulqa": 44.89,
    "winogrande": 75.77,
    "gsm8k": 68.84,
    "mmlu": 61.95,
    "average": 65.78
  },
  "microsoft/CodeGPT-small-py": {
    "arc": 22.7,
    "hellaswag": 27.26,
    "truthfulqa": 51.23,
    "mmlu": 25.05,
    "gsm8k": 0,
    "winogrande": 48.78,
    "average": 29.17
  },
  "microsoft/DialoGPT-large": {
    "arc": 23.38,
    "hellaswag": 25.77,
    "truthfulqa": 50.27,
    "mmlu": 23.81,
    "gsm8k": 0,
    "winogrande": 52.41,
    "average": 29.27
  },
  "microsoft/DialoGPT-medium": {
    "arc": 24.49,
    "hellaswag": 26.21,
    "truthfulqa": 47.06,
    "mmlu": 25.84,
    "gsm8k": 0,
    "winogrande": 49.57,
    "average": 28.86
  },
  "microsoft/DialoGPT-small": {
    "arc": 25.77,
    "hellaswag": 25.79,
    "truthfulqa": 47.49,
    "mmlu": 25.81,
    "gsm8k": 0,
    "winogrande": 50.28,
    "average": 29.19
  },
  "microsoft/Orca-2-13b": {
    "arc": 60.67,
    "hellaswag": 79.81,
    "truthfulqa": 56.41,
    "winogrande": 76.64,
    "gsm8k": 17.97,
    "mmlu": 60.37,
    "average": 58.65
  },
  "microsoft/Orca-2-7b": {
    "arc": 54.1,
    "hellaswag": 76.19,
    "truthfulqa": 52.45,
    "winogrande": 73.48,
    "gsm8k": 14.71,
    "mmlu": 56.37,
    "average": 54.55
  },
  "microsoft/phi-1_5": {
    "arc": 52.9,
    "hellaswag": 63.79,
    "truthfulqa": 40.89,
    "mmlu": 43.89,
    "gsm8k": 12.43,
    "winogrande": 72.22,
    "average": 47.69
  },
  "migtissera/SynthIA-7B-v1.3": {
    "arc": 62.12,
    "hellaswag": 83.45,
    "truthfulqa": 51.37,
    "mmlu": 62.65,
    "gsm8k": 17.59,
    "winogrande": 78.85,
    "average": 59.34
  },
  "migtissera/SynthIA-7B-v1.5": {
    "arc": 62.71,
    "hellaswag": 83.37,
    "truthfulqa": 51.32,
    "winogrande": 79.24,
    "gsm8k": 17.44,
    "mmlu": 63.48,
    "average": 59.59
  },
  "migtissera/Synthia-13B": {
    "arc": 59.98,
    "hellaswag": 81.86,
    "truthfulqa": 47.41,
    "mmlu": 56.11,
    "gsm8k": 10.99,
    "winogrande": 76.09,
    "average": 55.41
  },
  "migtissera/Synthia-13B-v1.2": {
    "arc": 61.26,
    "hellaswag": 82.93,
    "truthfulqa": 47.27,
    "mmlu": 56.47,
    "gsm8k": 10.99,
    "winogrande": 76.48,
    "average": 55.9
  },
  "migtissera/Synthia-34B-v1.2": {
    "arc": 54.86,
    "hellaswag": 74.33,
    "truthfulqa": 44.67,
    "mmlu": 53.2
  },
  "migtissera/Synthia-70B": {
    "arc": 69.45,
    "hellaswag": 87.11,
    "truthfulqa": 59.79,
    "mmlu": 68.91,
    "gsm8k": 31.39,
    "winogrande": 83.66,
    "average": 66.72
  },
  "migtissera/Synthia-70B-v1.1": {
    "arc": 70.05,
    "hellaswag": 87.12,
    "truthfulqa": 57.84,
    "mmlu": 70.34,
    "gsm8k": 31.84,
    "winogrande": 83.66,
    "average": 66.81
  },
  "migtissera/Synthia-70B-v1.2": {
    "arc": 70.48,
    "hellaswag": 86.98,
    "truthfulqa": 58.64,
    "mmlu": 70.13,
    "gsm8k": 31.92,
    "winogrande": 83.27,
    "average": 66.9
  },
  "migtissera/Synthia-70B-v1.2b": {
    "arc": 68.77,
    "hellaswag": 87.57,
    "truthfulqa": 57.69,
    "mmlu": 68.81,
    "gsm8k": 35.25,
    "winogrande": 83.9,
    "average": 67
  },
  "migtissera/Synthia-7B": {
    "arc": 56.14,
    "hellaswag": 78.6,
    "truthfulqa": 45.03,
    "mmlu": 50.35,
    "gsm8k": 6.6,
    "winogrande": 74.27,
    "average": 51.83
  },
  "migtissera/Synthia-7B-v1.2": {
    "arc": 54.35,
    "hellaswag": 79.29,
    "truthfulqa": 48.92,
    "mmlu": 49.33,
    "gsm8k": 10.84,
    "winogrande": 73.56,
    "average": 52.72
  },
  "migtissera/Tess-M-Creative-v1.0": {
    "arc": 66.81,
    "hellaswag": 85.14,
    "truthfulqa": 57.68,
    "winogrande": 83.11,
    "gsm8k": 62.09,
    "mmlu": 75.54,
    "average": 71.73
  },
  "migtissera/Tess-M-v1.1": {
    "arc": 67.15,
    "hellaswag": 84.76,
    "truthfulqa": 54.8,
    "winogrande": 82.87,
    "gsm8k": 54.66,
    "mmlu": 74.5,
    "average": 69.79
  },
  "migtissera/Tess-M-v1.3": {
    "arc": 62.54,
    "hellaswag": 83.95,
    "truthfulqa": 56.03,
    "winogrande": 81.14,
    "gsm8k": 59.21,
    "mmlu": 75.36,
    "average": 69.71
  },
  "migtissera/Tess-XS-v1-3-yarn-128K": {
    "arc": 61.6,
    "hellaswag": 82.96,
    "truthfulqa": 50.2,
    "winogrande": 74.74,
    "gsm8k": 43.37,
    "mmlu": 62.1,
    "average": 62.5
  },
  "migtissera/Tess-XS-v1.0": {
    "arc": 61.43,
    "hellaswag": 83.82,
    "truthfulqa": 47.12,
    "winogrande": 78.93,
    "gsm8k": 18.27,
    "mmlu": 64.1,
    "average": 58.94
  },
  "migtissera/Tess-XS-v1.1": {
    "arc": 63.91,
    "hellaswag": 84.06,
    "truthfulqa": 49.92,
    "winogrande": 79.16,
    "gsm8k": 16.22,
    "mmlu": 63.07,
    "average": 59.39
  },
  "minlik/chinese-alpaca-33b-merged": {
    "arc": 59.3,
    "hellaswag": 78.43,
    "truthfulqa": 52.45,
    "mmlu": 57.69,
    "gsm8k": 8.04,
    "winogrande": 76.09,
    "average": 55.33
  },
  "mistralai/Mistral-7B-Instruct-v0.1": {
    "arc": 54.52,
    "hellaswag": 75.63,
    "truthfulqa": 56.28,
    "mmlu": 55.38,
    "gsm8k": 14.25,
    "winogrande": 73.72,
    "average": 54.96
  },
  "mistralai/Mistral-7B-v0.1": {
    "arc": 59.98,
    "hellaswag": 83.31,
    "truthfulqa": 42.15,
    "mmlu": 64.16,
    "gsm8k": 37.07,
    "winogrande": 78.61,
    "average": 60.88
  },
  "mlabonne/NeuralHermes-2.5-Mistral-7B": {
    "arc": 66.55,
    "hellaswag": 84.9,
    "truthfulqa": 54.93,
    "winogrande": 78.3,
    "gsm8k": 61.33,
    "mmlu": 63.32,
    "average": 68.22
  },
  "mlinmg/SG-Raccoon-Yi-200k-2.0": {
    "arc": 62.54,
    "hellaswag": 80.26,
    "truthfulqa": 53.21,
    "winogrande": 76.32,
    "gsm8k": 30.71,
    "mmlu": 73.29,
    "average": 62.72
  },
  "mncai/Llama2-7B-guanaco-1k": {
    "arc": 55.12,
    "hellaswag": 80.53,
    "truthfulqa": 47.69,
    "mmlu": 47.93,
    "gsm8k": 7.58,
    "winogrande": 74.82,
    "average": 52.28
  },
  "mncai/Llama2-7B-guanaco-dolphin-500": {
    "arc": 56.74,
    "hellaswag": 81.63,
    "truthfulqa": 46.94,
    "mmlu": 48.69,
    "gsm8k": 5.99,
    "winogrande": 74.27,
    "average": 52.38
  },
  "mncai/Mistral-7B-OpenOrca-1k": {
    "arc": 62.97,
    "hellaswag": 84.66,
    "truthfulqa": 52.96,
    "mmlu": 62.2,
    "gsm8k": 11.98,
    "winogrande": 78.61,
    "average": 58.9
  },
  "mncai/Mistral-7B-openplatypus-1k": {
    "arc": 60.15,
    "hellaswag": 84.25,
    "truthfulqa": 49.86,
    "mmlu": 59.84,
    "gsm8k": 17.44,
    "winogrande": 76.87,
    "average": 58.07
  },
  "mncai/SGPT-1.3B-insurance-epoch10": {
    "arc": 24.57,
    "hellaswag": 24.25,
    "truthfulqa": 45.24,
    "mmlu": 25.23,
    "gsm8k": 0,
    "winogrande": 50.91,
    "average": 28.37
  },
  "mncai/chatdoctor": {
    "arc": 53.75,
    "hellaswag": 78.54,
    "truthfulqa": 43.55,
    "mmlu": 35.95,
    "gsm8k": 0,
    "winogrande": 69.93,
    "average": 46.95
  },
  "monology/openinstruct-mistral-7b": {
    "arc": 59.73,
    "hellaswag": 82.77,
    "truthfulqa": 48.76,
    "winogrande": 79.56,
    "gsm8k": 50.49,
    "mmlu": 60.55,
    "average": 63.64
  },
  "mosaicml/mpt-30b": {
    "arc": 55.97,
    "hellaswag": 82.42,
    "truthfulqa": 38.42,
    "mmlu": 48,
    "winogrande": 74.9,
    "gsm8k": 16.91,
    "average": 52.77
  },
  "mosaicml/mpt-30b-chat": {
    "arc": 58.36,
    "hellaswag": 82.41,
    "truthfulqa": 52,
    "mmlu": 50.98,
    "gsm8k": 12.13,
    "winogrande": 75.3,
    "average": 55.2
  },
  "mosaicml/mpt-30b-instruct": {
    "arc": 58.45,
    "hellaswag": 84.31,
    "truthfulqa": 38.05,
    "mmlu": 49.15,
    "gsm8k": 15.31,
    "winogrande": 75.14,
    "average": 53.4
  },
  "mosaicml/mpt-7b": {
    "arc": 47.7,
    "hellaswag": 77.53,
    "truthfulqa": 33.55,
    "mmlu": 28.07,
    "gsm8k": 4.02,
    "winogrande": 72.14,
    "average": 43.84
  },
  "mosaicml/mpt-7b-8k-chat": {
    "arc": 47.7,
    "hellaswag": 77.48,
    "truthfulqa": 43.65,
    "mmlu": 41.47,
    "gsm8k": 4.4,
    "winogrande": 71.03,
    "average": 47.62
  },
  "mosaicml/mpt-7b-8k-instruct": {
    "arc": 45.48,
    "hellaswag": 74.41,
    "truthfulqa": 35.06,
    "mmlu": 42.11,
    "gsm8k": 20.55,
    "winogrande": 65.51,
    "average": 47.19
  },
  "mosaicml/mpt-7b-chat": {
    "arc": 46.5,
    "hellaswag": 75.51,
    "truthfulqa": 40.16,
    "mmlu": 37.62,
    "gsm8k": 4.09,
    "winogrande": 68.43,
    "average": 45.39
  },
  "mosaicml/mpt-7b-instruct": {
    "arc": 50.34,
    "hellaswag": 77.91,
    "truthfulqa": 35.08,
    "mmlu": 32.35,
    "gsm8k": 2.81,
    "winogrande": 70.48,
    "average": 44.83
  },
  "mosaicml/mpt-7b-storywriter": {
    "arc": 20.39,
    "hellaswag": 27.45,
    "truthfulqa": 48.44,
    "mmlu": 24.25,
    "gsm8k": 0,
    "winogrande": 51.14,
    "average": 28.61
  },
  "mrfakename/NeuralOrca-7B-v1": {
    "arc": 65.27,
    "hellaswag": 85.07,
    "truthfulqa": 54.58,
    "winogrande": 78.77,
    "gsm8k": 58.45,
    "mmlu": 63.68,
    "average": 67.64
  },
  "mrm8488/llama-2-coder-7b": {
    "arc": 54.01,
    "hellaswag": 78.35,
    "truthfulqa": 38.49,
    "mmlu": 46.25,
    "gsm8k": 7.13,
    "winogrande": 75.45,
    "average": 49.95
  },
  "mrm8488/mistral-7b-ft-h4-no_robots_instructions": {
    "arc": 60.92,
    "hellaswag": 83.17,
    "truthfulqa": 43.63,
    "winogrande": 78.85,
    "gsm8k": 36.69,
    "mmlu": 63.37,
    "average": 61.11
  },
  "nathan0/mpt_delta_tuned_model_v2": {
    "arc": 50.68,
    "hellaswag": 76.41,
    "truthfulqa": 35.47,
    "mmlu": 28.73
  },
  "nathan0/mpt_delta_tuned_model_v3": {
    "arc": 50.6,
    "hellaswag": 76.4,
    "truthfulqa": 35.46,
    "mmlu": 27.29
  },
  "nicholasKluge/Aira-124M": {
    "arc": 24.57,
    "hellaswag": 31.29,
    "truthfulqa": 41.02,
    "mmlu": 25.29
  },
  "nicholasKluge/Aira-1B5": {
    "arc": 28.92,
    "hellaswag": 43.11,
    "truthfulqa": 41.16,
    "mmlu": 27.29
  },
  "nicholasKluge/Aira-2-1B1": {
    "arc": 23.21,
    "hellaswag": 26.97,
    "truthfulqa": 50.63,
    "mmlu": 24.86,
    "gsm8k": 0,
    "winogrande": 50.28,
    "average": 29.33
  },
  "nicholasKluge/Aira-2-355M": {
    "arc": 27.56,
    "hellaswag": 38.92,
    "truthfulqa": 38.53,
    "mmlu": 27.26,
    "gsm8k": 0,
    "winogrande": 53.75,
    "average": 31
  },
  "nicholasKluge/Aira-2-774M": {
    "arc": 28.75,
    "hellaswag": 40.8,
    "truthfulqa": 41.33,
    "mmlu": 25.1,
    "gsm8k": 0,
    "winogrande": 52.01,
    "average": 31.33
  },
  "nkpz/llama2-22b-chat-wizard-uncensored": {
    "arc": 56.23,
    "hellaswag": 80.39,
    "truthfulqa": 45.76,
    "mmlu": 53.62,
    "gsm8k": 11.14,
    "winogrande": 70.24,
    "average": 52.9
  },
  "nkpz/llama2-22b-daydreamer-v3": {
    "arc": 56.06,
    "hellaswag": 80.07,
    "truthfulqa": 42.43,
    "mmlu": 52.49,
    "gsm8k": 3.79,
    "winogrande": 73.48,
    "average": 51.39
  },
  "nnpy/Nape-0": {
    "arc": 32.68,
    "hellaswag": 58.68,
    "truthfulqa": 38.99,
    "winogrande": 57.3,
    "gsm8k": 0.08,
    "mmlu": 24.88,
    "average": 35.43
  },
  "nomic-ai/gpt4all-j": {
    "arc": 41.98,
    "hellaswag": 64.06,
    "truthfulqa": 42.78,
    "mmlu": 28.2,
    "gsm8k": 7.2,
    "winogrande": 64.72,
    "average": 41.49
  },
  "notstoic/PygmalionCoT-7b": {
    "arc": 51.45,
    "hellaswag": 76.92,
    "truthfulqa": 48.13,
    "mmlu": 33.35,
    "gsm8k": 3.26,
    "winogrande": 68.9,
    "average": 47
  },
  "nthngdy/pythia-owt2-70m-100k": {
    "arc": 20.9,
    "hellaswag": 28.34,
    "truthfulqa": 45.12,
    "mmlu": 25.02,
    "gsm8k": 0,
    "winogrande": 53.28,
    "average": 28.78
  },
  "nthngdy/pythia-owt2-70m-50k": {
    "arc": 21.5,
    "hellaswag": 28.15,
    "truthfulqa": 44.5,
    "mmlu": 25.7,
    "gsm8k": 0,
    "winogrande": 52.41,
    "average": 28.71
  },
  "ogimgio/gpt-neo-125m-neurallinguisticpioneers": {
    "arc": 22.44,
    "hellaswag": 30.36,
    "truthfulqa": 45.64,
    "mmlu": 25.14,
    "gsm8k": 0.08,
    "winogrande": 51.22,
    "average": 29.15
  },
  "oh-yeontaek/llama-2-13B-LoRA-assemble": {
    "arc": 63.57,
    "hellaswag": 83.51,
    "truthfulqa": 55.96,
    "mmlu": 59.82,
    "gsm8k": 8.42,
    "winogrande": 76.16,
    "average": 57.91
  },
  "oh-yeontaek/llama-2-70B-LoRA-assemble": {
    "arc": 71.84,
    "hellaswag": 86.78,
    "truthfulqa": 64.8,
    "mmlu": 69.4
  },
  "oh-yeontaek/llama-2-70B-LoRA-assemble-v2": {
    "arc": 71.84,
    "hellaswag": 86.89,
    "truthfulqa": 64.79,
    "mmlu": 69.37,
    "gsm8k": 14.25,
    "winogrande": 81.22,
    "average": 64.73
  },
  "oh-yeontaek/llama-2-7B-LoRA-assemble": {
    "arc": 57.34,
    "hellaswag": 78.81,
    "truthfulqa": 53.18,
    "mmlu": 50.75,
    "gsm8k": 0,
    "winogrande": 73.48,
    "average": 52.26
  },
  "openaccess-ai-collective/DPOpenHermes-7B": {
    "arc": 65.96,
    "hellaswag": 85.9,
    "truthfulqa": 56.92,
    "winogrande": 78.22,
    "gsm8k": 54.81,
    "mmlu": 63.98,
    "average": 67.63
  },
  "openaccess-ai-collective/dpopenhermes-alpha-v0": {
    "arc": 65.02,
    "hellaswag": 83.96,
    "truthfulqa": 51.75,
    "winogrande": 78.85,
    "gsm8k": 55.88,
    "mmlu": 63.67,
    "average": 66.52
  },
  "openaccess-ai-collective/grendel": {
    "arc": 60.49,
    "hellaswag": 79.99,
    "truthfulqa": 52.68,
    "winogrande": 75.3,
    "gsm8k": 28.73,
    "mmlu": 58.98,
    "average": 59.36
  },
  "openaccess-ai-collective/hippogriff-30b-chat": {
    "arc": 64.51,
    "hellaswag": 85.2,
    "truthfulqa": 48.42,
    "mmlu": 59.09,
    "gsm8k": 10.24,
    "winogrande": 80.82,
    "average": 58.05
  },
  "openaccess-ai-collective/jackalope-7b": {
    "arc": 63.4,
    "hellaswag": 83.29,
    "truthfulqa": 50.06,
    "mmlu": 63.5,
    "gsm8k": 28.66,
    "winogrande": 78.06,
    "average": 61.16
  },
  "openaccess-ai-collective/manticore-13b": {
    "arc": 58.7,
    "hellaswag": 81.63,
    "truthfulqa": 49.17,
    "mmlu": 50.84,
    "gsm8k": 12.21,
    "winogrande": 76.64,
    "average": 54.87
  },
  "openaccess-ai-collective/manticore-13b-chat-pyg": {
    "arc": 58.53,
    "hellaswag": 81.96,
    "truthfulqa": 48.76,
    "mmlu": 48.76,
    "gsm8k": 9.55,
    "winogrande": 77.19,
    "average": 54.13
  },
  "openaccess-ai-collective/manticore-30b-chat-pyg-alpha": {
    "arc": 64.16,
    "hellaswag": 84.38,
    "truthfulqa": 51.57,
    "mmlu": 57.49,
    "gsm8k": 16.07,
    "winogrande": 79.48,
    "average": 58.86
  },
  "openaccess-ai-collective/minotaur-13b": {
    "arc": 56.4,
    "hellaswag": 79.13,
    "truthfulqa": 49.62,
    "mmlu": 49.61,
    "gsm8k": 12.51,
    "winogrande": 76.56,
    "average": 53.97
  },
  "openaccess-ai-collective/minotaur-13b-fixed": {
    "arc": 59.04,
    "hellaswag": 81.66,
    "truthfulqa": 50.36,
    "mmlu": 50.1,
    "gsm8k": 13.12,
    "winogrande": 76.87,
    "average": 55.19
  },
  "openaccess-ai-collective/mistral-7b-slimorcaboros": {
    "arc": 63.65,
    "hellaswag": 83.7,
    "truthfulqa": 55.81,
    "winogrande": 77.03,
    "gsm8k": 23.43,
    "mmlu": 63.46,
    "average": 61.18
  },
  "openaccess-ai-collective/openhermes-2_5-dpo-no-robots": {
    "arc": 64.93,
    "hellaswag": 84.3,
    "truthfulqa": 52.12,
    "winogrande": 77.9,
    "gsm8k": 55.27,
    "mmlu": 63.86,
    "average": 66.4
  },
  "openaccess-ai-collective/openhermes-2_5-dpo-no-robots-v2": {
    "gsm8k": 55.42
  },
  "openaccess-ai-collective/wizard-mega-13b": {
    "arc": 57.34,
    "hellaswag": 81.09,
    "truthfulqa": 50.22,
    "mmlu": 50.59,
    "gsm8k": 10.08,
    "winogrande": 76.32,
    "average": 54.27
  },
  "openbmb/UltraLM-13b": {
    "arc": 29.44,
    "hellaswag": 25.99,
    "truthfulqa": 48.61,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 49.57,
    "average": 29.46
  },
  "openbmb/UltraLM-13b-v2.0": {
    "arc": 62.63,
    "hellaswag": 81.49,
    "truthfulqa": 49.48,
    "mmlu": 56.17,
    "gsm8k": 26.08,
    "winogrande": 76.48,
    "average": 58.72
  },
  "openbmb/UltraLM-65b": {
    "arc": 67.06,
    "hellaswag": 84.98,
    "truthfulqa": 53.51,
    "mmlu": 63.48,
    "gsm8k": 32.75,
    "winogrande": 81.14,
    "average": 63.82
  },
  "openbmb/UltraRM-13b": {
    "arc": 28.16,
    "hellaswag": 26.13,
    "truthfulqa": 47.91,
    "mmlu": 25.96,
    "gsm8k": 0,
    "winogrande": 49.33,
    "average": 29.58
  },
  "openchat/openchat_3.5": {
    "arc": 62.46,
    "hellaswag": 83.96,
    "truthfulqa": 45.43,
    "winogrande": 81.06,
    "gsm8k": 25.78,
    "mmlu": 62.89,
    "average": 60.26
  },
  "openchat/openchat_8192": {
    "arc": 59.56,
    "hellaswag": 81.44,
    "truthfulqa": 46.7,
    "mmlu": 46.26,
    "gsm8k": 7.35,
    "winogrande": 74.98,
    "average": 52.72
  },
  "openchat/openchat_v2": {
    "arc": 57.17,
    "hellaswag": 81.14,
    "truthfulqa": 49.54,
    "mmlu": 50.58,
    "gsm8k": 9.1,
    "winogrande": 76.24,
    "average": 53.96
  },
  "openchat/openchat_v2_w": {
    "arc": 57.34,
    "hellaswag": 81.23,
    "truthfulqa": 50.7,
    "mmlu": 50.17,
    "gsm8k": 8.42,
    "winogrande": 75.93,
    "average": 53.97
  },
  "openchat/openchat_v3.1": {
    "arc": 59.81,
    "hellaswag": 82.8,
    "truthfulqa": 44.45,
    "mmlu": 56.76,
    "gsm8k": 13.8,
    "winogrande": 76.24,
    "average": 55.64
  },
  "openchat/openchat_v3.2": {
    "arc": 59.64,
    "hellaswag": 82.68,
    "truthfulqa": 44.49,
    "mmlu": 56.68,
    "gsm8k": 13.65,
    "winogrande": 76.95,
    "average": 55.68
  },
  "openchat/openchat_v3.2_super": {
    "arc": 59.81,
    "hellaswag": 82.5,
    "truthfulqa": 42.3,
    "mmlu": 55.9,
    "gsm8k": 13.5,
    "winogrande": 75.93,
    "average": 54.99
  },
  "openchat/opencoderplus": {
    "arc": 50.6,
    "hellaswag": 78.22,
    "truthfulqa": 50.72,
    "mmlu": 42.73,
    "gsm8k": 4.62,
    "winogrande": 66.14,
    "average": 48.84
  },
  "openlm-research/open_llama_13b": {
    "arc": 51.19,
    "hellaswag": 75.23,
    "truthfulqa": 38.08,
    "mmlu": 43.75,
    "gsm8k": 3.26,
    "winogrande": 72.06,
    "average": 47.26
  },
  "openlm-research/open_llama_3b": {
    "arc": 39.85,
    "hellaswag": 62.65,
    "truthfulqa": 34.97,
    "mmlu": 26.94,
    "gsm8k": 0.45,
    "winogrande": 64.72,
    "average": 38.26
  },
  "openlm-research/open_llama_3b_v2": {
    "arc": 40.27,
    "hellaswag": 71.6,
    "truthfulqa": 34.78,
    "mmlu": 27.12,
    "gsm8k": 0.91,
    "winogrande": 67.01,
    "average": 40.28
  },
  "openlm-research/open_llama_7b": {
    "arc": 47.01,
    "hellaswag": 71.98,
    "truthfulqa": 34.85,
    "mmlu": 30.49,
    "gsm8k": 1.59,
    "winogrande": 67.96,
    "average": 42.31
  },
  "openlm-research/open_llama_7b_700bt_preview": {
    "arc": 35.07,
    "hellaswag": 61.79,
    "truthfulqa": 37.77,
    "mmlu": 25.45
  },
  "openlm-research/open_llama_7b_v2": {
    "arc": 43.69,
    "hellaswag": 72.2,
    "truthfulqa": 35.54,
    "mmlu": 41.29,
    "gsm8k": 3.49,
    "winogrande": 69.38,
    "average": 44.27
  },
  "openthaigpt/openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf": {
    "arc": 50.85,
    "hellaswag": 74.89,
    "truthfulqa": 47.23,
    "mmlu": 40.02,
    "gsm8k": 3.87,
    "winogrande": 69.06,
    "average": 47.65
  },
  "pankajmathur/Lima_Unchained_70b": {
    "arc": 68.26,
    "hellaswag": 87.65,
    "truthfulqa": 48.76,
    "mmlu": 70,
    "gsm8k": 34.72,
    "winogrande": 83.66,
    "average": 65.51
  },
  "pankajmathur/Mistral-7B-model_45k6e2e4": {
    "arc": 24.32,
    "hellaswag": 25.08,
    "truthfulqa": 50.85,
    "mmlu": 23.19
  },
  "pankajmathur/model_007": {
    "arc": 71.08,
    "hellaswag": 87.65,
    "truthfulqa": 63.12,
    "mmlu": 69.04
  },
  "pankajmathur/orca_mini_v3_13b": {
    "arc": 63.14,
    "hellaswag": 82.35,
    "truthfulqa": 51.81,
    "mmlu": 56.52,
    "gsm8k": 13.12,
    "winogrande": 76.48,
    "average": 57.24
  },
  "pankajmathur/orca_mini_v3_70b": {
    "arc": 71.25,
    "hellaswag": 87.85,
    "truthfulqa": 61.27,
    "mmlu": 70.18
  },
  "pankajmathur/orca_mini_v3_7b": {
    "arc": 56.91,
    "hellaswag": 79.64,
    "truthfulqa": 50.51,
    "mmlu": 52.37,
    "gsm8k": 7.13,
    "winogrande": 74.27,
    "average": 53.47
  },
  "pe-nlp/llama-2-13b-platypus-vicuna-wizard": {
    "arc": 61.26,
    "hellaswag": 82.31,
    "truthfulqa": 41.91,
    "mmlu": 55.21,
    "gsm8k": 0.91,
    "winogrande": 75.77,
    "average": 52.9
  },
  "pe-nlp/llama-2-13b-vicuna-wizard": {
    "arc": 57.76,
    "hellaswag": 82.16,
    "truthfulqa": 41.11,
    "mmlu": 54.68,
    "gsm8k": 0.91,
    "winogrande": 74.98,
    "average": 51.93
  },
  "perlthoughts/Chupacabra-7B": {
    "arc": 66.81,
    "hellaswag": 83.52,
    "truthfulqa": 52.31,
    "winogrande": 79.08,
    "gsm8k": 62.17,
    "mmlu": 62.68,
    "average": 67.76
  },
  "perlthoughts/Chupacabra-7B-v2": {
    "arc": 65.19,
    "hellaswag": 83.39,
    "truthfulqa": 57.17,
    "winogrande": 78.14,
    "gsm8k": 54.74,
    "mmlu": 63.6,
    "average": 67.04
  },
  "perlthoughts/Chupacabra-v3": {
    "arc": 66.21,
    "hellaswag": 81.29,
    "truthfulqa": 57.85,
    "winogrande": 77.43,
    "gsm8k": 15.01,
    "mmlu": 59.36,
    "average": 59.53
  },
  "pillowtalks-ai/delta13b": {
    "arc": 52.73,
    "hellaswag": 80.13,
    "truthfulqa": 52.08,
    "mmlu": 51.94,
    "gsm8k": 8.64,
    "winogrande": 74.19,
    "average": 53.29
  },
  "player1537/dolphinette": {
    "arc": 24.91,
    "hellaswag": 37.33,
    "truthfulqa": 42.08,
    "mmlu": 25.37,
    "gsm8k": 0,
    "winogrande": 54.22,
    "average": 30.65
  },
  "porkorbeef/Llama-2-13b": {
    "arc": 29.35,
    "hellaswag": 26.35,
    "truthfulqa": 48.32,
    "mmlu": 24.94,
    "gsm8k": 0,
    "winogrande": 51.7,
    "average": 30.11
  },
  "porkorbeef/Llama-2-13b-12_153950": {
    "arc": 28.58,
    "hellaswag": 26.58,
    "truthfulqa": 49.03,
    "mmlu": 20.79,
    "gsm8k": 0,
    "winogrande": 53.12,
    "average": 29.68
  },
  "porkorbeef/Llama-2-13b-public": {
    "arc": 29.95,
    "hellaswag": 26.65,
    "truthfulqa": 49.01,
    "mmlu": 22.74,
    "gsm8k": 0,
    "winogrande": 48.38,
    "average": 29.46
  },
  "porkorbeef/Llama-2-13b-sf": {
    "arc": 29.52,
    "hellaswag": 26.49,
    "truthfulqa": 48.97,
    "mmlu": 25.98,
    "gsm8k": 0,
    "winogrande": 50.36,
    "average": 30.22
  },
  "posicube/Llama-chat-AY-13B": {
    "arc": 62.8,
    "hellaswag": 83.23,
    "truthfulqa": 55.95,
    "mmlu": 60.01,
    "gsm8k": 12.13,
    "winogrande": 75.93,
    "average": 58.34
  },
  "posicube/Llama2-chat-AYB-13B": {
    "arc": 63.4,
    "hellaswag": 84.79,
    "truthfulqa": 55.62,
    "mmlu": 59.34,
    "gsm8k": 11.3,
    "winogrande": 76.24,
    "average": 58.45
  },
  "posicube/Llama2-chat-AYT-13B": {
    "arc": 63.31,
    "hellaswag": 83.53,
    "truthfulqa": 55.8,
    "mmlu": 59.67,
    "gsm8k": 8.87,
    "winogrande": 76.09,
    "average": 57.88
  },
  "postbot/distilgpt2-emailgen": {
    "arc": 21.76,
    "hellaswag": 27.52,
    "truthfulqa": 46.17,
    "winogrande": 51.62,
    "gsm8k": 0,
    "mmlu": 25.97,
    "average": 28.84
  },
  "postbot/distilgpt2-emailgen-V2": {
    "arc": 20.99,
    "hellaswag": 26.78,
    "truthfulqa": 46.51,
    "winogrande": 52.01,
    "gsm8k": 0,
    "mmlu": 25.53,
    "average": 28.64
  },
  "postbot/emailgen-pythia-410m-deduped": {
    "arc": 27.9,
    "hellaswag": 40.04,
    "truthfulqa": 38.2,
    "winogrande": 52.09,
    "gsm8k": 0,
    "mmlu": 27.35,
    "average": 30.93
  },
  "postbot/gpt2-medium-emailgen": {
    "arc": 26.45,
    "hellaswag": 34.31,
    "truthfulqa": 43.96,
    "winogrande": 50.43,
    "gsm8k": 0,
    "mmlu": 24.1,
    "average": 29.88
  },
  "postbot/pythia-160m-hq-emails": {
    "arc": 23.12,
    "hellaswag": 30.05,
    "truthfulqa": 45.51,
    "winogrande": 50.28,
    "gsm8k": 0,
    "mmlu": 26.58,
    "average": 29.26
  },
  "princeton-nlp/Sheared-LLaMA-1.3B": {
    "arc": 32.85,
    "hellaswag": 60.91,
    "truthfulqa": 37.14,
    "mmlu": 25.71,
    "gsm8k": 0.45,
    "winogrande": 58.64,
    "average": 35.95
  },
  "princeton-nlp/Sheared-LLaMA-2.7B": {
    "arc": 41.72,
    "hellaswag": 71.01,
    "truthfulqa": 37.32,
    "mmlu": 26.92,
    "gsm8k": 1.06,
    "winogrande": 67.01,
    "average": 40.84
  },
  "prithivida/Asimov-7B-v1": {
    "arc": 59.04,
    "hellaswag": 80.04,
    "truthfulqa": 51.15,
    "winogrande": 73.95,
    "gsm8k": 9.33,
    "mmlu": 56.35,
    "average": 54.98
  },
  "prithivida/Asimov-7B-v2": {
    "arc": 54.27,
    "hellaswag": 78.72,
    "truthfulqa": 45.44,
    "winogrande": 71.82,
    "gsm8k": 10.92,
    "mmlu": 52.59,
    "average": 52.29
  },
  "project-baize/baize-healthcare-lora-7B": {
    "arc": 54.1,
    "hellaswag": 77.32,
    "truthfulqa": 39.96,
    "mmlu": 37.09,
    "gsm8k": 4.4,
    "winogrande": 72.85,
    "average": 47.62
  },
  "project-baize/baize-v2-13b": {
    "arc": 56.91,
    "hellaswag": 79.29,
    "truthfulqa": 47.88,
    "mmlu": 49.72,
    "gsm8k": 8.95,
    "winogrande": 74.9,
    "average": 52.94
  },
  "project-baize/baize-v2-7b": {
    "arc": 48.98,
    "hellaswag": 75.06,
    "truthfulqa": 41.39,
    "mmlu": 39.6,
    "gsm8k": 4.17,
    "winogrande": 71.11,
    "average": 46.72
  },
  "psmathur/model_007": {
    "arc": 71.08,
    "hellaswag": 87.65,
    "truthfulqa": 63.12,
    "mmlu": 69.04,
    "gsm8k": 37.15,
    "winogrande": 83.35,
    "average": 68.57
  },
  "psmathur/model_007_13b": {},
  "psmathur/model_007_13b_v2": {
    "arc": 61.95,
    "hellaswag": 82.48,
    "truthfulqa": 53.5,
    "mmlu": 57.32,
    "gsm8k": 1.36,
    "winogrande": 75.85,
    "average": 55.41
  },
  "psmathur/model_007_v2": {
    "arc": 71.42,
    "hellaswag": 87.31,
    "truthfulqa": 62.65,
    "mmlu": 68.58,
    "gsm8k": 28.66,
    "winogrande": 84.14,
    "average": 67.13
  },
  "psmathur/model_009": {
    "arc": 71.59,
    "hellaswag": 87.7,
    "truthfulqa": 60.72,
    "mmlu": 69.43,
    "gsm8k": 39.42,
    "winogrande": 82.32,
    "average": 68.53
  },
  "psmathur/model_101": {
    "arc": 68.69,
    "hellaswag": 86.42,
    "truthfulqa": 58.85,
    "mmlu": 69.92,
    "gsm8k": 44.81,
    "winogrande": 82.08,
    "average": 68.46
  },
  "psmathur/model_420": {
    "arc": 70.14,
    "hellaswag": 87.73,
    "truthfulqa": 54,
    "mmlu": 70.35,
    "gsm8k": 28.58,
    "winogrande": 83.74,
    "average": 65.76
  },
  "psmathur/model_420_preview": {
    "arc": 67.06,
    "hellaswag": 87.26,
    "truthfulqa": 44.57,
    "mmlu": 69.85,
    "gsm8k": 33.21,
    "winogrande": 83.35,
    "average": 64.22
  },
  "psmathur/model_42_70b": {
    "arc": 68.26,
    "hellaswag": 87.65,
    "truthfulqa": 48.76,
    "mmlu": 70,
    "gsm8k": 34.72,
    "winogrande": 83.66,
    "average": 65.51
  },
  "psmathur/model_51": {
    "arc": 68.43,
    "hellaswag": 86.71,
    "truthfulqa": 57.18,
    "mmlu": 69.31,
    "gsm8k": 32.37,
    "winogrande": 81.77,
    "average": 65.96
  },
  "psmathur/orca_mini_13b": {
    "arc": 42.06,
    "hellaswag": 63.4,
    "truthfulqa": 43.1,
    "mmlu": 35.43,
    "gsm8k": 0,
    "winogrande": 64.17,
    "average": 41.36
  },
  "psmathur/orca_mini_3b": {
    "arc": 41.55,
    "hellaswag": 61.52,
    "truthfulqa": 42.42,
    "mmlu": 26.79,
    "gsm8k": 0.08,
    "winogrande": 61.8,
    "average": 39.03
  },
  "psmathur/orca_mini_7b": {
    "arc": 43.94,
    "hellaswag": 65.22,
    "truthfulqa": 42.03,
    "mmlu": 29.97,
    "gsm8k": 0.38,
    "winogrande": 66.06,
    "average": 41.27
  },
  "psmathur/orca_mini_v2_13b": {
    "arc": 55.29,
    "hellaswag": 79.62,
    "truthfulqa": 52.58,
    "mmlu": 49.83,
    "gsm8k": 6.37,
    "winogrande": 72.69,
    "average": 52.73
  },
  "psmathur/orca_mini_v2_7b": {
    "arc": 50.77,
    "hellaswag": 76.02,
    "truthfulqa": 43.86,
    "mmlu": 39.5,
    "gsm8k": 2.88,
    "winogrande": 71.43,
    "average": 47.41
  },
  "psmathur/orca_mini_v3_13b": {
    "arc": 63.14,
    "hellaswag": 82.35,
    "truthfulqa": 51.81,
    "mmlu": 56.52,
    "gsm8k": 13.12,
    "winogrande": 76.48,
    "average": 57.24
  },
  "psmathur/orca_mini_v3_70b": {
    "arc": 71.25,
    "hellaswag": 87.85,
    "truthfulqa": 61.27,
    "mmlu": 70.18,
    "gsm8k": 40.86,
    "winogrande": 82.72,
    "average": 69.02
  },
  "psmathur/orca_mini_v3_7b": {
    "arc": 56.91,
    "hellaswag": 79.64,
    "truthfulqa": 50.51,
    "mmlu": 52.37,
    "gsm8k": 7.13,
    "winogrande": 74.27,
    "average": 53.47
  },
  "psmathur/test_42_70b": {
    "arc": 68.26,
    "hellaswag": 87.65,
    "truthfulqa": 48.76,
    "mmlu": 70,
    "gsm8k": 45.94,
    "winogrande": 83.66,
    "average": 67.38
  },
  "psyche/kogpt": {
    "arc": 21.16,
    "hellaswag": 28.11,
    "truthfulqa": 42.06,
    "mmlu": 26.56,
    "gsm8k": 0,
    "winogrande": 49.09,
    "average": 27.83
  },
  "psyche/kollama2-7b": {
    "arc": 53.24,
    "hellaswag": 78.78,
    "truthfulqa": 44.56,
    "mmlu": 42.31,
    "gsm8k": 5.99,
    "winogrande": 73.95,
    "average": 49.81
  },
  "psyche/kollama2-7b-v2": {
    "arc": 53.33,
    "hellaswag": 78.5,
    "truthfulqa": 46.37,
    "mmlu": 43.61,
    "gsm8k": 6.52,
    "winogrande": 75.61,
    "average": 50.66
  },
  "psyche/kollama2-7b-v3": {
    "arc": 49.74,
    "hellaswag": 78.45,
    "truthfulqa": 42.92,
    "mmlu": 40.41
  },
  "pszemraj/distilgpt2-HC3": {
    "arc": 24.66,
    "hellaswag": 27.99,
    "truthfulqa": 42.1,
    "winogrande": 50.36,
    "gsm8k": 0,
    "mmlu": 23.95,
    "average": 28.18
  },
  "pszemraj/pythia-31m-KI_v1-2048-scratch": {
    "arc": 23.12,
    "hellaswag": 25.23,
    "truthfulqa": 51.67,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 51.78,
    "average": 29.15
  },
  "pszemraj/pythia-31m-goodwiki-deduped-2048-scratch": {
    "arc": 23.12,
    "hellaswag": 25.66,
    "truthfulqa": 51.32,
    "mmlu": 23.11,
    "gsm8k": 0,
    "winogrande": 49.88,
    "average": 28.85
  },
  "pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e": {
    "arc": 21.59,
    "hellaswag": 25.79,
    "truthfulqa": 50.62,
    "mmlu": 24.99,
    "gsm8k": 0,
    "winogrande": 48.62,
    "average": 28.6
  },
  "pszemraj/pythia-31m-simplewiki-2048": {
    "arc": 22.18,
    "hellaswag": 25.55,
    "truthfulqa": 49.37,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 49.41,
    "average": 28.27
  },
  "pszemraj/pythia-31m-simplewiki-scratch-bf16": {
    "arc": 22.78,
    "hellaswag": 25.61,
    "truthfulqa": 49.65,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 50.51,
    "average": 28.61
  },
  "pszemraj/pythia-6.9b-HC3": {
    "arc": 36.52,
    "hellaswag": 61.76,
    "truthfulqa": 45.05,
    "mmlu": 26.94,
    "gsm8k": 0,
    "winogrande": 60.77,
    "average": 38.51
  },
  "pythainlp/wangchanglm-7.5B-sft-en-sharded": {
    "arc": 34.47,
    "hellaswag": 59.81,
    "truthfulqa": 34.15,
    "mmlu": 26.37,
    "gsm8k": 0.23,
    "winogrande": 58.25,
    "average": 35.55
  },
  "pythainlp/wangchanglm-7.5B-sft-enth": {
    "arc": 33.79,
    "hellaswag": 58.99,
    "truthfulqa": 34.9,
    "mmlu": 24.52,
    "gsm8k": 0.53,
    "winogrande": 57.93,
    "average": 35.11
  },
  "qblocks/falcon_7b_norobots": {
    "arc": 47.87,
    "hellaswag": 77.92,
    "truthfulqa": 36.81,
    "winogrande": 71.74,
    "gsm8k": 4.47,
    "mmlu": 27.94,
    "average": 44.46
  },
  "qblocks/mistral_7b_norobots": {
    "arc": 58.96,
    "hellaswag": 80.57,
    "truthfulqa": 41.91,
    "winogrande": 75.61,
    "gsm8k": 38.36,
    "mmlu": 57.66,
    "average": 58.85
  },
  "qblocks/zephyr_7b_norobots": {
    "arc": 56.48,
    "hellaswag": 79.64,
    "truthfulqa": 44.6,
    "winogrande": 74.11,
    "gsm8k": 20.62,
    "mmlu": 55.52,
    "average": 55.16
  },
  "qiyinmiss/My_GPT2": {
    "arc": 21.93,
    "hellaswag": 31.59,
    "truthfulqa": 40.73,
    "winogrande": 50.51,
    "gsm8k": 0.68,
    "mmlu": 25.84,
    "average": 28.55
  },
  "qualis2006/llama-2-7b-int4-python-code-18k": {
    "arc": 52.13,
    "hellaswag": 78.55,
    "truthfulqa": 37.69,
    "mmlu": 46.25,
    "gsm8k": 6.22,
    "winogrande": 74.98,
    "average": 49.3
  },
  "quantumaikr/KoreanLM-hf": {
    "arc": 51.45,
    "hellaswag": 76.77,
    "truthfulqa": 44.34,
    "mmlu": 40.61,
    "gsm8k": 3.41,
    "winogrande": 69.77,
    "average": 47.73
  },
  "quantumaikr/QuantumLM": {
    "arc": 55.8,
    "hellaswag": 79.74,
    "truthfulqa": 46.71,
    "mmlu": 54.17,
    "gsm8k": 9.86,
    "winogrande": 74.19,
    "average": 53.41
  },
  "quantumaikr/QuantumLM-70B-hf": {
    "arc": 59.47,
    "hellaswag": 83.02,
    "truthfulqa": 53.39,
    "mmlu": 62.25,
    "gsm8k": 14.78,
    "winogrande": 78.77,
    "average": 58.61
  },
  "quantumaikr/QuantumLM-7B": {
    "arc": 50.26,
    "hellaswag": 76.1,
    "truthfulqa": 46.25,
    "mmlu": 45.27,
    "gsm8k": 7.66,
    "winogrande": 71.51,
    "average": 49.51
  },
  "quantumaikr/QuantumLM-llama2-70B-Korean-LoRA": {
    "arc": 70.56,
    "hellaswag": 86.39,
    "truthfulqa": 56.08,
    "mmlu": 69.41
  },
  "quantumaikr/llama-2-70B-chat": {
    "arc": 67.58,
    "hellaswag": 86.94,
    "truthfulqa": 57.31,
    "mmlu": 69.18
  },
  "quantumaikr/llama-2-70b-fb16-guanaco-1k": {
    "arc": 70.48,
    "hellaswag": 87.33,
    "truthfulqa": 57.56,
    "mmlu": 70.25
  },
  "quantumaikr/llama-2-70b-fb16-korean": {
    "arc": 67.15,
    "hellaswag": 86.78,
    "truthfulqa": 56.5,
    "mmlu": 69.29,
    "gsm8k": 29.04,
    "winogrande": 82.64,
    "average": 65.23
  },
  "quantumaikr/llama-2-70b-fb16-orca-chat-10k": {
    "arc": 68.09,
    "hellaswag": 87.07,
    "truthfulqa": 61.56,
    "mmlu": 69.21,
    "gsm8k": 26.91,
    "winogrande": 84.14,
    "average": 66.16
  },
  "quantumaikr/llama-2-7b-hf-guanaco-1k": {
    "arc": 51.62,
    "hellaswag": 76.73,
    "truthfulqa": 44.79,
    "mmlu": 47.45,
    "gsm8k": 7.43,
    "winogrande": 72.77,
    "average": 50.13
  },
  "quantumaikr/open_llama_7b_hf": {
    "arc": 26.45,
    "hellaswag": 26.95,
    "truthfulqa": 49.54,
    "mmlu": 26.54
  },
  "quantumaikr/quantumairk-llama-2-70B-instruct": {
    "arc": 70.31,
    "hellaswag": 87.05,
    "truthfulqa": 54.42,
    "mmlu": 70.46
  },
  "radm/Philosophy-Platypus2-13b": {
    "arc": 58.62,
    "hellaswag": 78.52,
    "truthfulqa": 37.34,
    "mmlu": 54.3
  },
  "rameshm/llama-2-13b-mathgpt-v4": {
    "arc": 50.94,
    "hellaswag": 75.56,
    "truthfulqa": 41.96,
    "mmlu": 43.78,
    "gsm8k": 14.71,
    "winogrande": 69.14,
    "average": 49.35
  },
  "revolutionarybukhari/Llama-2-7b-chat-finetune-AUTOMATE": {
    "arc": 53.07,
    "hellaswag": 75.59,
    "truthfulqa": 44.73,
    "winogrande": 73.24,
    "gsm8k": 8.64,
    "mmlu": 48.8,
    "average": 50.68
  },
  "rinna/bilingual-gpt-neox-4b": {
    "arc": 29.18,
    "hellaswag": 43.73,
    "truthfulqa": 45,
    "mmlu": 23.1,
    "gsm8k": 0,
    "winogrande": 51.85,
    "average": 32.14
  },
  "rinna/bilingual-gpt-neox-4b-8k": {
    "arc": 28.58,
    "hellaswag": 43.94,
    "truthfulqa": 47.48,
    "mmlu": 25.38,
    "gsm8k": 0,
    "winogrande": 47.99,
    "average": 32.23
  },
  "rinna/bilingual-gpt-neox-4b-instruction-sft": {
    "arc": 28.07,
    "hellaswag": 47.5,
    "truthfulqa": 43.76,
    "winogrande": 52.33,
    "gsm8k": 0,
    "mmlu": 23.12,
    "average": 32.46
  },
  "rinna/youri-7b": {
    "arc": 49.06,
    "hellaswag": 74.89,
    "truthfulqa": 36.03,
    "winogrande": 71.82,
    "gsm8k": 8.64,
    "mmlu": 42.22,
    "average": 47.11
  },
  "rinna/youri-7b-chat": {
    "arc": 51.19,
    "hellaswag": 76.09,
    "truthfulqa": 41.17,
    "winogrande": 75.06,
    "gsm8k": 1.36,
    "mmlu": 46.06,
    "average": 48.49
  },
  "rinna/youri-7b-instruction": {
    "gsm8k": 0
  },
  "rishiraj/bloom-560m-guanaco": {
    "arc": 27.9,
    "hellaswag": 26.11,
    "truthfulqa": 49.37,
    "mmlu": 24.46
  },
  "rishiraj/smol-7b": {
    "arc": 63.74,
    "hellaswag": 84.77,
    "truthfulqa": 46.17,
    "winogrande": 80.66,
    "gsm8k": 62.32,
    "mmlu": 65,
    "average": 67.11
  },
  "robowaifudev/megatron-gpt2-345m": {
    "arc": 24.23,
    "hellaswag": 39.18,
    "truthfulqa": 41.51,
    "mmlu": 24.32,
    "gsm8k": 0.23,
    "winogrande": 52.96,
    "average": 30.4
  },
  "rombodawg/LosslessMegaCoder-llama2-13b-mini": {
    "arc": 60.58,
    "hellaswag": 81.26,
    "truthfulqa": 48.89,
    "mmlu": 57.92,
    "gsm8k": 15.92,
    "winogrande": 76.95,
    "average": 56.92
  },
  "rombodawg/LosslessMegaCoder-llama2-7b-mini": {
    "arc": 53.5,
    "hellaswag": 77.38,
    "truthfulqa": 45.77,
    "mmlu": 49.72,
    "gsm8k": 9.55,
    "winogrande": 74.03,
    "average": 51.66
  },
  "roneneldan/TinyStories-1M": {
    "arc": 23.46,
    "hellaswag": 25.23,
    "truthfulqa": 49.4,
    "mmlu": 24.57,
    "gsm8k": 0,
    "winogrande": 52.17,
    "average": 29.14
  },
  "roneneldan/TinyStories-28M": {
    "arc": 22.78,
    "hellaswag": 25.83,
    "truthfulqa": 48.08,
    "mmlu": 23.53,
    "gsm8k": 0,
    "winogrande": 50.43,
    "average": 28.44
  },
  "roneneldan/TinyStories-33M": {
    "arc": 24.23,
    "hellaswag": 25.69,
    "truthfulqa": 47.64,
    "mmlu": 23.82,
    "gsm8k": 0,
    "winogrande": 49.09,
    "average": 28.41
  },
  "roneneldan/TinyStories-3M": {
    "arc": 22.01,
    "hellaswag": 25.58,
    "truthfulqa": 47.33,
    "mmlu": 24.99,
    "gsm8k": 0,
    "winogrande": 49.25,
    "average": 28.19
  },
  "roneneldan/TinyStories-8M": {
    "arc": 24.66,
    "hellaswag": 25.03,
    "truthfulqa": 46.54,
    "mmlu": 23.33,
    "gsm8k": 0,
    "winogrande": 50.28,
    "average": 28.31
  },
  "royallab/Pygmalion-2-13b-SuperCOT": {
    "arc": 63.23,
    "hellaswag": 83.68,
    "truthfulqa": 53.14,
    "mmlu": 54.9,
    "gsm8k": 6.29,
    "winogrande": 77.51,
    "average": 56.46
  },
  "rufjdk5480/llama-7b-ludwig-alpaca": {
    "arc": 54.01,
    "hellaswag": 78.73,
    "truthfulqa": 41.91,
    "winogrande": 74.27,
    "gsm8k": 14.86,
    "mmlu": 45.8,
    "average": 51.6
  },
  "s1ghhh/medllama-2-70b-qlora-1.1": {
    "arc": 69.03,
    "hellaswag": 87.17,
    "truthfulqa": 52.41,
    "mmlu": 71.04,
    "gsm8k": 32.07,
    "winogrande": 84.21,
    "average": 65.99
  },
  "sartmis1/starcoder-finetune-openapi": {
    "arc": 30.63,
    "hellaswag": 48.09,
    "truthfulqa": 41.77,
    "mmlu": 30.4
  },
  "sartmis1/starcoder-finetune-selfinstruct": {
    "arc": 31.23,
    "hellaswag": 47.66,
    "truthfulqa": 41.63,
    "mmlu": 29.52,
    "gsm8k": 6.07,
    "winogrande": 57.77,
    "average": 35.65
  },
  "sauce1337/AppleSauce-L2-13b": {
    "arc": 61.01,
    "hellaswag": 83.61,
    "truthfulqa": 47.81,
    "mmlu": 57.07,
    "gsm8k": 10.01,
    "winogrande": 75.93,
    "average": 55.91
  },
  "sauce1337/BerrySauce-L2-13b": {
    "arc": 62.29,
    "hellaswag": 83.78,
    "truthfulqa": 48.3,
    "mmlu": 57.1,
    "gsm8k": 11.75,
    "winogrande": 76.09,
    "average": 56.55
  },
  "sequelbox/DaringFortitude": {
    "arc": 63.48,
    "hellaswag": 83.56,
    "truthfulqa": 55.96,
    "winogrande": 76.48,
    "gsm8k": 8.79,
    "mmlu": 59.81,
    "average": 58.01
  },
  "sequelbox/SharpBalance": {
    "arc": 69.28,
    "hellaswag": 87.59,
    "truthfulqa": 59.05,
    "mmlu": 69.51,
    "gsm8k": 34.65,
    "winogrande": 84.06,
    "average": 67.36
  },
  "sequelbox/StellarBright": {
    "arc": 72.95,
    "hellaswag": 87.82,
    "truthfulqa": 64.46,
    "mmlu": 71.17,
    "gsm8k": 39.5,
    "winogrande": 83.27,
    "average": 69.86
  },
  "shaohang/Sparse0.5_OPT-1.3": {
    "arc": 27.13,
    "hellaswag": 48.69,
    "truthfulqa": 39.11,
    "mmlu": 25.6,
    "gsm8k": 0.08,
    "winogrande": 58.56,
    "average": 33.2
  },
  "shaohang/SparseOPT-1.3B": {
    "arc": 27.13,
    "hellaswag": 48.69,
    "truthfulqa": 39.11,
    "mmlu": 25.6,
    "gsm8k": 0.08,
    "winogrande": 58.56,
    "average": 33.2
  },
  "shareAI/CodeLLaMA-chat-13b-Chinese": {
    "arc": 43.26,
    "hellaswag": 63.87,
    "truthfulqa": 48.97,
    "mmlu": 34.29,
    "gsm8k": 10.77,
    "winogrande": 67.88,
    "average": 44.84
  },
  "shareAI/bimoGPT-llama2-13b": {
    "arc": 58.79,
    "hellaswag": 82.08,
    "truthfulqa": 37.82,
    "mmlu": 55.6,
    "gsm8k": 11.3,
    "winogrande": 76.48,
    "average": 53.68
  },
  "shareAI/llama2-13b-Chinese-chat": {
    "arc": 60.58,
    "hellaswag": 82.19,
    "truthfulqa": 45.11,
    "mmlu": 55.45,
    "gsm8k": 11.37,
    "winogrande": 76.64,
    "average": 55.22
  },
  "shibing624/chinese-alpaca-plus-13b-hf": {
    "arc": 53.16,
    "hellaswag": 73.51,
    "truthfulqa": 45.32,
    "mmlu": 48.81,
    "gsm8k": 2.12,
    "winogrande": 75.06,
    "average": 49.66
  },
  "shibing624/chinese-alpaca-plus-7b-hf": {
    "arc": 49.23,
    "hellaswag": 70.48,
    "truthfulqa": 39.72,
    "mmlu": 38.39,
    "gsm8k": 0.68,
    "winogrande": 70.09,
    "average": 44.77
  },
  "shibing624/chinese-llama-plus-13b-hf": {
    "arc": 46.25,
    "hellaswag": 71.88,
    "truthfulqa": 39.89,
    "mmlu": 40.74,
    "gsm8k": 0.53,
    "winogrande": 73.09,
    "average": 45.4
  },
  "sia-ai/llama-2-7b-1-percent-open-orca-1000-steps-v0": {
    "arc": 51.28,
    "hellaswag": 78.75,
    "truthfulqa": 45.83,
    "mmlu": 44.68,
    "gsm8k": 2.73,
    "winogrande": 74.11,
    "average": 49.56
  },
  "simonveitner/MathHermes-2.5-Mistral-7B": {
    "arc": 64.76,
    "hellaswag": 84.19,
    "truthfulqa": 51.95,
    "winogrande": 77.66,
    "gsm8k": 49.28,
    "mmlu": 63.59,
    "average": 65.24
  },
  "simsim314/WizardLM-70B-V1.0-HF": {
    "arc": 65.44,
    "hellaswag": 84.41,
    "truthfulqa": 54.81,
    "mmlu": 64.05
  },
  "souvik0306/falcon_7b_3epoch_norobots": {
    "arc": 47.61,
    "hellaswag": 77.24,
    "truthfulqa": 36.27,
    "winogrande": 69.53,
    "gsm8k": 1.52,
    "mmlu": 29.73,
    "average": 43.65
  },
  "souvik0306/mistral_7b_2epoch_norobots": {
    "arc": 61.01,
    "hellaswag": 83.37,
    "truthfulqa": 42.62,
    "winogrande": 79.08,
    "gsm8k": 16.98,
    "mmlu": 63.96,
    "average": 57.84
  },
  "speechlessai/speechless-codellama-34b-v1.0": {
    "arc": 52.47,
    "hellaswag": 74.13,
    "truthfulqa": 47.14,
    "mmlu": 53.47,
    "gsm8k": 14.71,
    "winogrande": 73.24,
    "average": 52.53
  },
  "speechlessai/speechless-codellama-airoboros-orca-platypus-13b": {
    "arc": 44.88,
    "hellaswag": 67.7,
    "truthfulqa": 40.88,
    "mmlu": 43.16,
    "gsm8k": 1.82,
    "winogrande": 66.14,
    "average": 44.1
  },
  "speechlessai/speechless-codellama-dolphin-orca-platypus-13b": {
    "arc": 45.82,
    "hellaswag": 67.71,
    "truthfulqa": 44.67,
    "mmlu": 45.88,
    "gsm8k": 8.49,
    "winogrande": 65.35,
    "average": 46.32
  },
  "speechlessai/speechless-coding-7b-16k-tora": {
    "arc": 41.13,
    "hellaswag": 64.48,
    "truthfulqa": 44.95,
    "winogrande": 63.85,
    "gsm8k": 17.06,
    "mmlu": 38.86,
    "average": 45.06
  },
  "speechlessai/speechless-llama2-dolphin-orca-platypus-13b": {
    "arc": 59.64,
    "hellaswag": 82.65,
    "truthfulqa": 43.44,
    "mmlu": 57.9,
    "gsm8k": 9.7,
    "winogrande": 77.19,
    "average": 55.09
  },
  "speechlessai/speechless-mistral-7b-dare-0.85": {
    "arc": 63.31,
    "hellaswag": 84.93,
    "truthfulqa": 50.68,
    "winogrande": 79.32,
    "gsm8k": 19.86,
    "mmlu": 64.22,
    "average": 60.39
  },
  "stabilityai/StableBeluga-13B": {
    "arc": 62.03,
    "hellaswag": 82.27,
    "truthfulqa": 49.61,
    "mmlu": 57.71,
    "gsm8k": 13.8,
    "winogrande": 76.87,
    "average": 57.05
  },
  "stabilityai/StableBeluga-7B": {
    "arc": 56.31,
    "hellaswag": 79.14,
    "truthfulqa": 50.19,
    "mmlu": 52.71,
    "gsm8k": 7.81,
    "winogrande": 75.22,
    "average": 53.56
  },
  "stabilityai/StableBeluga1-Delta": {
    "arc": 68.17,
    "hellaswag": 85.88,
    "truthfulqa": 55.81,
    "mmlu": 64.83,
    "gsm8k": 0,
    "winogrande": 49.8,
    "average": 54.08
  },
  "stabilityai/StableBeluga2": {
    "arc": 71.08,
    "hellaswag": 86.37,
    "truthfulqa": 59.44,
    "mmlu": 68.79,
    "gsm8k": 35.86,
    "winogrande": 82.95,
    "average": 67.42
  },
  "stabilityai/stablelm-3b-4e1t": {
    "arc": 46.59,
    "hellaswag": 75.94,
    "truthfulqa": 37.2,
    "mmlu": 45.23,
    "gsm8k": 3.34,
    "winogrande": 71.19,
    "average": 46.58
  },
  "stabilityai/stablelm-base-alpha-3b": {
    "arc": 26.45,
    "hellaswag": 42.24,
    "truthfulqa": 40.5,
    "mmlu": 25.43,
    "gsm8k": 0.45,
    "winogrande": 53.91,
    "average": 31.5
  },
  "stabilityai/stablelm-base-alpha-7b": {
    "arc": 32,
    "hellaswag": 51.78,
    "truthfulqa": 40.19,
    "mmlu": 26.21,
    "gsm8k": 0.61,
    "winogrande": 55.41,
    "average": 34.37
  },
  "stabilityai/stablelm-base-alpha-7b-v2": {
    "arc": 47.35,
    "hellaswag": 77.08,
    "truthfulqa": 36.46,
    "mmlu": 45.1,
    "gsm8k": 2.58,
    "winogrande": 68.51,
    "average": 46.18
  },
  "stabilityai/stablelm-tuned-alpha-3b": {
    "arc": 27.82,
    "hellaswag": 44.06,
    "truthfulqa": 42.33,
    "mmlu": 23.08,
    "gsm8k": 0.53,
    "winogrande": 55.01,
    "average": 32.14
  },
  "stabilityai/stablelm-tuned-alpha-7b": {
    "arc": 31.91,
    "hellaswag": 53.59,
    "truthfulqa": 40.37,
    "mmlu": 24.41,
    "gsm8k": 0.83,
    "winogrande": 53.12,
    "average": 34.04
  },
  "starmpcc/Asclepius-Llama2-13B": {
    "arc": 55.89,
    "hellaswag": 79.66,
    "truthfulqa": 40.76,
    "winogrande": 72.69,
    "gsm8k": 0.15,
    "mmlu": 52.38,
    "average": 50.26
  },
  "starmpcc/Asclepius-Llama2-7B": {
    "arc": 50.85,
    "hellaswag": 76.53,
    "truthfulqa": 43.31,
    "winogrande": 68.27,
    "gsm8k": 0.3,
    "mmlu": 43.61,
    "average": 47.15
  },
  "synapsoft/Llama-2-7b-chat-hf-flan2022-1.2M": {
    "arc": 49.57,
    "hellaswag": 76.25,
    "truthfulqa": 42.17,
    "mmlu": 45.99,
    "gsm8k": 1.52,
    "winogrande": 71.82,
    "average": 47.89
  },
  "synapsoft/Llama-2-7b-hf-flan2022-1.2M": {
    "arc": 23.29,
    "hellaswag": 78.46,
    "truthfulqa": 37.97,
    "mmlu": 42.33,
    "gsm8k": 4.47,
    "winogrande": 75.53,
    "average": 43.68
  },
  "team-lucid/mptk-1b": {
    "gsm8k": 0,
    "winogrande": 49.72
  },
  "teknium/CollectiveCognition-v1-Mistral-7B": {
    "arc": 62.37,
    "hellaswag": 85.5,
    "truthfulqa": 54.48,
    "mmlu": 62.76,
    "gsm8k": 17.89,
    "winogrande": 77.58,
    "average": 60.1
  },
  "teknium/CollectiveCognition-v1.1-Mistral-7B": {
    "arc": 62.54,
    "hellaswag": 84.13,
    "truthfulqa": 57.61,
    "mmlu": 62.57,
    "gsm8k": 35.86,
    "winogrande": 75.37,
    "average": 63.01
  },
  "teknium/Mistral-Trismegistus-7B": {
    "arc": 54.1,
    "hellaswag": 77.91,
    "truthfulqa": 49.36,
    "mmlu": 54.49,
    "gsm8k": 9.93,
    "winogrande": 70.17,
    "average": 52.66
  },
  "teknium/OpenHermes-13B": {
    "arc": 60.15,
    "hellaswag": 82.18,
    "truthfulqa": 45.98,
    "mmlu": 56.19,
    "gsm8k": 11.6,
    "winogrande": 75.45,
    "average": 55.26
  },
  "teknium/OpenHermes-2-Mistral-7B": {
    "arc": 63.05,
    "hellaswag": 83.81,
    "truthfulqa": 50.24,
    "mmlu": 63.46
  },
  "teknium/OpenHermes-2.5-Mistral-7B": {
    "arc": 64.93,
    "hellaswag": 84.18,
    "truthfulqa": 52.24,
    "winogrande": 78.06,
    "gsm8k": 26.08,
    "mmlu": 63.64,
    "average": 61.52
  },
  "teknium/OpenHermes-7B": {
    "arc": 56.14,
    "hellaswag": 78.32,
    "truthfulqa": 45,
    "mmlu": 48.62,
    "gsm8k": 5,
    "winogrande": 74.51,
    "average": 51.26
  },
  "tianlinliu0121/zephyr-7b-dpo-full-beta-0.2": {
    "arc": 61.77,
    "hellaswag": 84.04,
    "truthfulqa": 54.72,
    "winogrande": 76.95,
    "gsm8k": 30.02,
    "mmlu": 61.79,
    "average": 61.55
  },
  "tianyil1/denas-llama2": {
    "arc": 53.92,
    "hellaswag": 77.83,
    "truthfulqa": 45.24,
    "mmlu": 45.5
  },
  "tiiuae/falcon-180B": {
    "arc": 69.2,
    "hellaswag": 88.89,
    "truthfulqa": 45.16,
    "mmlu": 69.59,
    "gsm8k": 45.94,
    "winogrande": 86.9,
    "average": 67.61
  },
  "tiiuae/falcon-180B-chat": {
    "arc": 64.42,
    "hellaswag": 88.04,
    "truthfulqa": 53.69,
    "mmlu": 68.03
  },
  "tiiuae/falcon-40b": {
    "gsm8k": 21.46,
    "winogrande": 81.29,
    "arc": 61.95,
    "hellaswag": 85.28,
    "truthfulqa": 41.72,
    "mmlu": 56.98,
    "average": 58.11
  },
  "tiiuae/falcon-40b-instruct": {
    "arc": 61.6,
    "hellaswag": 84.31,
    "truthfulqa": 52.52,
    "mmlu": 55.45,
    "gsm8k": 34.34,
    "winogrande": 79.79,
    "average": 61.34
  },
  "tiiuae/falcon-7b": {
    "arc": 47.87,
    "hellaswag": 78.13,
    "truthfulqa": 34.26,
    "mmlu": 27.79,
    "gsm8k": 4.62,
    "winogrande": 72.38,
    "average": 44.17
  },
  "tiiuae/falcon-7b-instruct": {
    "arc": 46.16,
    "hellaswag": 70.85,
    "truthfulqa": 44.08,
    "mmlu": 25.84,
    "gsm8k": 4.7,
    "winogrande": 67.96,
    "average": 43.26
  },
  "tiiuae/falcon-rw-1b": {
    "arc": 35.07,
    "hellaswag": 63.56,
    "truthfulqa": 35.96,
    "mmlu": 25.28,
    "gsm8k": 0.53,
    "winogrande": 62.04,
    "average": 37.07
  },
  "timdettmers/guanaco-33b-merged": {
    "arc": 62.46,
    "hellaswag": 84.48,
    "truthfulqa": 51.22,
    "mmlu": 53.78
  },
  "timdettmers/guanaco-65b-merged": {
    "arc": 27.47,
    "hellaswag": 26.6,
    "truthfulqa": 48.41,
    "mmlu": 25.17
  },
  "titan087/OpenLlama13B-Guanaco": {
    "arc": 51.19,
    "hellaswag": 75.24,
    "truthfulqa": 38.4,
    "mmlu": 43.76,
    "gsm8k": 7.58,
    "winogrande": 71.74,
    "average": 47.98
  },
  "tlphams/zoyllm-7b-slimorca": {
    "arc": 50.6,
    "hellaswag": 72.12,
    "truthfulqa": 49.13,
    "winogrande": 67.32,
    "gsm8k": 20.7,
    "mmlu": 48.78,
    "average": 51.44
  },
  "togethercomputer/GPT-JT-6B-v0": {
    "arc": 42.06,
    "hellaswag": 67.96,
    "truthfulqa": 38.89,
    "mmlu": 49.34,
    "gsm8k": 1.21,
    "winogrande": 64.8,
    "average": 44.04
  },
  "togethercomputer/GPT-JT-6B-v1": {
    "arc": 40.87,
    "hellaswag": 67.15,
    "truthfulqa": 37.07,
    "mmlu": 47.19,
    "gsm8k": 1.21,
    "winogrande": 65.27,
    "average": 43.13
  },
  "togethercomputer/GPT-JT-Moderation-6B": {
    "arc": 40.53,
    "hellaswag": 67.66,
    "truthfulqa": 37.33,
    "mmlu": 41.63,
    "gsm8k": 0.99,
    "winogrande": 62.67,
    "average": 41.8
  },
  "togethercomputer/GPT-NeoXT-Chat-Base-20B": {
    "arc": 45.65,
    "hellaswag": 74.03,
    "truthfulqa": 34.51,
    "mmlu": 29.92,
    "gsm8k": 6.9,
    "winogrande": 67.09,
    "average": 43.02
  },
  "togethercomputer/LLaMA-2-7B-32K": {
    "arc": 47.53,
    "hellaswag": 76.14,
    "truthfulqa": 39.23,
    "mmlu": 43.33,
    "gsm8k": 4.32,
    "winogrande": 71.9,
    "average": 47.08
  },
  "togethercomputer/Llama-2-7B-32K-Instruct": {
    "arc": 51.37,
    "hellaswag": 78.47,
    "truthfulqa": 45.01,
    "mmlu": 45.53,
    "gsm8k": 4.7,
    "winogrande": 72.85,
    "average": 49.65
  },
  "togethercomputer/Pythia-Chat-Base-7B": {
    "arc": 40.02,
    "hellaswag": 68.67,
    "truthfulqa": 34.63,
    "mmlu": 27.44,
    "gsm8k": 4.09,
    "winogrande": 64.01,
    "average": 39.81
  },
  "togethercomputer/RedPajama-INCITE-7B-Base": {
    "arc": 46.25,
    "hellaswag": 71.63,
    "truthfulqa": 33.03,
    "mmlu": 27.68,
    "gsm8k": 3.03,
    "winogrande": 67.32,
    "average": 41.49
  },
  "togethercomputer/RedPajama-INCITE-7B-Chat": {
    "arc": 42.06,
    "hellaswag": 70.82,
    "truthfulqa": 36.09,
    "mmlu": 26.94,
    "gsm8k": 0.45,
    "winogrande": 59.83,
    "average": 39.37
  },
  "togethercomputer/RedPajama-INCITE-7B-Instruct": {
    "arc": 44.11,
    "hellaswag": 72.02,
    "truthfulqa": 33.96,
    "mmlu": 37.62,
    "gsm8k": 1.59,
    "winogrande": 64.96,
    "average": 42.38
  },
  "togethercomputer/RedPajama-INCITE-Base-3B-v1": {
    "arc": 40.19,
    "hellaswag": 64.77,
    "truthfulqa": 33.23,
    "mmlu": 27.03,
    "gsm8k": 1.29,
    "winogrande": 64.72,
    "average": 38.54
  },
  "togethercomputer/RedPajama-INCITE-Base-7B-v0.1": {
    "arc": 46.25,
    "hellaswag": 71.63,
    "truthfulqa": 33.03,
    "mmlu": 27.68,
    "gsm8k": 1.59,
    "winogrande": 67.32,
    "average": 41.25
  },
  "togethercomputer/RedPajama-INCITE-Chat-3B-v1": {
    "arc": 42.83,
    "hellaswag": 67.62,
    "truthfulqa": 34.44,
    "mmlu": 26.23,
    "gsm8k": 0.53,
    "winogrande": 65.51,
    "average": 39.53
  },
  "togethercomputer/RedPajama-INCITE-Chat-7B-v0.1": {
    "arc": 42.06,
    "hellaswag": 70.82,
    "truthfulqa": 36.09,
    "mmlu": 26.94,
    "gsm8k": 0.45,
    "winogrande": 59.83,
    "average": 39.37
  },
  "togethercomputer/RedPajama-INCITE-Instruct-3B-v1": {
    "arc": 41.55,
    "hellaswag": 65.48,
    "truthfulqa": 36.41,
    "mmlu": 25.03,
    "gsm8k": 1.36,
    "winogrande": 64.48,
    "average": 39.05
  },
  "togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1": {
    "arc": 44.11,
    "hellaswag": 72.02,
    "truthfulqa": 33.96,
    "mmlu": 37.62,
    "gsm8k": 1.59,
    "winogrande": 64.96,
    "average": 42.38
  },
  "totally-not-an-llm/EverythingLM-13b-16k": {
    "arc": 56.57,
    "hellaswag": 80.58,
    "truthfulqa": 47.46,
    "mmlu": 50.18,
    "gsm8k": 6.44,
    "winogrande": 72.77,
    "average": 52.33
  },
  "totally-not-an-llm/EverythingLM-13b-V2-16k": {
    "arc": 58.7,
    "hellaswag": 80.88,
    "truthfulqa": 47.37,
    "mmlu": 49.69,
    "gsm8k": 6.82,
    "winogrande": 73.01,
    "average": 52.75
  },
  "totally-not-an-llm/EverythingLM-13b-V3-16k": {
    "arc": 58.19,
    "hellaswag": 80.12,
    "truthfulqa": 45.18,
    "mmlu": 50.48,
    "gsm8k": 1.97,
    "winogrande": 70.72,
    "average": 51.11
  },
  "totally-not-an-llm/EverythingLM-13b-V3-peft": {
    "arc": 58.36,
    "hellaswag": 81.03,
    "truthfulqa": 52.98,
    "mmlu": 54.7,
    "gsm8k": 5.53,
    "winogrande": 72.85,
    "average": 54.24
  },
  "totally-not-an-llm/PuddleJumper-13b": {
    "arc": 58.7,
    "hellaswag": 81.18,
    "truthfulqa": 56.44,
    "mmlu": 58.25,
    "gsm8k": 3.34,
    "winogrande": 72.77,
    "average": 55.11
  },
  "totally-not-an-llm/PuddleJumper-13b-V2": {
    "arc": 57,
    "hellaswag": 81.06,
    "truthfulqa": 52.66,
    "mmlu": 58.3,
    "gsm8k": 3.64,
    "winogrande": 72.45,
    "average": 54.18
  },
  "u-chom/preded-title-amazongoogle-abtbuy": {
    "arc": 50.94,
    "hellaswag": 78.14,
    "truthfulqa": 41.65,
    "mmlu": 37.99
  },
  "uberkie/metharme-1.3b-finetuned": {
    "arc": 20.56,
    "hellaswag": 28.02,
    "truthfulqa": 44.8,
    "mmlu": 25.26
  },
  "unaidedelf87777/wizard-mistral-v0.1": {
    "arc": 61.77,
    "hellaswag": 83.51,
    "truthfulqa": 47.46,
    "mmlu": 63.99,
    "gsm8k": 19.03,
    "winogrande": 78.3,
    "average": 59.01
  },
  "uni-tianyan/Uni-TianYan": {
    "arc": 72.1,
    "hellaswag": 87.4,
    "truthfulqa": 65.81,
    "mmlu": 69.91,
    "gsm8k": 22.14,
    "winogrande": 82.32,
    "average": 66.61
  },
  "upstage/Llama-2-70b-instruct": {
    "arc": 70.9,
    "hellaswag": 87.48,
    "truthfulqa": 60.97,
    "mmlu": 69.8,
    "gsm8k": 32.22,
    "winogrande": 82.87,
    "average": 67.37
  },
  "upstage/Llama-2-70b-instruct-1024": {
    "gsm8k": 32.22,
    "winogrande": 82.87
  },
  "upstage/SOLAR-0-70b-16bit": {
    "arc": 71.08,
    "hellaswag": 87.89,
    "truthfulqa": 62.25,
    "mmlu": 70.58,
    "gsm8k": 45.26,
    "winogrande": 83.58,
    "average": 70.11
  },
  "upstage/llama-30b-instruct": {
    "arc": 62.46,
    "hellaswag": 86.23,
    "truthfulqa": 52.78,
    "mmlu": 59.37,
    "gsm8k": 12.13,
    "winogrande": 80.51,
    "average": 58.91
  },
  "upstage/llama-30b-instruct-2048": {
    "arc": 64.93,
    "hellaswag": 84.94,
    "truthfulqa": 56.3,
    "mmlu": 61.9,
    "gsm8k": 17.82,
    "winogrande": 79.56,
    "average": 60.91
  },
  "upstage/llama-65b-instruct": {
    "arc": 68.86,
    "hellaswag": 86.43,
    "truthfulqa": 59.7,
    "mmlu": 64.77,
    "gsm8k": 26.23,
    "winogrande": 81.06,
    "average": 64.51
  },
  "uukuguy/CollectiveCognition-v1.1-Mistral-7B-dare-0.85": {
    "arc": 61.01,
    "hellaswag": 84.31,
    "truthfulqa": 44.87,
    "winogrande": 78.85,
    "gsm8k": 18.95,
    "mmlu": 64.34,
    "average": 58.72
  },
  "uukuguy/Mistral-7B-OpenOrca-lora": {
    "arc": 61.95,
    "hellaswag": 83.62,
    "truthfulqa": 42.74,
    "winogrande": 79.08,
    "gsm8k": 17.29,
    "mmlu": 64.16,
    "average": 58.14
  },
  "uukuguy/Orca-2-13b-f16": {
    "arc": 60.67,
    "hellaswag": 79.81,
    "truthfulqa": 56.41,
    "winogrande": 76.64,
    "gsm8k": 38.97,
    "mmlu": 60.37,
    "average": 62.15
  },
  "uukuguy/Orca-2-7b-f16": {
    "arc": 29.61,
    "hellaswag": 25.62,
    "truthfulqa": 48.36,
    "winogrande": 50.59,
    "gsm8k": 0,
    "mmlu": 26.7,
    "average": 30.15
  },
  "uukuguy/SynthIA-7B-v1.3-dare-0.85": {
    "arc": 61.01,
    "hellaswag": 83.5,
    "truthfulqa": 43.77,
    "winogrande": 78.93,
    "gsm8k": 18.57,
    "mmlu": 64.49,
    "average": 58.38
  },
  "uukuguy/airoboros-m-7b-3.1.2-dare-0.85": {
    "arc": 61.09,
    "hellaswag": 83.57,
    "truthfulqa": 43.64,
    "winogrande": 78.37,
    "gsm8k": 17.44,
    "mmlu": 64.05,
    "average": 58.03
  },
  "uukuguy/speechless-code-mistral-7b-v1.0": {
    "arc": 60.58,
    "hellaswag": 83.75,
    "truthfulqa": 47.9,
    "mmlu": 62.98,
    "gsm8k": 19.18,
    "winogrande": 78.69,
    "average": 58.85
  },
  "uukuguy/speechless-code-mistral-orca-7b-v1.0": {
    "arc": 59.64,
    "hellaswag": 82.25,
    "truthfulqa": 48.45,
    "mmlu": 61.33,
    "gsm8k": 8.26,
    "winogrande": 77.51,
    "average": 56.24
  },
  "uukuguy/speechless-codellama-34b-v1.9": {
    "arc": 54.27,
    "hellaswag": 75.2,
    "truthfulqa": 43.92,
    "mmlu": 56.12,
    "gsm8k": 24.79,
    "winogrande": 73.56,
    "average": 54.64
  },
  "uukuguy/speechless-codellama-34b-v2.0": {
    "arc": 54.35,
    "hellaswag": 75.65,
    "truthfulqa": 45.21,
    "mmlu": 54.67,
    "gsm8k": 11.6,
    "winogrande": 73.56,
    "average": 52.51
  },
  "uukuguy/speechless-codellama-dolphin-orca-platypus-13b": {
    "arc": 44.8,
    "hellaswag": 68.6,
    "truthfulqa": 46.28,
    "mmlu": 44.03,
    "gsm8k": 9.55,
    "winogrande": 66.93,
    "average": 46.7
  },
  "uukuguy/speechless-codellama-dolphin-orca-platypus-34b": {
    "arc": 52.47,
    "hellaswag": 74.13,
    "truthfulqa": 47.14,
    "mmlu": 53.47,
    "gsm8k": 14.71,
    "winogrande": 73.24,
    "average": 52.53
  },
  "uukuguy/speechless-codellama-orca-13b": {
    "arc": 44.37,
    "hellaswag": 65.2,
    "truthfulqa": 45.94,
    "mmlu": 43.46,
    "gsm8k": 5.99,
    "winogrande": 64.01,
    "average": 44.83
  },
  "uukuguy/speechless-codellama-orca-airoboros-13b-0.10e": {
    "arc": 29.44,
    "hellaswag": 25.71,
    "truthfulqa": 49.64,
    "mmlu": 25.43,
    "gsm8k": 0,
    "winogrande": 51.93,
    "average": 30.36
  },
  "uukuguy/speechless-codellama-orca-platypus-13b-0.10e": {
    "arc": 28.75,
    "hellaswag": 25.88,
    "truthfulqa": 49.27,
    "mmlu": 25.36,
    "gsm8k": 0,
    "winogrande": 49.72,
    "average": 29.83
  },
  "uukuguy/speechless-codellama-platypus-13b": {
    "arc": 45.31,
    "hellaswag": 68.63,
    "truthfulqa": 42.38,
    "mmlu": 42.82,
    "gsm8k": 9.1,
    "winogrande": 65.59,
    "average": 45.64
  },
  "uukuguy/speechless-hermes-coig-lite-13b": {
    "arc": 59.56,
    "hellaswag": 82.26,
    "truthfulqa": 47.56,
    "mmlu": 55.3,
    "gsm8k": 9.86,
    "winogrande": 78.53,
    "average": 55.51
  },
  "uukuguy/speechless-llama2-13b": {
    "arc": 62.2,
    "hellaswag": 81.88,
    "truthfulqa": 55.62,
    "mmlu": 58.65,
    "gsm8k": 13.95,
    "winogrande": 76.56,
    "average": 58.14
  },
  "uukuguy/speechless-llama2-hermes-orca-platypus-13b": {
    "arc": 60.92,
    "hellaswag": 83.5,
    "truthfulqa": 54.29,
    "mmlu": 59.39,
    "gsm8k": 9.7,
    "winogrande": 75.22,
    "average": 57.17
  },
  "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b": {
    "arc": 59.56,
    "hellaswag": 82.6,
    "truthfulqa": 56.02,
    "mmlu": 58.35,
    "gsm8k": 13.12,
    "winogrande": 75.37,
    "average": 57.5
  },
  "uukuguy/speechless-llama2-luban-orca-platypus-13b": {
    "arc": 62.54,
    "hellaswag": 82.76,
    "truthfulqa": 54.66,
    "mmlu": 59.23,
    "gsm8k": 8.19,
    "winogrande": 77.11,
    "average": 57.42
  },
  "uukuguy/speechless-mistral-7b-dare-0.85": {
    "arc": 63.57,
    "hellaswag": 84.82,
    "truthfulqa": 50.66,
    "winogrande": 79.24,
    "gsm8k": 45.56,
    "mmlu": 64.29,
    "average": 64.69
  },
  "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b": {
    "arc": 64.33,
    "hellaswag": 84.4,
    "truthfulqa": 52.52,
    "winogrande": 78.37,
    "gsm8k": 21.38,
    "mmlu": 63.72,
    "average": 60.79
  },
  "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85": {
    "arc": 61.69,
    "hellaswag": 83.85,
    "truthfulqa": 43.13,
    "winogrande": 78.93,
    "gsm8k": 40.33,
    "mmlu": 64.43,
    "average": 62.06
  },
  "uukuguy/speechless-mistral-six-in-one-7b": {
    "arc": 62.97,
    "hellaswag": 84.6,
    "truthfulqa": 57.77,
    "winogrande": 77.51,
    "gsm8k": 18.42,
    "mmlu": 63.29,
    "average": 60.76
  },
  "uukuguy/speechless-orca-platypus-coig-lite-2k-0.6e-13b": {
    "arc": 59.9,
    "hellaswag": 80.76,
    "truthfulqa": 47.97,
    "mmlu": 58.34,
    "gsm8k": 7.51,
    "winogrande": 77.9,
    "average": 55.4
  },
  "uukuguy/speechless-orca-platypus-coig-lite-4k-0.5e-13b": {
    "arc": 58.02,
    "hellaswag": 80.15,
    "truthfulqa": 48.04,
    "mmlu": 57.26,
    "gsm8k": 5.84,
    "winogrande": 75.45,
    "average": 54.13
  },
  "uukuguy/speechless-orca-platypus-coig-lite-4k-0.6e-13b": {
    "arc": 58.79,
    "hellaswag": 79.93,
    "truthfulqa": 48.29,
    "mmlu": 56.77,
    "gsm8k": 4.25,
    "winogrande": 75.93,
    "average": 53.99
  },
  "uukuguy/speechless-tools-7b": {
    "arc": 38.91,
    "hellaswag": 57.69,
    "truthfulqa": 44.08,
    "winogrande": 58.56,
    "gsm8k": 7.51,
    "mmlu": 33.24,
    "average": 40
  },
  "uukuguy/speechless-tora-code-7b-v1.0": {
    "arc": 42.66,
    "hellaswag": 65.16,
    "truthfulqa": 42.06,
    "mmlu": 38.56,
    "gsm8k": 0.91,
    "winogrande": 62.9,
    "average": 42.04
  },
  "uukuguy/zephyr-7b-alpha-dare-0.85": {
    "arc": 61.18,
    "hellaswag": 83.67,
    "truthfulqa": 44.41,
    "winogrande": 78.45,
    "gsm8k": 42.08,
    "mmlu": 64.3,
    "average": 62.35
  },
  "v2ray/LLaMA-2-Jannie-70B-QLoRA": {
    "arc": 68.94,
    "hellaswag": 86.9,
    "truthfulqa": 53.67,
    "mmlu": 69.37,
    "gsm8k": 31.77,
    "winogrande": 82.95,
    "average": 65.6
  },
  "v2ray/LLaMA-2-Wizard-70B-QLoRA": {
    "arc": 67.75,
    "hellaswag": 87.5,
    "truthfulqa": 61.72,
    "mmlu": 68.96,
    "gsm8k": 30.48,
    "winogrande": 82.32,
    "average": 66.46
  },
  "venkycs/llama-v2-7b-32kC-Security": {
    "arc": 49.83,
    "hellaswag": 77.33,
    "truthfulqa": 47.96,
    "mmlu": 44.41,
    "gsm8k": 3.87,
    "winogrande": 71.74,
    "average": 49.19
  },
  "vibhorag101/llama-2-13b-chat-hf-phr_mental_therapy": {
    "arc": 38.82,
    "hellaswag": 72.76,
    "truthfulqa": 46.92,
    "winogrande": 65.59,
    "gsm8k": 7.81,
    "mmlu": 23.12,
    "average": 42.5
  },
  "vibhorag101/llama-2-7b-chat-hf-phr_mental_health-2048": {
    "arc": 52.39,
    "hellaswag": 75.39,
    "truthfulqa": 42.89,
    "mmlu": 39.77,
    "gsm8k": 5.91,
    "winogrande": 71.19,
    "average": 47.92
  },
  "vicgalle/alpaca-7b": {
    "arc": 28.07,
    "hellaswag": 25.83,
    "truthfulqa": 48.49,
    "mmlu": 25.31,
    "gsm8k": 0,
    "winogrande": 49.72,
    "average": 29.57
  },
  "vicgalle/gpt2-alpaca": {
    "arc": 22.87,
    "hellaswag": 31.14,
    "truthfulqa": 36.22,
    "mmlu": 26.26,
    "gsm8k": 0,
    "winogrande": 50.67,
    "average": 27.86
  },
  "vicgalle/gpt2-alpaca-gpt4": {
    "arc": 22.61,
    "hellaswag": 31.17,
    "truthfulqa": 38.04,
    "mmlu": 25.76,
    "gsm8k": 0.3,
    "winogrande": 52.17,
    "average": 28.34
  },
  "victor123/WizardLM-13B-1.0": {
    "arc": 28.5,
    "hellaswag": 25.97,
    "truthfulqa": 48.61,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 49.41,
    "average": 29.27
  },
  "vihangd/dopeyplats-1.1b-2T-v1": {
    "arc": 33.11,
    "hellaswag": 54.31,
    "truthfulqa": 39.26,
    "winogrande": 58.8,
    "gsm8k": 1.67,
    "mmlu": 24.55,
    "average": 35.28
  },
  "vihangd/shearedplats-1.3b-v1": {
    "arc": 35.41,
    "hellaswag": 62.75,
    "truthfulqa": 33.93,
    "winogrande": 58.48,
    "gsm8k": 0.53,
    "mmlu": 24.75,
    "average": 35.98
  },
  "vihangd/shearedplats-2.7b-v2": {
    "arc": 42.41,
    "hellaswag": 72.58,
    "truthfulqa": 39.76,
    "winogrande": 65.9,
    "gsm8k": 1.52,
    "mmlu": 27.52,
    "average": 41.62
  },
  "vihangd/smartyplats-3b-v1": {
    "arc": 40.53,
    "hellaswag": 70.85,
    "truthfulqa": 36.53,
    "mmlu": 25.31,
    "gsm8k": 1.06,
    "winogrande": 65.75,
    "average": 40.01
  },
  "vihangd/smartyplats-3b-v2": {
    "arc": 41.04,
    "hellaswag": 71.19,
    "truthfulqa": 36.66,
    "mmlu": 24.32,
    "gsm8k": 1.59,
    "winogrande": 66.93,
    "average": 40.29
  },
  "vihangd/smartyplats-7b-v2": {
    "arc": 57.94,
    "hellaswag": 80.76,
    "truthfulqa": 50.26,
    "winogrande": 75.53,
    "gsm8k": 38.82,
    "mmlu": 58.16,
    "average": 60.25
  },
  "vikp/phi2": {
    "arc": 22.87,
    "hellaswag": 30.7,
    "truthfulqa": 46.1,
    "mmlu": 27.55,
    "gsm8k": 0.68,
    "winogrande": 52.01,
    "average": 29.99
  },
  "vmajor/Orca2-13B-selfmerge-26B": {
    "arc": 60.84,
    "hellaswag": 79.84,
    "truthfulqa": 56.38,
    "winogrande": 76.87,
    "gsm8k": 39.2,
    "mmlu": 60.32,
    "average": 62.24
  },
  "vmajor/Orca2-13B-selfmerge-39B": {
    "arc": 60.84,
    "hellaswag": 79.84,
    "truthfulqa": 56.38,
    "winogrande": 76.87,
    "gsm8k": 39.2,
    "mmlu": 60.32,
    "average": 62.24
  },
  "voidful/changpt-bart": {
    "arc": 28.67,
    "hellaswag": 26.41,
    "truthfulqa": 47.94,
    "mmlu": 23.12,
    "gsm8k": 0,
    "winogrande": 49.49,
    "average": 29.27
  },
  "vonjack/Qwen-LLaMAfied-HFTok-7B-Chat": {
    "arc": 50.51,
    "hellaswag": 83.65,
    "truthfulqa": 44.23,
    "mmlu": 51.53,
    "gsm8k": 2.5,
    "winogrande": 71.43,
    "average": 50.64
  },
  "w601sxs/b1ade-1b": {
    "arc": 28.58,
    "hellaswag": 46.08,
    "truthfulqa": 41.34,
    "mmlu": 25.11,
    "gsm8k": 0.61,
    "winogrande": 53.83,
    "average": 32.59
  },
  "w95/megachat": {
    "arc": 30.8,
    "hellaswag": 54.35,
    "truthfulqa": 39.85,
    "winogrande": 56.99,
    "gsm8k": 0.99,
    "mmlu": 25.55,
    "average": 34.76
  },
  "wahaha1987/llama_13b_sharegpt94k_fastchat": {
    "arc": 53.75,
    "hellaswag": 79.47,
    "truthfulqa": 49.54,
    "mmlu": 51.5,
    "gsm8k": 8.42,
    "winogrande": 72.61,
    "average": 52.55
  },
  "wahaha1987/llama_7b_sharegpt94k_fastchat": {
    "arc": 53.24,
    "hellaswag": 76.94,
    "truthfulqa": 45.34,
    "mmlu": 44.64,
    "gsm8k": 4.32,
    "winogrande": 70.64,
    "average": 49.19
  },
  "wannaphong/openthaigpt-0.1.0-beta-full-model_for_open_llm_leaderboard": {
    "arc": 51.28,
    "hellaswag": 77.46,
    "truthfulqa": 43.28,
    "mmlu": 33.18
  },
  "wei123602/FINETUNE3_TEST4": {
    "arc": 55.63,
    "hellaswag": 81.31,
    "truthfulqa": 41.14,
    "mmlu": 52.13,
    "gsm8k": 11.22,
    "winogrande": 76.72,
    "average": 53.03
  },
  "wei123602/Llama-2-13b-FINETUNE4": {
    "arc": 58.7,
    "hellaswag": 81.93,
    "truthfulqa": 43.26,
    "mmlu": 57.21,
    "gsm8k": 12.51,
    "winogrande": 76.95,
    "average": 55.09
  },
  "wei123602/Llama-2-13b-FINETUNE4_TEST": {
    "arc": 54.78,
    "hellaswag": 81.52,
    "truthfulqa": 39.14,
    "mmlu": 56.03,
    "gsm8k": 13.19,
    "winogrande": 77.03,
    "average": 53.62
  },
  "wei123602/Llama-2-13b-FINETUNE4_TEST2": {
    "arc": 58.45,
    "hellaswag": 81.7,
    "truthfulqa": 40.19,
    "mmlu": 56.61,
    "gsm8k": 13.19,
    "winogrande": 76.64,
    "average": 54.46
  },
  "wei123602/Llama-2-13b-FINETUNE4_TEST3": {
    "arc": 59.04,
    "hellaswag": 81.65,
    "truthfulqa": 39.98,
    "mmlu": 56.37,
    "gsm8k": 11.22,
    "winogrande": 75.45,
    "average": 53.95
  },
  "wei123602/Llama-2-13b-FINETUNE4_compare8k2": {
    "arc": 58.28,
    "hellaswag": 81.39,
    "truthfulqa": 39.86,
    "mmlu": 56.87,
    "gsm8k": 11.9,
    "winogrande": 76.01,
    "average": 54.05
  },
  "wei123602/llama-13b-FINETUNE3": {
    "arc": 59.3,
    "hellaswag": 81.53,
    "truthfulqa": 41.63,
    "mmlu": 57.46,
    "gsm8k": 12.13,
    "winogrande": 76.72,
    "average": 54.79
  },
  "wei123602/llama2-13b-FINETUNE3_TEST": {
    "arc": 53.67,
    "hellaswag": 79.66,
    "truthfulqa": 40.22,
    "mmlu": 54.48,
    "gsm8k": 14.56,
    "winogrande": 75.93,
    "average": 53.09
  },
  "wei123602/llama2-13b-FINETUNE3_TEST2": {
    "arc": 54.69,
    "hellaswag": 81.48,
    "truthfulqa": 39.93,
    "mmlu": 56.8,
    "gsm8k": 12.59,
    "winogrande": 76.24,
    "average": 53.62
  },
  "wei123602/llama2-13b-fintune2-4E": {
    "arc": 55.89,
    "hellaswag": 80.95,
    "truthfulqa": 42.72,
    "mmlu": 53.73,
    "gsm8k": 10.92,
    "winogrande": 73.09,
    "average": 52.88
  },
  "wenge-research/yayi-13b-llama2": {
    "arc": 48.46,
    "hellaswag": 74.79,
    "truthfulqa": 42.35,
    "mmlu": 38.84,
    "gsm8k": 4.02,
    "winogrande": 69.69,
    "average": 46.36
  },
  "wenge-research/yayi-70b-llama2": {
    "arc": 60.67,
    "hellaswag": 83.93,
    "truthfulqa": 47.63,
    "mmlu": 64.42
  },
  "wenge-research/yayi-7b": {
    "arc": 46.33,
    "hellaswag": 61.72,
    "truthfulqa": 43.7,
    "mmlu": 36.34,
    "gsm8k": 0.91,
    "winogrande": 62.27,
    "average": 41.88
  },
  "wenge-research/yayi-7b-llama2": {
    "arc": 55.03,
    "hellaswag": 77.84,
    "truthfulqa": 44.02,
    "mmlu": 40.92,
    "gsm8k": 6.67,
    "winogrande": 74.51,
    "average": 49.83
  },
  "willnguyen/lacda-2-7B-chat-v0.1": {
    "arc": 53.07,
    "hellaswag": 77.57,
    "truthfulqa": 44.57,
    "winogrande": 74.19,
    "gsm8k": 6.29,
    "mmlu": 46.03,
    "average": 50.29
  },
  "willyninja30/ARIA-70B-French": {
    "arc": 64.51,
    "hellaswag": 85.87,
    "truthfulqa": 52.8,
    "mmlu": 63.88,
    "gsm8k": 26.69,
    "winogrande": 80.51,
    "average": 62.38
  },
  "winglian/Llama-2-3b-hf": {
    "arc": 26.96,
    "hellaswag": 26.52,
    "truthfulqa": 50.71,
    "mmlu": 23.33,
    "gsm8k": 0,
    "winogrande": 49.64,
    "average": 29.53
  },
  "winglian/basilisk-4b": {
    "arc": 25.85,
    "hellaswag": 39.6,
    "truthfulqa": 43.74,
    "mmlu": 24.61,
    "gsm8k": 0,
    "winogrande": 53.12,
    "average": 31.15
  },
  "winglian/llama-2-4b": {
    "arc": 31.23,
    "hellaswag": 53.29,
    "truthfulqa": 38.72,
    "mmlu": 24.22,
    "gsm8k": 0.45,
    "winogrande": 57.46,
    "average": 34.23
  },
  "wtang06/mpt-125m-c4": {
    "gsm8k": 0,
    "winogrande": 49.57
  },
  "xDAN-AI/xDAN-L1-Thinking": {
    "arc": 63.74,
    "hellaswag": 84.53,
    "truthfulqa": 52.13,
    "mmlu": 62.9
  },
  "xDAN-AI/xDAN_13b_l2_lora": {
    "arc": 61.01,
    "hellaswag": 82.64,
    "truthfulqa": 44.75,
    "mmlu": 56.03
  },
  "xhyi/PT_GPTNEO350_ATG": {
    "arc": 25.43,
    "hellaswag": 37.59,
    "truthfulqa": 43.05,
    "mmlu": 24.79,
    "gsm8k": 0.45,
    "winogrande": 51.46,
    "average": 30.46
  },
  "xiaol/RWKV-v4-raven-14B-one-state": {
    "arc": 45.73,
    "hellaswag": 71.48,
    "truthfulqa": 37.3,
    "mmlu": 33.47
  },
  "xxyyy123/10k_v1_lora_qkvo_rank14_v3": {
    "arc": 55.97,
    "hellaswag": 79.22,
    "truthfulqa": 53.44,
    "mmlu": 50.71
  },
  "xxyyy123/10k_v1_lora_qkvo_rank28_v2": {
    "arc": 55.38,
    "hellaswag": 79.21,
    "truthfulqa": 52.75,
    "mmlu": 50.5,
    "gsm8k": 0.61,
    "winogrande": 73.24,
    "average": 51.95
  },
  "xxyyy123/1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128": {
    "arc": 62.88,
    "hellaswag": 83.99,
    "truthfulqa": 50.55,
    "winogrande": 79.72,
    "gsm8k": 40.18,
    "mmlu": 62.89,
    "average": 63.37
  },
  "xxyyy123/20k_v1_lora_qkvo_rank14_v2": {
    "arc": 55.38,
    "hellaswag": 79.1,
    "truthfulqa": 51.58,
    "mmlu": 50.65
  },
  "xxyyy123/Mistral7B_adaptor_v1": {
    "arc": 62.97,
    "hellaswag": 83.81,
    "truthfulqa": 49.77,
    "winogrande": 79.16,
    "gsm8k": 41.24,
    "mmlu": 63.56,
    "average": 63.42
  },
  "xxyyy123/mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2": {
    "arc": 57.17,
    "hellaswag": 79.57,
    "truthfulqa": 52.51,
    "mmlu": 50.24,
    "gsm8k": 0.38,
    "winogrande": 72.93,
    "average": 52.13
  },
  "xxyyy123/test_merge_p_ov1_w0.66_w0.5_n1": {
    "arc": 62.46,
    "hellaswag": 82.37,
    "truthfulqa": 56.18,
    "mmlu": 58.05
  },
  "xxyyy123/test_qkvo_adptor": {
    "arc": 55.38,
    "hellaswag": 78.99,
    "truthfulqa": 53.53,
    "mmlu": 51.64
  },
  "xzuyn/Alpacino-SuperCOT-13B": {
    "arc": 58.36,
    "hellaswag": 81.69,
    "truthfulqa": 45.42,
    "mmlu": 47.89,
    "gsm8k": 7.51,
    "winogrande": 76.95,
    "average": 52.97
  },
  "xzuyn/MedicWizard-7B": {
    "arc": 53.5,
    "hellaswag": 78.39,
    "truthfulqa": 41.32,
    "mmlu": 44.61,
    "gsm8k": 4.93,
    "winogrande": 70.56,
    "average": 48.89
  },
  "yec019/fbopt-350m-8bit": {
    "arc": 23.55,
    "hellaswag": 36.6,
    "truthfulqa": 40.97,
    "winogrande": 52.64,
    "gsm8k": 1.29,
    "mmlu": 26.22,
    "average": 30.21
  },
  "yeen214/llama2_7b_merge_orcafamily": {
    "arc": 56.91,
    "hellaswag": 81.17,
    "truthfulqa": 49.68,
    "winogrande": 75.93,
    "gsm8k": 23.12,
    "mmlu": 51.49,
    "average": 56.38
  },
  "yeen214/llama2_7b_small_tuning_v1": {
    "arc": 22.44,
    "hellaswag": 25,
    "truthfulqa": 48.7,
    "mmlu": 25.51,
    "gsm8k": 0,
    "winogrande": 49.72,
    "average": 28.56
  },
  "yeen214/test_llama2_7b": {
    "arc": 53.07,
    "hellaswag": 78.57,
    "truthfulqa": 38.75,
    "mmlu": 46.86,
    "gsm8k": 7.13,
    "winogrande": 74.03,
    "average": 49.73
  },
  "yeen214/test_llama2_ko_7b": {
    "arc": 29.95,
    "hellaswag": 26.94,
    "truthfulqa": 49.03,
    "mmlu": 25.62,
    "gsm8k": 0,
    "winogrande": 48.38,
    "average": 29.99
  },
  "yeontaek/Platypus2-13B-IA3": {
    "arc": 61.09,
    "hellaswag": 82.65,
    "truthfulqa": 38.35,
    "mmlu": 56.32,
    "gsm8k": 11.3,
    "winogrande": 75.69,
    "average": 54.23
  },
  "yeontaek/Platypus2-13B-LoRa": {
    "arc": 60.67,
    "hellaswag": 82.5,
    "truthfulqa": 43.91,
    "mmlu": 56.34,
    "gsm8k": 7.51,
    "winogrande": 75.93,
    "average": 54.48
  },
  "yeontaek/Platypus2-13B-LoRa-v2": {
    "arc": 59.47,
    "hellaswag": 82.41,
    "truthfulqa": 41.92,
    "mmlu": 57.15
  },
  "yeontaek/Platypus2-13B-QLoRa": {
    "arc": 57.51,
    "hellaswag": 82.55,
    "truthfulqa": 43.38,
    "mmlu": 57.34,
    "gsm8k": 5,
    "winogrande": 76.64,
    "average": 53.74
  },
  "yeontaek/Platypus2xOpenOrca-13B-IA3": {
    "arc": 62.12,
    "hellaswag": 82.1,
    "truthfulqa": 47.88,
    "mmlu": 58.84,
    "gsm8k": 11.83,
    "winogrande": 77.11,
    "average": 56.65
  },
  "yeontaek/Platypus2xOpenOrca-13B-IA3-ensemble": {
    "arc": 62.12,
    "hellaswag": 82.28,
    "truthfulqa": 47.46,
    "mmlu": 59.07
  },
  "yeontaek/Platypus2xOpenOrca-13B-IA3-v2": {
    "arc": 62.29,
    "hellaswag": 82.09,
    "truthfulqa": 47.03,
    "mmlu": 57.91
  },
  "yeontaek/Platypus2xOpenOrca-13B-IA3-v2.1": {
    "arc": 62.29,
    "hellaswag": 82.09,
    "truthfulqa": 47.03,
    "mmlu": 57.91,
    "gsm8k": 10.99,
    "winogrande": 77.43,
    "average": 56.29
  },
  "yeontaek/Platypus2xOpenOrca-13B-IA3-v3": {
    "arc": 62.54,
    "hellaswag": 82.1,
    "truthfulqa": 46.96,
    "mmlu": 58.67,
    "gsm8k": 12.36,
    "winogrande": 77.82,
    "average": 56.74
  },
  "yeontaek/Platypus2xOpenOrca-13B-IA3-v4": {
    "arc": 61.43,
    "hellaswag": 81.84,
    "truthfulqa": 48.64,
    "mmlu": 59.02,
    "gsm8k": 10.84,
    "winogrande": 77.19,
    "average": 56.49
  },
  "yeontaek/Platypus2xOpenOrca-13B-LoRa": {
    "arc": 60.75,
    "hellaswag": 82.09,
    "truthfulqa": 45.15,
    "mmlu": 58.77,
    "gsm8k": 7.13,
    "winogrande": 77.03,
    "average": 55.15
  },
  "yeontaek/Platypus2xOpenOrca-13B-LoRa-v2": {
    "arc": 58.62,
    "hellaswag": 81.17,
    "truthfulqa": 43.43,
    "mmlu": 50.23,
    "gsm8k": 0.08,
    "winogrande": 76.16,
    "average": 51.62
  },
  "yeontaek/Platypus2xOpenOrcaxGuanaco-13B-LoRa": {
    "arc": 61.26,
    "hellaswag": 80.52,
    "truthfulqa": 41.82,
    "mmlu": 57.84
  },
  "yeontaek/WizardCoder-Python-13B-LoRa": {
    "arc": 47.78,
    "hellaswag": 69.6,
    "truthfulqa": 43.97,
    "mmlu": 38.76,
    "gsm8k": 7.81,
    "winogrande": 65.43,
    "average": 45.56
  },
  "yeontaek/airoboros-2.1-llama-2-13B-QLoRa": {
    "arc": 59.73,
    "hellaswag": 82.91,
    "truthfulqa": 45.14,
    "mmlu": 54.77,
    "gsm8k": 2.81,
    "winogrande": 74.03,
    "average": 53.23
  },
  "yeontaek/llama-2-13B-ensemble-v1": {
    "arc": 62.29,
    "hellaswag": 82.36,
    "truthfulqa": 50.16,
    "mmlu": 57.59
  },
  "yeontaek/llama-2-13B-ensemble-v3": {
    "arc": 62.37,
    "hellaswag": 82.29,
    "truthfulqa": 49.78,
    "mmlu": 57.67
  },
  "yeontaek/llama-2-13B-ensemble-v4": {
    "arc": 62.97,
    "hellaswag": 82.38,
    "truthfulqa": 51.82,
    "mmlu": 56.48
  },
  "yeontaek/llama-2-13B-ensemble-v5": {
    "arc": 62.63,
    "hellaswag": 83.06,
    "truthfulqa": 53.27,
    "mmlu": 59.49
  },
  "yeontaek/llama-2-13B-ensemble-v6": {
    "arc": 52.22,
    "hellaswag": 80.95,
    "truthfulqa": 52.64,
    "mmlu": 57.38
  },
  "yeontaek/llama-2-13b-Beluga-QLoRA": {
    "arc": 59.22,
    "hellaswag": 81.92,
    "truthfulqa": 48.23,
    "mmlu": 56.67,
    "gsm8k": 1.29,
    "winogrande": 77.19,
    "average": 54.09
  },
  "yeontaek/llama-2-13b-Guanaco-QLoRA": {
    "arc": 61.09,
    "hellaswag": 82.99,
    "truthfulqa": 44.12,
    "mmlu": 55.47,
    "gsm8k": 10.99,
    "winogrande": 77.19,
    "average": 55.31
  },
  "yeontaek/llama-2-13b-QLoRA": {
    "arc": 58.02,
    "hellaswag": 82.33,
    "truthfulqa": 46.23,
    "mmlu": 55.8,
    "gsm8k": 3.26,
    "winogrande": 77.58,
    "average": 53.87
  },
  "yeontaek/llama-2-70B-ensemble-v2": {
    "arc": 68.77,
    "hellaswag": 85.36,
    "truthfulqa": 64.51,
    "mmlu": 68.04
  },
  "yeontaek/llama-2-70B-ensemble-v3": {
    "arc": 68.52,
    "hellaswag": 87.16,
    "truthfulqa": 64.22,
    "mmlu": 68.15
  },
  "yeontaek/llama-2-70B-ensemble-v4": {
    "arc": 70.9,
    "hellaswag": 87.34,
    "truthfulqa": 62.6,
    "mmlu": 69.71
  },
  "yeontaek/llama-2-70B-ensemble-v5": {
    "arc": 71.16,
    "hellaswag": 87.24,
    "truthfulqa": 63.45,
    "mmlu": 69.6
  },
  "yeontaek/llama-2-70B-ensemble-v6": {
    "arc": 70.99,
    "hellaswag": 87.2,
    "truthfulqa": 62.43,
    "mmlu": 68.07
  },
  "yeontaek/llama-2-70B-ensemble-v7": {
    "arc": 70.31,
    "hellaswag": 87.31,
    "truthfulqa": 63.1,
    "mmlu": 68.34
  },
  "yeontaek/llama-2-70B-ensemble-v8": {
    "arc": 67.24,
    "hellaswag": 84.56,
    "truthfulqa": 62.11,
    "mmlu": 63.56
  },
  "yeontaek/llama-2-70b-IA3-guanaco": {
    "arc": 68.52,
    "hellaswag": 85.67,
    "truthfulqa": 43.47,
    "mmlu": 67.03,
    "gsm8k": 28.73,
    "winogrande": 82.24,
    "average": 62.61
  },
  "yhyhy3/med-orca-instruct-33b": {
    "arc": 28.84,
    "hellaswag": 25.63,
    "truthfulqa": 49.26,
    "mmlu": 26.5,
    "gsm8k": 0,
    "winogrande": 50.51,
    "average": 30.12
  },
  "yhyhy3/open_llama_7b_v2_med_instruct": {
    "arc": 46.5,
    "hellaswag": 76.91,
    "truthfulqa": 40.33,
    "mmlu": 42.32,
    "gsm8k": 2.05,
    "winogrande": 69.3,
    "average": 46.24
  },
  "yihan6324/instructmining-platypus-15k": {
    "arc": 54.35,
    "hellaswag": 80.01,
    "truthfulqa": 41.8,
    "mmlu": 37.44
  },
  "yihan6324/llama-2-7b-instructmining-60k-sharegpt": {
    "arc": 54.44,
    "hellaswag": 78.59,
    "truthfulqa": 52.9,
    "mmlu": 51.26
  },
  "yihan6324/llama2-13b-instructmining-40k-sharegpt": {
    "arc": 59.98,
    "hellaswag": 83.06,
    "truthfulqa": 52.44,
    "mmlu": 56.48
  },
  "yihan6324/llama2-7b-instructmining-40k-sharegpt": {
    "arc": 55.12,
    "hellaswag": 78.96,
    "truthfulqa": 53.18,
    "mmlu": 50.43
  },
  "yihan6324/llama2-7b-instructmining-60k-sharegpt": {
    "arc": 54.44,
    "hellaswag": 78.59,
    "truthfulqa": 52.9,
    "mmlu": 51.26
  },
  "yihan6324/llama2-7b-instructmining-orca-40k": {
    "arc": 56.74,
    "hellaswag": 80.24,
    "truthfulqa": 51.03,
    "mmlu": 48.16
  },
  "yihan6324/llama2-7b-instructmining-orca-90k": {
    "arc": 54.44,
    "hellaswag": 80.45,
    "truthfulqa": 49.36,
    "mmlu": 50.89
  },
  "yulan-team/YuLan-Chat-2-13b-fp16": {
    "arc": 59.04,
    "hellaswag": 80.66,
    "truthfulqa": 52.18,
    "mmlu": 56.72,
    "gsm8k": 13.8,
    "winogrande": 79.64,
    "average": 57.01
  },
  "zarakiquemparte/kuchiki-1.1-l2-7b": {
    "arc": 54.18,
    "hellaswag": 78,
    "truthfulqa": 49.96,
    "mmlu": 48.14,
    "gsm8k": 4.7,
    "winogrande": 73.16,
    "average": 51.36
  },
  "zarakiquemparte/kuchiki-l2-7b": {
    "arc": 54.35,
    "hellaswag": 78.44,
    "truthfulqa": 49.88,
    "mmlu": 47.74,
    "gsm8k": 4.47,
    "winogrande": 73.09,
    "average": 51.33
  },
  "zarakiquemparte/zarablend-1.1-l2-7b": {
    "arc": 54.86,
    "hellaswag": 78.58,
    "truthfulqa": 49,
    "mmlu": 47.89,
    "gsm8k": 4.55,
    "winogrande": 72.61,
    "average": 51.25
  },
  "zarakiquemparte/zarablend-l2-7b": {
    "arc": 54.44,
    "hellaswag": 78.62,
    "truthfulqa": 49.38,
    "mmlu": 47.61,
    "gsm8k": 4.4,
    "winogrande": 73.32,
    "average": 51.29
  },
  "zarakiquemparte/zarablendex-vq-l2-7b": {
    "arc": 56.06,
    "hellaswag": 79.37,
    "truthfulqa": 51.17,
    "mmlu": 51.45
  },
  "zarakiquemparte/zarafusionex-1.1-l2-7b": {
    "arc": 56.14,
    "hellaswag": 79.34,
    "truthfulqa": 50.66,
    "mmlu": 52.1,
    "gsm8k": 7.81,
    "winogrande": 74.43,
    "average": 53.41
  },
  "zarakiquemparte/zarafusionex-1.2-l2-7b": {
    "arc": 56.66,
    "hellaswag": 79.16,
    "truthfulqa": 51.29,
    "mmlu": 51.94,
    "gsm8k": 8.57,
    "winogrande": 74.74,
    "average": 53.73
  },
  "zarakiquemparte/zarafusionix-l2-7b": {
    "arc": 55.55,
    "hellaswag": 79.4,
    "truthfulqa": 51.05,
    "mmlu": 51.21,
    "gsm8k": 7.2,
    "winogrande": 74.66,
    "average": 53.18
  },
  "zarakiquemparte/zararp-1.1-l2-7b": {
    "arc": 56.48,
    "hellaswag": 78.85,
    "truthfulqa": 51.99,
    "mmlu": 51.49,
    "gsm8k": 1.14,
    "winogrande": 73.4,
    "average": 52.23
  },
  "zarakiquemparte/zararp-l2-7b": {
    "arc": 56.31,
    "hellaswag": 79.19,
    "truthfulqa": 51.26,
    "mmlu": 51.36,
    "gsm8k": 1.74,
    "winogrande": 74.51,
    "average": 52.4
  },
  "zarakiquemparte/zaraxe-l2-7b": {
    "arc": 57.17,
    "hellaswag": 79.34,
    "truthfulqa": 49.11,
    "mmlu": 51,
    "gsm8k": 7.58,
    "winogrande": 73.48,
    "average": 52.95
  },
  "zarakiquemparte/zaraxls-l2-7b": {
    "arc": 54.44,
    "hellaswag": 78.94,
    "truthfulqa": 46.51,
    "mmlu": 50.39,
    "gsm8k": 0.23,
    "winogrande": 73.16,
    "average": 50.61
  },
  "ziqingyang/chinese-alpaca-2-13b": {
    "arc": 58.7,
    "hellaswag": 79.74,
    "truthfulqa": 50.22,
    "mmlu": 55.1,
    "gsm8k": 10.46,
    "winogrande": 75.69,
    "average": 54.98
  },
  "ziqingyang/chinese-alpaca-2-7b": {
    "arc": 49.57,
    "hellaswag": 72.62,
    "truthfulqa": 48.63,
    "mmlu": 46.5,
    "gsm8k": 5.76,
    "winogrande": 70.01,
    "average": 48.85
  },
  "ziqingyang/chinese-llama-2-13b": {
    "arc": 55.8,
    "hellaswag": 79.53,
    "truthfulqa": 38.24,
    "mmlu": 53.01,
    "gsm8k": 3.94,
    "winogrande": 75.69,
    "average": 51.04
  },
  "ziqingyang/chinese-llama-2-7b": {
    "arc": 44.45,
    "hellaswag": 69.5,
    "truthfulqa": 37,
    "mmlu": 37.47,
    "gsm8k": 1.44,
    "winogrande": 68.98,
    "average": 43.14
  }
}